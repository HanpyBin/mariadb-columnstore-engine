From 00490ac2138a70c4fff5b2ca76ec53e2c57c7f01 Mon Sep 17 00:00:00 2001
From: Roman Nozdrin <roman.nozdrin@mariadb.com>
Date: Fri, 24 Feb 2023 14:29:26 +0000
Subject: [PATCH 01/15] MCOL-5437 Fixes to follow the charset_info api change
 introduced by MDEV-30661

---
 utils/funcexp/func_lcase.cpp | 4 ++++
 utils/funcexp/func_ucase.cpp | 6 +++++-
 2 files changed, 9 insertions(+), 1 deletion(-)

diff --git a/utils/funcexp/func_lcase.cpp b/utils/funcexp/func_lcase.cpp
index ccc2dccb58..eabdfd40b1 100644
--- a/utils/funcexp/func_lcase.cpp
+++ b/utils/funcexp/func_lcase.cpp
@@ -53,7 +53,11 @@ std::string Func_lcase::getStrVal(rowgroup::Row& row, FunctionParm& fp, bool& is
 
   CHARSET_INFO* cs = colType.getCharset();
   uint64_t inLen = tstr.length();
+#if MYSQL_VERSION_ID >= 101004
+  uint64_t bufLen = inLen * cs->casedn_multiply();
+#else
   uint64_t bufLen = inLen * cs->casedn_multiply;
+#endif
   char* outBuf = new char[bufLen];
 
   uint64_t outLen = cs->casedn(tstr.c_str(), inLen, outBuf, bufLen);
diff --git a/utils/funcexp/func_ucase.cpp b/utils/funcexp/func_ucase.cpp
index 578ad5e07e..1cbbd6a2db 100644
--- a/utils/funcexp/func_ucase.cpp
+++ b/utils/funcexp/func_ucase.cpp
@@ -62,7 +62,11 @@ std::string Func_ucase::getStrVal(rowgroup::Row& row, FunctionParm& fp, bool& is
 
   CHARSET_INFO* cs = colType.getCharset();
   uint64_t inLen = tstr.length();
-  uint64_t bufLen = inLen * cs->caseup_multiply;
+#if MYSQL_VERSION_ID >= 101004
+  uint64_t bufLen = inLen * cs->casedn_multiply();
+#else
+  uint64_t bufLen = inLen * cs->casedn_multiply;
+#endif
   char* outBuf = new char[bufLen];
 
   uint64_t outLen = cs->caseup(tstr.c_str(), inLen, outBuf, bufLen);

From 7e6462d17cfdc3d30be51e7c867053a164cea809 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Fri, 9 Jun 2023 16:53:14 +0800
Subject: [PATCH 02/15] fix segmentation error

---
 cmake/thrift.cmake               |  6 +++---
 writeengine/bulk/CMakeLists.txt  |  5 ++++-
 writeengine/bulk/we_bulkload.cpp | 35 +++++++++++++++++++++++++++++++-
 writeengine/bulk/we_bulkload.h   |  4 ++++
 4 files changed, 45 insertions(+), 5 deletions(-)

diff --git a/cmake/thrift.cmake b/cmake/thrift.cmake
index 3cce8ddbfa..8b4f25e33e 100644
--- a/cmake/thrift.cmake
+++ b/cmake/thrift.cmake
@@ -7,8 +7,8 @@ set(THRIFT_LIBRARY ${THRIFT_LIBRARY_DIRS}/${CMAKE_STATIC_LIBRARY_PREFIX}thrift${
 
 
 ExternalProject_Add(external_thrift
-    URL https://github.com/apache/thrift/archive/refs/tags/v0.17.0.tar.gz
-    URL_HASH SHA256=f5888bcd3b8de40c2c2ab86896867ad9b18510deb412cba3e5da76fb4c604c29
+    URL https://github.com/apache/thrift/archive/refs/tags/v0.13.0.tar.gz
+    URL_HASH SHA256=5da60088e60984f4f0801deeea628d193c33cec621e78c8a43a5d8c4055f7ad9
     PREFIX ${INSTALL_LOCATION}
     CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=${INSTALL_LOCATION}
     -DBUILD_COMPILER=YES
@@ -20,7 +20,7 @@ ExternalProject_Add(external_thrift
     -DBUILD_NODEJS=NO
     -DBUILD_PYTHON=NO
     -DBUILD_TESTING=NO
-    -DBUILD_SHARED_LIBS=NO
+    -DWITH_STATIC_LIB=ON
     -DCMAKE_CXX_FLAGS:STRING="-fPIC"
     -DBOOST_INCLUDEDIR=${Boost_INCLUDE_DIRS}
     -DBOOST_LIBRARYDIR=${Boost_LIBRARY_DIRS}
diff --git a/writeengine/bulk/CMakeLists.txt b/writeengine/bulk/CMakeLists.txt
index a414b1797e..a4db3b9a93 100644
--- a/writeengine/bulk/CMakeLists.txt
+++ b/writeengine/bulk/CMakeLists.txt
@@ -41,6 +41,9 @@ set(cpimport.bin_SRCS cpimport.cpp)
 add_executable(cpimport.bin ${cpimport.bin_SRCS})
 add_dependencies(cpimport.bin marias3)
 target_link_libraries(cpimport.bin boost_program_options ${ENGINE_LDFLAGS} ${NETSNMP_LIBRARIES} ${ENGINE_WRITE_LIBS} ${S3API_DEPS} we_bulk we_xml)
-
+FIND_PACKAGE(Arrow REQUIRED)
+FIND_PACKAGE(Parquet REQUIRED)
+target_link_libraries(cpimport.bin arrow)
+target_link_libraries(cpimport.bin parquet)
 install(TARGETS cpimport.bin DESTINATION ${ENGINE_BINDIR} COMPONENT columnstore-engine)
 
diff --git a/writeengine/bulk/we_bulkload.cpp b/writeengine/bulk/we_bulkload.cpp
index 4ddbd7e4af..a6cbb661fb 100644
--- a/writeengine/bulk/we_bulkload.cpp
+++ b/writeengine/bulk/we_bulkload.cpp
@@ -25,6 +25,12 @@
 #include "we_bulkload.h"
 #undef WE_BULKLOAD_DLLEXPORT
 
+#include <arrow/api.h>
+#include <arrow/io/api.h>
+#include <parquet/arrow/reader.h>
+#include <parquet/arrow/writer.h>
+#include <parquet/exception.h>
+
 #include <cmath>
 #include <cstdlib>
 #include <climits>
@@ -446,6 +452,26 @@ int BulkLoad::loadJobInfo(const string& fullName, bool bUseTempJobFile, int argc
   return NO_ERROR;
 }
 
+
+
+void BulkLoad::spawnWorkersParquet()
+{
+  // std::cout << "Reading first column of parquet-arrow-example.parquet" << std::endl;
+  // std::shared_ptr<arrow::io::ReadableFile> infile;
+  // PARQUET_ASSIGN_OR_THROW(infile,
+  //                         arrow::io::ReadableFile::Open("/tmp/parquet-arrow-example.parquet",
+  //                                                       arrow::default_memory_pool()));
+  // std::unique_ptr<parquet::arrow::FileReader> reader;
+  // PARQUET_THROW_NOT_OK(
+  //     parquet::arrow::OpenFile(infile, arrow::default_memory_pool(), &reader));
+  // std::shared_ptr<arrow::ChunkedArray> array;
+  // PARQUET_THROW_NOT_OK(reader->ReadColumn(1, &array));
+  // PARQUET_THROW_NOT_OK(arrow::PrettyPrint(*array, 4, &std::cout));
+  // std::cout << std::endl;
+
+  
+}
+
 //------------------------------------------------------------------------------
 // DESCRIPTION:
 //    Spawns and joins the Read and Parsing threads to import the data.
@@ -1154,7 +1180,14 @@ int BulkLoad::processJob()
 
   startTimer();
 
-  spawnWorkers();
+  if (tables[0]->fLoadFileList[0].rfind(".parquet") != std::string::npos)
+  {
+    spawnWorkersParquet();
+  }
+  else
+  {
+    spawnWorkers();
+  }
 
   if (BulkStatus::getJobStatus() == EXIT_FAILURE)
   {
diff --git a/writeengine/bulk/we_bulkload.h b/writeengine/bulk/we_bulkload.h
index 39841b23af..4ad9996293 100644
--- a/writeengine/bulk/we_bulkload.h
+++ b/writeengine/bulk/we_bulkload.h
@@ -244,6 +244,10 @@ class BulkLoad : public FileOp
   // Spawn the worker threads.
   void spawnWorkers();
 
+  // Handle parquet file single-threaded
+  void spawnWorkersParquet();
+
+
   // Checks if all tables have the status set
   bool allTablesDone(Status status);
 

From a3a6f30a8d747d6180d49b95684b4ce68df46cf3 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Wed, 14 Jun 2023 16:41:29 +0800
Subject: [PATCH 03/15] integrate parquet-cpp

---
 writeengine/bulk/we_bulkload.cpp  | 43 +++++++++++++++---------
 writeengine/bulk/we_bulkload.h    | 12 +++++++
 writeengine/bulk/we_tableinfo.cpp | 56 +++++++++++++++++++++++++++++++
 writeengine/bulk/we_tableinfo.h   |  4 +++
 4 files changed, 99 insertions(+), 16 deletions(-)

diff --git a/writeengine/bulk/we_bulkload.cpp b/writeengine/bulk/we_bulkload.cpp
index a6cbb661fb..9b7f2c30f8 100644
--- a/writeengine/bulk/we_bulkload.cpp
+++ b/writeengine/bulk/we_bulkload.cpp
@@ -456,20 +456,31 @@ int BulkLoad::loadJobInfo(const string& fullName, bool bUseTempJobFile, int argc
 
 void BulkLoad::spawnWorkersParquet()
 {
-  // std::cout << "Reading first column of parquet-arrow-example.parquet" << std::endl;
-  // std::shared_ptr<arrow::io::ReadableFile> infile;
-  // PARQUET_ASSIGN_OR_THROW(infile,
-  //                         arrow::io::ReadableFile::Open("/tmp/parquet-arrow-example.parquet",
-  //                                                       arrow::default_memory_pool()));
-  // std::unique_ptr<parquet::arrow::FileReader> reader;
-  // PARQUET_THROW_NOT_OK(
-  //     parquet::arrow::OpenFile(infile, arrow::default_memory_pool(), &reader));
-  // std::shared_ptr<arrow::ChunkedArray> array;
-  // PARQUET_THROW_NOT_OK(reader->ReadColumn(1, &array));
-  // PARQUET_THROW_NOT_OK(arrow::PrettyPrint(*array, 4, &std::cout));
-  // std::cout << std::endl;
-
-  
+  int tableId = -1;
+
+  try
+  {
+    // Loop to select and read the next table
+
+    while (true)
+    {
+      tableId = -1;
+
+      if ((tableId = lockTableForRead(id)) == -1)
+      {
+        fLog.logMsg(
+          "BulkLoad::ReadOperation No more tables "
+          "available for processing. Read thread " +
+            Convertor::int2Str(id) + " exiting...",
+        MSGLVL_INFO2);
+        return;
+      }
+
+      // for every table, read parquet file
+      int rc = fTableInfo[tableId].readParquetData();
+      // TODO:
+    }
+  }
 }
 
 //------------------------------------------------------------------------------
@@ -861,7 +872,7 @@ int BulkLoad::preProcess(Job& job, int tableNo, TableInfo* tableInfo)
   }
 
   // Initialize BulkLoadBuffers after we have added all the columns
-  rc = tableInfo->initializeBuffers(fNoOfBuffers, job.jobTableList[tableNo].fFldRefs, fixedBinaryRecLen);
+  rc = tableInfo->(fNoOfBuffers, job.jobTableList[tableNo].fFldRefs, fixedBinaryRecLen);
   if (rc)
     return rc;
 
@@ -1180,7 +1191,7 @@ int BulkLoad::processJob()
 
   startTimer();
 
-  if (tables[0]->fLoadFileList[0].rfind(".parquet") != std::string::npos)
+  if (LOAD_FILE == FILE_PARQUET)
   {
     spawnWorkersParquet();
   }
diff --git a/writeengine/bulk/we_bulkload.h b/writeengine/bulk/we_bulkload.h
index 4ad9996293..97c8afddd4 100644
--- a/writeengine/bulk/we_bulkload.h
+++ b/writeengine/bulk/we_bulkload.h
@@ -54,6 +54,13 @@
 /** Namespace WriteEngine */
 namespace WriteEngine
 {
+
+enum LOADFILE
+{
+  FILE_TEXT,
+  FILE_PARQUET
+};
+
 /** Class BulkLoad */
 class BulkLoad : public FileOp
 {
@@ -212,6 +219,7 @@ class BulkLoad : public FileOp
   timeval fEndTime;                              // job end time
   double fTotalTime;                             // elapsed time for current phase
   std::vector<std::string> fCmdLineImportFiles;  // Import Files from cmd line
+  LOADFILE LOAD_FILE;                            // Import Files type
   BulkModeType fBulkMode;                        // Distributed bulk mode (1,2, or 3)
   std::string fBRMRptFileName;                   // Name of distributed mode rpt file
   bool fbTruncationAsError;                      // Treat string truncation as error
@@ -309,6 +317,10 @@ class BulkLoad : public FileOp
 //------------------------------------------------------------------------------
 inline void BulkLoad::addToCmdLineImportFileList(const std::string& importFile)
 {
+  if (importFile.rfind(".parquet") != std::string::npos)
+  {
+    LOAD_FILE = FILE_PARQUET;
+  }
   fCmdLineImportFiles.push_back(importFile);
 }
 
diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index 8e861b7b07..8d81ae635b 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -55,6 +55,15 @@ using namespace querytele;
 #include "oamcache.h"
 #include "cacheutils.h"
 
+#include <arrow/api.h>
+#include <arrow/io/api.h>
+#include <parquet/arrow/reader.h>
+#include <parquet/arrow/writer.h>
+#include <parquet/exception.h>
+#include <arrow/result.h>
+#include <arrow/status.h>
+#include <arrow/io/file.h>
+#include <parquet/stream_reader.h>
 namespace
 {
 const std::string BAD_FILE_SUFFIX = ".bad";  // Reject data file suffix
@@ -259,6 +268,53 @@ bool TableInfo::lockForRead(const int& locker)
   return false;
 }
 
+
+
+int TableInfo::readParquetData()
+{
+  int fileCounter = 0;
+  fFileName = fLoadFileList[fileCounter];
+
+  std::cout << "Reading by RecordBatchReader" << std::endl;
+
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+
+  // Configure general Parquet reader settings
+  auto reader_properties = parquet::ReaderProperties(pool);
+  reader_properties.set_buffer_size(4096 * 4);
+  reader_properties.enable_buffered_stream();
+
+  // Configure Arrow-specific Parquet reader settings
+  auto arrow_reader_props = parquet::ArrowReaderProperties();
+  // TODO:batch_size is set as a parameter
+  arrow_reader_props.set_batch_size(64 * 1024);  // default 64 * 1024
+
+  parquet::arrow::FileReaderBuilder reader_builder;
+  PARQUET_THROW_NOT_OK(
+      reader_builder.OpenFile(fFileName, /*memory_map=*/false, reader_properties));
+  reader_builder.memory_pool(pool);
+  reader_builder.properties(arrow_reader_props);
+
+  std::unique_ptr<parquet::arrow::FileReader> arrow_reader;
+  PARQUET_ASSIGN_OR_THROW(arrow_reader, reader_builder.Build());
+
+  std::shared_ptr<::arrow::RecordBatchReader> rb_reader;
+  PARQUET_THROW_NOT_OK(arrow_reader->GetRecordBatchReader(&rb_reader));
+
+
+  for (arrow::Result<std::shared_ptr<arrow::RecordBatch>> maybe_batch : *rb_reader) {
+    // Operate on each batch...
+    // TODO:
+    PARQUET_ASSIGN_OR_THROW(auto batch, maybe_batch);
+    // PARQUET_ASSIGN_OR_THROW(auto table,
+    //                       arrow::Table::FromRecordBatches(batch->schema(), {batch}));
+    // std::cout << "Loaded " << table->num_rows() << " rows in " << table->num_columns()
+    //           << " columns." << std::endl;
+    // PARQUET_THROW_NOT_OK(arrow::PrettyPrint(*(batch->GetColumnByName("str")), 4, &std::cout));
+    std::cout << batch->ToString() << std::endl;
+  }
+}
+
 //------------------------------------------------------------------------------
 // Loop thru reading the import file(s) assigned to this TableInfo object.
 //------------------------------------------------------------------------------
diff --git a/writeengine/bulk/we_tableinfo.h b/writeengine/bulk/we_tableinfo.h
index f5a09ec901..d67c928cee 100644
--- a/writeengine/bulk/we_tableinfo.h
+++ b/writeengine/bulk/we_tableinfo.h
@@ -373,6 +373,10 @@ class TableInfo : public WeUIDGID
    */
   int readTableData();
 
+  /** @brief Read parquet file data
+  */
+  int readParquetData();
+  
   /** @brief parse method
    */
   int parseColumn(const int& columnId, const int& bufferId, double& processingTime);

From f124ac2a54229b440f7c4a06010af210030457ce Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Mon, 26 Jun 2023 21:13:51 +0800
Subject: [PATCH 04/15] update parse code

---
 writeengine/bulk/CMakeLists.txt        |  4 +-
 writeengine/bulk/we_bulkload.cpp       | 50 +++++++++-----
 writeengine/bulk/we_bulkloadbuffer.cpp | 96 ++++++++++++++++++++++++++
 writeengine/bulk/we_bulkloadbuffer.h   |  4 ++
 writeengine/bulk/we_tableinfo.cpp      | 38 +++++++---
 writeengine/bulk/we_tableinfo.h        |  6 +-
 6 files changed, 164 insertions(+), 34 deletions(-)

diff --git a/writeengine/bulk/CMakeLists.txt b/writeengine/bulk/CMakeLists.txt
index a4db3b9a93..66c01501a1 100644
--- a/writeengine/bulk/CMakeLists.txt
+++ b/writeengine/bulk/CMakeLists.txt
@@ -41,8 +41,8 @@ set(cpimport.bin_SRCS cpimport.cpp)
 add_executable(cpimport.bin ${cpimport.bin_SRCS})
 add_dependencies(cpimport.bin marias3)
 target_link_libraries(cpimport.bin boost_program_options ${ENGINE_LDFLAGS} ${NETSNMP_LIBRARIES} ${ENGINE_WRITE_LIBS} ${S3API_DEPS} we_bulk we_xml)
-FIND_PACKAGE(Arrow REQUIRED)
-FIND_PACKAGE(Parquet REQUIRED)
+FIND_PACKAGE(Arrow)
+FIND_PACKAGE(Parquet)
 target_link_libraries(cpimport.bin arrow)
 target_link_libraries(cpimport.bin parquet)
 install(TARGETS cpimport.bin DESTINATION ${ENGINE_BINDIR} COMPONENT columnstore-engine)
diff --git a/writeengine/bulk/we_bulkload.cpp b/writeengine/bulk/we_bulkload.cpp
index 9b7f2c30f8..2104bff904 100644
--- a/writeengine/bulk/we_bulkload.cpp
+++ b/writeengine/bulk/we_bulkload.cpp
@@ -456,31 +456,43 @@ int BulkLoad::loadJobInfo(const string& fullName, bool bUseTempJobFile, int argc
 
 void BulkLoad::spawnWorkersParquet()
 {
+  int current_thread = 0;
+
   int tableId = -1;
 
-  try
+  // Loop to select and read the next table
+
+  while (true)
   {
-    // Loop to select and read the next table
+    tableId = -1;
 
-    while (true)
+    if ((tableId = lockTableForRead(current_thread)) == -1)
     {
-      tableId = -1;
-
-      if ((tableId = lockTableForRead(id)) == -1)
-      {
-        fLog.logMsg(
-          "BulkLoad::ReadOperation No more tables "
-          "available for processing. Read thread " +
-            Convertor::int2Str(id) + " exiting...",
-        MSGLVL_INFO2);
-        return;
-      }
-
-      // for every table, read parquet file
-      int rc = fTableInfo[tableId].readParquetData();
-      // TODO:
+      fLog.logMsg(
+        "BulkLoad::ReadOperation No more tables "
+        "available for processing. Read thread ",
+      MSGLVL_INFO2);
+      return;
     }
+
+    // for every table, read parquet file
+    int rc = fTableInfo[tableId].readParquetData();
+    // TODO:
+    if (rc == NO_ERROR)
+      break;
   }
+  // std::cout << "Reading first column of parquet-arrow-example.parquet" << std::endl;
+  // std::shared_ptr<arrow::io::ReadableFile> infile;
+  // PARQUET_ASSIGN_OR_THROW(infile,
+  //                         arrow::io::ReadableFile::Open("/tmp/parquet-arrow-example.parquet",
+  //                                                       arrow::default_memory_pool()));
+  // std::unique_ptr<parquet::arrow::FileReader> reader;
+  // PARQUET_THROW_NOT_OK(
+  //     parquet::arrow::OpenFile(infile, arrow::default_memory_pool(), &reader));
+  // std::shared_ptr<arrow::ChunkedArray> array;
+  // PARQUET_THROW_NOT_OK(reader->ReadColumn(1, &array));
+  // PARQUET_THROW_NOT_OK(arrow::PrettyPrint(*array, 4, &std::cout));
+  // std::cout << std::endl;
 }
 
 //------------------------------------------------------------------------------
@@ -872,7 +884,7 @@ int BulkLoad::preProcess(Job& job, int tableNo, TableInfo* tableInfo)
   }
 
   // Initialize BulkLoadBuffers after we have added all the columns
-  rc = tableInfo->(fNoOfBuffers, job.jobTableList[tableNo].fFldRefs, fixedBinaryRecLen);
+  rc = tableInfo->initializeBuffers(fNoOfBuffers, job.jobTableList[tableNo].fFldRefs, fixedBinaryRecLen);
   if (rc)
     return rc;
 
diff --git a/writeengine/bulk/we_bulkloadbuffer.cpp b/writeengine/bulk/we_bulkloadbuffer.cpp
index 9af6e8e236..ee8abd0597 100644
--- a/writeengine/bulk/we_bulkloadbuffer.cpp
+++ b/writeengine/bulk/we_bulkloadbuffer.cpp
@@ -45,6 +45,12 @@
 
 #include "utils_utf8.h"  // utf8_truncate_point()
 
+#include <arrow/api.h>
+#include <arrow/io/api.h>
+#include <parquet/arrow/reader.h>
+#include <parquet/arrow/writer.h>
+#include <parquet/exception.h>
+
 using namespace std;
 using namespace boost;
 using namespace execplan;
@@ -1522,6 +1528,96 @@ void BulkLoadBuffer::convert(char* field, int fieldLength, bool nullFlag, unsign
   memcpy(output, pVal, width);
 }
 
+
+int BulkLoadBuffer::parseParquet(ColumnInfo& columnInfo, int current_batch_size)
+{
+  int rc = NO_ERROR;
+  ColumnBufferSection* section = 0;
+  uint32_t nRowsParsed;
+  RID lastInputInExtent;
+  ColumnInfo &columnInfo = fColumns[k];
+  if (columnInfo.column.colType == COL_TYPE_DICT)
+  {
+    continue;
+  }
+  else
+  {
+    RETURN_ON_ERROR(columnInfo.fColBufferMgr->reserveSection(k*bs, current_batch_size, nRowsParsed, &section, lastInputInExtent));
+
+    if (nRowsParsed > 0)
+    {
+      unsigned char* buf = new unsigned char[current_batch_size * columnInfo.column.width];
+      char* field = new char[MAX_FIELD_SIZE + 1];
+
+      BLBufferStats bufStats(columnInfo.column.dataType);
+      std::shared_ptr<arrow::Array> columnData = batch->column(k);
+      int tokenLength = 0;
+      bool tokenNullFlag = false;
+      // How to know what data stored in this column
+      // It means how can I know what
+      if (columnInfo.column.weType == WR_CHAR)
+      {
+
+        auto binaryArray = std::static_pointer_cast<arrow::BinaryArray>(columnData);
+        // int value_len;
+        const uint8_t* dataPtr;
+        for (uint32_t i = 0; i < current_batch_size; i++)
+        {
+
+          if (columnData->IsNull(i))
+          {
+            field[0] = '\0';
+            // tokenLength = 0;
+            tokenNullFlag = true;
+          }
+          else
+          {
+            dataPtr = binaryArray->GetValue(i, &tokenLength);
+            memcpy(field, dataPtr, tokenLength);
+            field[tokenLength] = '\0';
+            // tokenLength
+          }
+
+          convert(field, tokenLength, tokenNullFlag, buf + i * columnInfo.column.width, columnInfo.column,
+                  bufStats);
+        }
+      }
+      else
+      {
+        const char* data_ptr = columnData->data()->GetValues<char>(1);
+        for (uint32_t i = 0; i < current_batch_size; i++)
+        {
+          if (columnData->IsNull(i))
+          {
+            field[0] = '\0';
+            tokenNullFlag = true;
+          }
+          else
+          {
+            memcpy(field, data_ptr + columnInfo.column.width * i, columnInfo.column.width);
+            field[columnInfo.column.width * i] = '\0';
+            tokenLength = columnInfo.column.width;
+            tokenNullFlag = false;
+          }
+
+          convert(field, tokenLength, tokenNullFlag, buf + i * columnInfo.column.width, columnInfo.column, 
+           bufStats)
+        }
+      }
+
+      delete[] field;
+      section->write(buf, current_batch_size);
+      delete[] buf;
+
+
+      RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section));
+    }
+  
+  }
+  return rc;
+
+}
+
 //------------------------------------------------------------------------------
 // Parse the contents of the Read buffer based on whether it is a dictionary
 // column or not.
diff --git a/writeengine/bulk/we_bulkloadbuffer.h b/writeengine/bulk/we_bulkloadbuffer.h
index 2abc40e635..b1f74444e4 100644
--- a/writeengine/bulk/we_bulkloadbuffer.h
+++ b/writeengine/bulk/we_bulkloadbuffer.h
@@ -289,6 +289,10 @@ class BulkLoadBuffer
    */
   int parse(ColumnInfo& columnInfo);
 
+  /** @brief Parse the parquet table data
+  */
+  int parseParquet(ColumnInfo& columnInfo, int current_batch_size);
+
   /** @brief Set the delimiter used to delimit the columns within a row
    */
   void setColDelimiter(const char& delim)
diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index 8d81ae635b..c168d93dd6 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -269,12 +269,13 @@ bool TableInfo::lockForRead(const int& locker)
 }
 
 
-
 int TableInfo::readParquetData()
 {
+  int rc = NO_ERROR;
   int fileCounter = 0;
   fFileName = fLoadFileList[fileCounter];
 
+  //---------------------------------------------------
   std::cout << "Reading by RecordBatchReader" << std::endl;
 
   arrow::MemoryPool* pool = arrow::default_memory_pool();
@@ -287,7 +288,8 @@ int TableInfo::readParquetData()
   // Configure Arrow-specific Parquet reader settings
   auto arrow_reader_props = parquet::ArrowReaderProperties();
   // TODO:batch_size is set as a parameter
-  arrow_reader_props.set_batch_size(64 * 1024);  // default 64 * 1024
+  int64_t bs = 10;
+  arrow_reader_props.set_batch_size(bs);  // default 64 * 1024
 
   parquet::arrow::FileReaderBuilder reader_builder;
   PARQUET_THROW_NOT_OK(
@@ -302,19 +304,25 @@ int TableInfo::readParquetData()
   PARQUET_THROW_NOT_OK(arrow_reader->GetRecordBatchReader(&rb_reader));
 
 
-  for (arrow::Result<std::shared_ptr<arrow::RecordBatch>> maybe_batch : *rb_reader) {
+  for (arrow::Result<std::shared_ptr<arrow::RecordBatch>> maybe_batch : *rb_reader)
+  {
     // Operate on each batch...
-    // TODO:
     PARQUET_ASSIGN_OR_THROW(auto batch, maybe_batch);
-    // PARQUET_ASSIGN_OR_THROW(auto table,
-    //                       arrow::Table::FromRecordBatches(batch->schema(), {batch}));
-    // std::cout << "Loaded " << table->num_rows() << " rows in " << table->num_columns()
-    //           << " columns." << std::endl;
-    // PARQUET_THROW_NOT_OK(arrow::PrettyPrint(*(batch->GetColumnByName("str")), 4, &std::cout));
-    std::cout << batch->ToString() << std::endl;
+    int current_batch_size = batch->num_rows();
+    // for every column in batch, parse it into ColumnBuffer
+
+    for (unsigned k = 0; k < fNumberOfColumns; k++)
+    {
+      // pass reference to my parseColumn func
+      fBuffers[0].parseParquet(fColumns[k], current_batch_size);
+
+      // TODO:setParseComplete
+    }
   }
+  return rc;
 }
 
+
 //------------------------------------------------------------------------------
 // Loop thru reading the import file(s) assigned to this TableInfo object.
 //------------------------------------------------------------------------------
@@ -718,6 +726,16 @@ int TableInfo::parseColumn(const int& columnId, const int& bufferId, double& pro
   return rc;
 }
 
+int TableInfo::parseColumnParquet(const int& columnId, double& processingTime)
+{
+  int rc = NO_ERROR;
+  timeval parseStart, parseEnd;
+  gettimeofday(&parseStart, NULL);
+
+
+  return rc;
+}
+
 //------------------------------------------------------------------------------
 // Mark the specified column (columnId) in the specified buffer (bufferId) as
 // PARSE_COMPLETE.  If this is the last column to be parsed for this buffer,
diff --git a/writeengine/bulk/we_tableinfo.h b/writeengine/bulk/we_tableinfo.h
index d67c928cee..512ccee3ab 100644
--- a/writeengine/bulk/we_tableinfo.h
+++ b/writeengine/bulk/we_tableinfo.h
@@ -373,10 +373,10 @@ class TableInfo : public WeUIDGID
    */
   int readTableData();
 
-  /** @brief Read parquet file data
-  */
+  /** @brief Read the parquet file data into the memory
+   */
   int readParquetData();
-  
+ 
   /** @brief parse method
    */
   int parseColumn(const int& columnId, const int& bufferId, double& processingTime);

From 2840aea55ea43ba7de8b34c78e9332f02be794f2 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Fri, 30 Jun 2023 23:00:54 +0800
Subject: [PATCH 05/15] support int datatype to finish whole process

---
 writeengine/bulk/we_bulkload.cpp       |  56 ++--
 writeengine/bulk/we_bulkloadbuffer.cpp |  89 -----
 writeengine/bulk/we_bulkloadbuffer.h   |   4 -
 writeengine/bulk/we_tableinfo.cpp      | 447 ++++++++++++++++++++++++-
 writeengine/bulk/we_tableinfo.h        |  26 ++
 5 files changed, 483 insertions(+), 139 deletions(-)

diff --git a/writeengine/bulk/we_bulkload.cpp b/writeengine/bulk/we_bulkload.cpp
index 2104bff904..4cc3685cf3 100644
--- a/writeengine/bulk/we_bulkload.cpp
+++ b/writeengine/bulk/we_bulkload.cpp
@@ -456,43 +456,33 @@ int BulkLoad::loadJobInfo(const string& fullName, bool bUseTempJobFile, int argc
 
 void BulkLoad::spawnWorkersParquet()
 {
-  int current_thread = 0;
+  // int current_thread = 0;
 
-  int tableId = -1;
+  int tableId = 0;
 
   // Loop to select and read the next table
 
-  while (true)
-  {
-    tableId = -1;
-
-    if ((tableId = lockTableForRead(current_thread)) == -1)
-    {
-      fLog.logMsg(
-        "BulkLoad::ReadOperation No more tables "
-        "available for processing. Read thread ",
-      MSGLVL_INFO2);
-      return;
-    }
-
-    // for every table, read parquet file
-    int rc = fTableInfo[tableId].readParquetData();
-    // TODO:
-    if (rc == NO_ERROR)
-      break;
-  }
-  // std::cout << "Reading first column of parquet-arrow-example.parquet" << std::endl;
-  // std::shared_ptr<arrow::io::ReadableFile> infile;
-  // PARQUET_ASSIGN_OR_THROW(infile,
-  //                         arrow::io::ReadableFile::Open("/tmp/parquet-arrow-example.parquet",
-  //                                                       arrow::default_memory_pool()));
-  // std::unique_ptr<parquet::arrow::FileReader> reader;
-  // PARQUET_THROW_NOT_OK(
-  //     parquet::arrow::OpenFile(infile, arrow::default_memory_pool(), &reader));
-  // std::shared_ptr<arrow::ChunkedArray> array;
-  // PARQUET_THROW_NOT_OK(reader->ReadColumn(1, &array));
-  // PARQUET_THROW_NOT_OK(arrow::PrettyPrint(*array, 4, &std::cout));
-  // std::cout << std::endl;
+  // while (true)
+  // {
+  //   tableId = 0;
+
+  //   // if ((tableId = lockTableForRead(current_thread)) == -1)
+  //   // {
+  //   //   fLog.logMsg(
+  //   //     "BulkLoad::ReadOperation No more tables "
+  //   //     "available for processing. Read thread ",
+  //   //   MSGLVL_INFO2);
+  //   //   return;
+  //   // }
+
+  //   // for every table, read parquet file
+  //   int rc = fTableInfo[tableId].readParquetData();
+  //   if (rc == NO_ERROR)
+  //     break;
+  // }
+  int rc = fTableInfo[tableId].readParquetData();
+  std::cout << rc << std::endl;
+  std::cout << "it's all done" << std::endl;
 }
 
 //------------------------------------------------------------------------------
diff --git a/writeengine/bulk/we_bulkloadbuffer.cpp b/writeengine/bulk/we_bulkloadbuffer.cpp
index ee8abd0597..69495483b7 100644
--- a/writeengine/bulk/we_bulkloadbuffer.cpp
+++ b/writeengine/bulk/we_bulkloadbuffer.cpp
@@ -1529,95 +1529,6 @@ void BulkLoadBuffer::convert(char* field, int fieldLength, bool nullFlag, unsign
 }
 
 
-int BulkLoadBuffer::parseParquet(ColumnInfo& columnInfo, int current_batch_size)
-{
-  int rc = NO_ERROR;
-  ColumnBufferSection* section = 0;
-  uint32_t nRowsParsed;
-  RID lastInputInExtent;
-  ColumnInfo &columnInfo = fColumns[k];
-  if (columnInfo.column.colType == COL_TYPE_DICT)
-  {
-    continue;
-  }
-  else
-  {
-    RETURN_ON_ERROR(columnInfo.fColBufferMgr->reserveSection(k*bs, current_batch_size, nRowsParsed, &section, lastInputInExtent));
-
-    if (nRowsParsed > 0)
-    {
-      unsigned char* buf = new unsigned char[current_batch_size * columnInfo.column.width];
-      char* field = new char[MAX_FIELD_SIZE + 1];
-
-      BLBufferStats bufStats(columnInfo.column.dataType);
-      std::shared_ptr<arrow::Array> columnData = batch->column(k);
-      int tokenLength = 0;
-      bool tokenNullFlag = false;
-      // How to know what data stored in this column
-      // It means how can I know what
-      if (columnInfo.column.weType == WR_CHAR)
-      {
-
-        auto binaryArray = std::static_pointer_cast<arrow::BinaryArray>(columnData);
-        // int value_len;
-        const uint8_t* dataPtr;
-        for (uint32_t i = 0; i < current_batch_size; i++)
-        {
-
-          if (columnData->IsNull(i))
-          {
-            field[0] = '\0';
-            // tokenLength = 0;
-            tokenNullFlag = true;
-          }
-          else
-          {
-            dataPtr = binaryArray->GetValue(i, &tokenLength);
-            memcpy(field, dataPtr, tokenLength);
-            field[tokenLength] = '\0';
-            // tokenLength
-          }
-
-          convert(field, tokenLength, tokenNullFlag, buf + i * columnInfo.column.width, columnInfo.column,
-                  bufStats);
-        }
-      }
-      else
-      {
-        const char* data_ptr = columnData->data()->GetValues<char>(1);
-        for (uint32_t i = 0; i < current_batch_size; i++)
-        {
-          if (columnData->IsNull(i))
-          {
-            field[0] = '\0';
-            tokenNullFlag = true;
-          }
-          else
-          {
-            memcpy(field, data_ptr + columnInfo.column.width * i, columnInfo.column.width);
-            field[columnInfo.column.width * i] = '\0';
-            tokenLength = columnInfo.column.width;
-            tokenNullFlag = false;
-          }
-
-          convert(field, tokenLength, tokenNullFlag, buf + i * columnInfo.column.width, columnInfo.column, 
-           bufStats)
-        }
-      }
-
-      delete[] field;
-      section->write(buf, current_batch_size);
-      delete[] buf;
-
-
-      RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section));
-    }
-  
-  }
-  return rc;
-
-}
-
 //------------------------------------------------------------------------------
 // Parse the contents of the Read buffer based on whether it is a dictionary
 // column or not.
diff --git a/writeengine/bulk/we_bulkloadbuffer.h b/writeengine/bulk/we_bulkloadbuffer.h
index b1f74444e4..2abc40e635 100644
--- a/writeengine/bulk/we_bulkloadbuffer.h
+++ b/writeengine/bulk/we_bulkloadbuffer.h
@@ -289,10 +289,6 @@ class BulkLoadBuffer
    */
   int parse(ColumnInfo& columnInfo);
 
-  /** @brief Parse the parquet table data
-  */
-  int parseParquet(ColumnInfo& columnInfo, int current_batch_size);
-
   /** @brief Set the delimiter used to delimit the columns within a row
    */
   void setColDelimiter(const char& delim)
diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index c168d93dd6..cefa487a12 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -269,10 +269,61 @@ bool TableInfo::lockForRead(const int& locker)
 }
 
 
+// int TableInfo::parseParquetCol(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, int bs)
+// {
+//   int rc = NO_ERROR;
+//   ColumnBufferSection* section = 0;
+//   uint32_t nRowsParsed;
+//   RID lastInputRowInExtent;
+//   ColumnInfo& columnInfo = fColumns[k];
+//   RETURN_ON_ERROR(columnInfo.fColBufferMgr->reserveSection(10 * k, bs, nRowsParsed,
+//                   &section, lastInputRowInExtent));
+  
+
+//   if (nRowsParsed > 0)
+//   {
+//     unsigned char* buf = new unsigned char[bs * columnInfo.column.width];
+
+//     std::shared_ptr<arrow::Array> columnData = batch->column(k);
+    
+//   }
+//   return rc;
+// }
+
+
+// int TableInfo::parseParquetDict(unsigned int k, int bs)
+// {
+//   int rc = NO_ERROR;
+
+
+//   return rc;
+// }
+
+// int TableInfo::parseParquet(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, int bs)
+// {
+//   int rc = NO_ERROR;
+//   ColumnBufferSection* section = 0;
+//   uint32_t nRowsParsed;
+//   RID lastInputExtent;
+//   // ColumnInfo& columnInfo = fColumns[k];
+
+//   if (columnInfo.column.colType == COL_TYPE_DICT)
+//   {
+//     rc = parseParquetDict(k, bs);
+//   }
+//   else
+//   {
+//     rc = parseParquetCol(batch, k, bs);
+//   }
+
+// }
+
+
 int TableInfo::readParquetData()
 {
   int rc = NO_ERROR;
   int fileCounter = 0;
+  // read first file temporarily
   fFileName = fLoadFileList[fileCounter];
 
   //---------------------------------------------------
@@ -303,22 +354,392 @@ int TableInfo::readParquetData()
   std::shared_ptr<::arrow::RecordBatchReader> rb_reader;
   PARQUET_THROW_NOT_OK(arrow_reader->GetRecordBatchReader(&rb_reader));
 
-
+  int batch_processed = 0;
   for (arrow::Result<std::shared_ptr<arrow::RecordBatch>> maybe_batch : *rb_reader)
   {
     // Operate on each batch...
     PARQUET_ASSIGN_OR_THROW(auto batch, maybe_batch);
-    int current_batch_size = batch->num_rows();
+    unsigned int current_batch_size = batch->num_rows();
     // for every column in batch, parse it into ColumnBuffer
+    
+    // fNumberOfColumns-1 because there is a special column named aux which is internal column
+    // And later `aux` should be processed individually
 
-    for (unsigned k = 0; k < fNumberOfColumns; k++)
+    for (unsigned k = 0; k < fNumberOfColumns-1; k++)
     {
-      // pass reference to my parseColumn func
-      fBuffers[0].parseParquet(fColumns[k], current_batch_size);
+      // parseParquet(batch, k, current_batch_size);
+      if (fColumns[k].column.colType == COL_TYPE_DICT)
+      {
+        // rc = parseParquetDict(k, bs);
+        continue;
+      }
+      else
+      {
+          // rc = parseParquetCol(batch, k, bs);
+        // int rc = NO_ERROR;
+        ColumnBufferSection* section = 0;
+        uint32_t nRowsParsed;
+        RID lastInputRowInExtent;
+        ColumnInfo& columnInfo = fColumns[k];
+        RETURN_ON_ERROR(columnInfo.fColBufferMgr->reserveSection(bs * batch_processed, current_batch_size, nRowsParsed,
+                        &section, lastInputRowInExtent));
+        if (nRowsParsed > 0)
+        {
+          unsigned char* buf = new unsigned char[current_batch_size * columnInfo.column.width];
+
+          BLBufferStats bufStats(columnInfo.column.dataType);
+          bool updateCPInfoPendingFlag = false;
+          std::shared_ptr<arrow::Array> columnData = batch->column(k);
+          // get current column data type
+          // arrow::Type::type colType = columnData->type()->id();
+          // only consider `int` type now 
+          const char* data_ptr = columnData->data()->GetValues<char>(1);
+          for (uint32_t i = 0; i < current_batch_size; i++)
+          {
+            unsigned char* p = buf + i * columnInfo.column.width;
+            void *t;
+            long long origVal;
+            int32_t iVal;
+            bool bSatVal = false;
+            if (columnData->IsNull(i))
+            {
+              if (columnInfo.column.fWithDefault)
+              {
+                origVal = columnInfo.column.fDefaultInt;
+              }
+              else
+              {
+                iVal = joblist::INTNULL;
+              }
+            }
+            else
+            {
+              memcpy(&iVal, data_ptr + 4*i, 4);
+              origVal = (long long)iVal;
+            }
+
+            // Saturate the value
+            if (origVal < columnInfo.column.fMinIntSat)
+            {
+              origVal = columnInfo.column.fMinIntSat;
+              bSatVal = true;
+            }
+            else if (origVal > static_cast<int64_t>(columnInfo.column.fMaxIntSat))
+            {
+              origVal = static_cast<int64_t>(columnInfo.column.fMaxIntSat);
+              bSatVal = true;
+            }
+            if (bSatVal)
+              bufStats.satCount++;
+
+            if (origVal < bufStats.minBufferVal)
+              bufStats.minBufferVal = origVal;
+
+            if (origVal > bufStats.maxBufferVal)
+              bufStats.maxBufferVal = origVal;
+            t = &iVal;
+            memcpy(p, t, 4);
+
+            updateCPInfoPendingFlag = true;
+
+            if ((RID)(bs * batch_processed + i) == lastInputRowInExtent)
+            {
+              if (columnInfo.column.width <= 8)
+              {
+                columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.minBufferVal, bufStats.maxBufferVal,
+                                        columnInfo.column.dataType, columnInfo.column.width);
+              }
+              else
+              {
+                columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.bigMinBufferVal, bufStats.bigMaxBufferVal,
+                                        columnInfo.column.dataType, columnInfo.column.width);
+              }
+
+              // what's this rowsPerExtent for?
+              lastInputRowInExtent += columnInfo.rowsPerExtent();
+
+              if (isUnsigned(columnInfo.column.dataType))
+              {
+                if (columnInfo.column.width <= 8)
+                {
+                  bufStats.minBufferVal = static_cast<int64_t>(MAX_UBIGINT);
+                  bufStats.maxBufferVal = static_cast<int64_t>(MIN_UBIGINT);
+                }
+                else
+                {
+                  bufStats.bigMinBufferVal = -1;
+                  bufStats.bigMaxBufferVal = 0;
+                }
+                updateCPInfoPendingFlag = false;
+              }
+              else
+              {
+                if (columnInfo.column.width <= 8)
+                {
+                  bufStats.minBufferVal = MAX_BIGINT;
+                  bufStats.maxBufferVal = MIN_BIGINT;
+                }
+                else
+                {
+                  utils::int128Max(bufStats.bigMinBufferVal);
+                  utils::int128Min(bufStats.bigMaxBufferVal);
+                }
+                updateCPInfoPendingFlag = false;
+              }
+            }
+
+          }
+
+          if (updateCPInfoPendingFlag)
+          {
+            if (columnInfo.column.width <= 8)
+            {
+              columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.minBufferVal, bufStats.maxBufferVal,
+                                      columnInfo.column.dataType, columnInfo.column.width);
+            }
+            else
+            {
+              columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.bigMinBufferVal, bufStats.bigMaxBufferVal,
+                                      columnInfo.column.dataType, columnInfo.column.width);
+            }
+          }
+
+          if (bufStats.satCount)
+          {
+            columnInfo.incSaturatedCnt(bufStats.satCount);
+          }
 
-      // TODO:setParseComplete
+          section->write(buf, current_batch_size);
+          delete[] buf;
+
+          RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section))
+
+        }
+        // return rc;
+      }
     }
+
+    // process `aux` column
+    ColumnInfo& columnInfo = fColumns[fNumberOfColumns-1];
+    ColumnBufferSection* section = 0;
+    uint32_t nRowsParsed;
+    RID lastInputRowInExtent;
+    // ColumnInfo& columnInfo = fColumns[k];
+    RETURN_ON_ERROR(columnInfo.fColBufferMgr->reserveSection(bs * batch_processed, current_batch_size, nRowsParsed,
+                    &section, lastInputRowInExtent));
+    if (nRowsParsed > 0)
+    {
+      unsigned char* buf = new unsigned char[current_batch_size * columnInfo.column.width];
+
+      BLBufferStats bufStats(columnInfo.column.dataType);
+      bool updateCPInfoPendingFlag = false;
+
+      // std::shared_ptr<arrow::Array> columnData = batch->column(k);
+      // get current column data type
+      // arrow::Type::type colType = columnData->type()->id();
+      // only consider `int` type now 
+      // const char* data_ptr = columnData->data()->GetValues<char>(1);
+      for (uint32_t i = 0; i < current_batch_size; i++)
+      {
+        unsigned char* p = buf + i * columnInfo.column.width;
+        void *t;
+        int64_t origVal;
+        // int32_t iVal;
+        bool bSatVal = false;
+        origVal = static_cast<int64_t>(columnInfo.column.fDefaultUInt);
+        // Saturate the value
+        if (origVal < columnInfo.column.fMinIntSat)
+        {
+          origVal = columnInfo.column.fMinIntSat;
+          bSatVal = true;
+        }
+        else if (origVal > static_cast<int64_t>(columnInfo.column.fMaxIntSat))
+        {
+          origVal = static_cast<int64_t>(columnInfo.column.fMaxIntSat);
+          bSatVal = true;
+        }
+        if (bSatVal)
+          bufStats.satCount++;
+        uint64_t uVal = origVal;
+
+        if (uVal < static_cast<uint64_t>(bufStats.minBufferVal))
+          bufStats.minBufferVal = origVal;
+
+        if (uVal > static_cast<uint64_t>(bufStats.maxBufferVal))
+          bufStats.maxBufferVal = origVal;
+        
+        uint8_t ubiVal = origVal;
+        t = &ubiVal;
+        memcpy(p, t, 1);
+
+        updateCPInfoPendingFlag = true;
+
+        if ((RID)(bs * batch_processed + i) == lastInputRowInExtent)
+        {
+          if (columnInfo.column.width <= 8)
+          {
+            columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.minBufferVal, bufStats.maxBufferVal,
+                                    columnInfo.column.dataType, columnInfo.column.width);
+          }
+          else
+          {
+            columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.bigMinBufferVal, bufStats.bigMaxBufferVal,
+                                    columnInfo.column.dataType, columnInfo.column.width);
+          }
+
+          // what's this rowsPerExtent for?
+          lastInputRowInExtent += columnInfo.rowsPerExtent();
+
+          if (isUnsigned(columnInfo.column.dataType))
+          {
+            if (columnInfo.column.width <= 8)
+            {
+              bufStats.minBufferVal = static_cast<int64_t>(MAX_UBIGINT);
+              bufStats.maxBufferVal = static_cast<int64_t>(MIN_UBIGINT);
+            }
+            else
+            {
+              bufStats.bigMinBufferVal = -1;
+              bufStats.bigMaxBufferVal = 0;
+            }
+            updateCPInfoPendingFlag = false;
+          }
+          else
+          {
+            if (columnInfo.column.width <= 8)
+            {
+              bufStats.minBufferVal = MAX_BIGINT;
+              bufStats.maxBufferVal = MIN_BIGINT;
+            }
+            else
+            {
+              utils::int128Max(bufStats.bigMinBufferVal);
+              utils::int128Min(bufStats.bigMaxBufferVal);
+            }
+            updateCPInfoPendingFlag = false;
+          }
+        }
+
+
+      }
+
+      if (updateCPInfoPendingFlag)
+      {
+        if (columnInfo.column.width <= 8)
+        {
+          columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.minBufferVal, bufStats.maxBufferVal,
+                                  columnInfo.column.dataType, columnInfo.column.width);
+        }
+        else
+        {
+          columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.bigMinBufferVal, bufStats.bigMaxBufferVal,
+                                  columnInfo.column.dataType, columnInfo.column.width);
+        }
+      }
+
+      if (bufStats.satCount)
+      {
+        columnInfo.incSaturatedCnt(bufStats.satCount);
+      }
+
+      section->write(buf, current_batch_size);
+      delete[] buf;
+
+      RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section))
+
+    }
+
+
+
+
+    batch_processed++;
+  }
+
+  // TODO:setParseComplete
+  // After all the data has been parsed
+  // Accumulate list of HWM dictionary blocks to be flushed from cache
+  for (unsigned k = 0; k < fNumberOfColumns; k++)
+  {
+    std::vector<BRM::LBID_t> dictBlksToFlush;
+    fColumns[k].getDictFlushBlks(dictBlksToFlush);
+
+    for (unsigned kk = 0; kk < dictBlksToFlush.size(); kk++)
+    {
+      fDictFlushBlks.push_back(dictBlksToFlush[kk]);
+    }
+
+    int rc = fColumns[k].finishParsing();
+    if (rc != NO_ERROR)
+    {
+      return rc;
+    }
+  }
+
+  if (!idbdatafile::IDBPolicy::useHdfs())
+  {
+    if (fDictFlushBlks.size() > 0)
+    {
+      cacheutils::flushPrimProcAllverBlocks(fDictFlushBlks);
+      fDictFlushBlks.clear();
+    }
+  }
+  
+  rc = synchronizeAutoInc();
+  if (rc != NO_ERROR)
+  {
+    return rc;
+  }
+
+  std::vector<DBRootExtentInfo> segFileInfo;
+  for (unsigned i = 0; i < fColumns.size(); i++)
+  {
+    DBRootExtentInfo extentInfo;
+    fColumns[i].getSegFileInfo(extentInfo);
+    segFileInfo.push_back(extentInfo);
   }
+
+
+  rc = validateColumnHWMs(0, segFileInfo, "Ending");
+
+  if (rc != NO_ERROR)
+  {
+    return rc;
+  }
+
+  rc = confirmDBFileChanges();
+
+  if (rc != NO_ERROR)
+  {
+    return rc;
+  }
+
+  rc = finishBRM();
+  if (rc != NO_ERROR)
+  {
+    return rc;
+  }
+
+  rc = changeTableLockState();
+
+  if (rc != NO_ERROR)
+  {
+    return rc;
+  }
+
+  deleteTempDBFileChanges();
+  deleteMetaDataRollbackFile();
+
+  rc = releaseTableLock();
+
+  if (rc != NO_ERROR)
+  {
+    return rc;
+  }
+
+  fStatusTI = WriteEngine::PARSE_COMPLETE;
+
+  freeProcessingBuffers();
+
   return rc;
 }
 
@@ -726,15 +1147,15 @@ int TableInfo::parseColumn(const int& columnId, const int& bufferId, double& pro
   return rc;
 }
 
-int TableInfo::parseColumnParquet(const int& columnId, double& processingTime)
-{
-  int rc = NO_ERROR;
-  timeval parseStart, parseEnd;
-  gettimeofday(&parseStart, NULL);
+// int TableInfo::parseColumnParquet(const int& columnId, double& processingTime)
+// {
+//   int rc = NO_ERROR;
+//   timeval parseStart, parseEnd;
+//   gettimeofday(&parseStart, NULL);
 
 
-  return rc;
-}
+//   return rc;
+// }
 
 //------------------------------------------------------------------------------
 // Mark the specified column (columnId) in the specified buffer (bufferId) as
diff --git a/writeengine/bulk/we_tableinfo.h b/writeengine/bulk/we_tableinfo.h
index 512ccee3ab..c5630c77a3 100644
--- a/writeengine/bulk/we_tableinfo.h
+++ b/writeengine/bulk/we_tableinfo.h
@@ -30,6 +30,16 @@
 #include <boost/ptr_container/ptr_vector.hpp>
 #include <boost/uuid/uuid.hpp>
 
+#include <arrow/api.h>
+#include <arrow/io/api.h>
+#include <parquet/arrow/reader.h>
+#include <parquet/arrow/writer.h>
+#include <parquet/exception.h>
+#include <arrow/result.h>
+#include <arrow/status.h>
+#include <arrow/io/file.h>
+#include <parquet/stream_reader.h>
+
 #include <libmarias3/marias3.h>
 
 #include "we_type.h"
@@ -373,6 +383,18 @@ class TableInfo : public WeUIDGID
    */
   int readTableData();
 
+  // /** @brief parse parquet data
+  // */
+  // int parseParquetCol(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, int bs);
+
+  // /** @brief parse parquet data
+  // */
+  // int parseParquetDict(unsigned int k, int bs);
+
+  // /** @brief parse parquet data
+  // */
+  // int parseParquet(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, int bs);
+
   /** @brief Read the parquet file data into the memory
    */
   int readParquetData();
@@ -381,6 +403,10 @@ class TableInfo : public WeUIDGID
    */
   int parseColumn(const int& columnId, const int& bufferId, double& processingTime);
 
+  /** @brief update the buffer status for column(parquet)
+  */
+  int setParseCompleteParquet();
+
   /** @brief update the buffer status for column
    */
   int setParseComplete(const int& columnId, const int& bufferId, double processingTime);

From 385092e78299e2b71d5e64268fbf5946dbdf5ba6 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Sun, 2 Jul 2023 22:33:58 +0800
Subject: [PATCH 06/15] add support for
 float,double,char,short,ushort,byte,ubyte

---
 utils/dataconvert/dataconvert.cpp | 110 +++++
 utils/dataconvert/dataconvert.h   |   7 +
 writeengine/bulk/we_tableinfo.cpp | 644 ++++++++++++++++++++++++++++++
 writeengine/bulk/we_tableinfo.h   |   2 +
 4 files changed, 763 insertions(+)

diff --git a/utils/dataconvert/dataconvert.cpp b/utils/dataconvert/dataconvert.cpp
index fefca375f8..5e2a327be4 100644
--- a/utils/dataconvert/dataconvert.cpp
+++ b/utils/dataconvert/dataconvert.cpp
@@ -2003,6 +2003,116 @@ int64_t DataConvert::convertColumnTimestamp(const char* dataOrg, CalpontDateTime
   return value;
 }
 
+
+int64_t DataConvert::convertArrowColumnTime32(int32_t timeVal)
+{
+  int64_t value = 0;
+  // convert millisecond to time
+  int inHour, inMinute, inSecond, inMicrosecond;
+  inHour = inMinute = inSecond = inMicrosecond = 0;
+  bool isNeg = false;
+  if (timeVal < 0)
+    isNeg = true;
+  inHour = timeVal / 3600000;
+  // inHour %= 24;
+  inMinute = (timeVal - inHour * 3600000) / 60000;
+  // inMinute %= 60;
+  inSecond = (timeVal - inHour * 3600000 - inMinute * 60000) / 1000;
+  // inSecond %= 60;
+  inMicrosecond = (timeVal - inHour * 360000 - inMinute * 60000 - inSecond * 1000) * 1000;
+  if (isTimeValid(inHour, inMinute, inSecond, inMicrosecond))
+  {
+    Time atime;
+    atime.hour = inHour;
+    atime.minute = inMinute;
+    atime.second = inSecond;
+    atime.msecond = inMicrosecond;
+    atime.is_neg = isNeg;
+
+    memcpy(&value, &atime, 8);
+  }
+  else
+  {
+    // Emulate MariaDB's time saturation
+    if (inHour > 838)
+    {
+      Time atime;
+      atime.hour = 838;
+      atime.minute = 59;
+      atime.second = 59;
+      atime.msecond = 999999;
+      atime.is_neg = false;
+      memcpy(&value, &atime, 8);
+    }
+    else if (inHour < -838)
+    {
+      Time atime;
+      atime.hour = -838;
+      atime.minute = 59;
+      atime.second = 59;
+      atime.msecond = 999999;
+      atime.is_neg = false;
+      memcpy(&value, &atime, 8);
+    }
+  }
+  return value;
+}
+
+int64_t DataConvert::convertArrowColumnTime64(int64_t timeVal)
+{
+  int64_t value = 0;
+  // convert macrosecond to time
+  int inHour, inMinute, inSecond, inMicrosecond;
+  inHour = inMinute = inSecond = inMicrosecond = 0;
+  bool isNeg = false;
+  if (timeVal < 0)
+    isNeg = true;
+  inHour = timeVal / 3600000000;
+  // inHour %= 24;
+  inMinute = (timeVal - inHour * 3600000000) / 60000000;
+  // inMinute %= 60;
+  inSecond = (timeVal - inHour * 3600000000 - inMinute * 60000000) / 1000000;
+  // inSecond %= 60;
+  inMicrosecond = timeVal - inHour * 360000000 - inMinute * 60000000 - inSecond * 1000000;
+  if (isTimeValid(inHour, inMinute, inSecond, inMicrosecond))
+  {
+    Time atime;
+    atime.hour = inHour;
+    atime.minute = inMinute;
+    atime.second = inSecond;
+    atime.msecond = inMicrosecond;
+    atime.is_neg = isNeg;
+
+    memcpy(&value, &atime, 8);
+  }
+  else
+  {
+    // Emulate MariaDB's time saturation
+    if (inHour > 838)
+    {
+      Time atime;
+      atime.hour = 838;
+      atime.minute = 59;
+      atime.second = 59;
+      atime.msecond = 999999;
+      atime.is_neg = false;
+      memcpy(&value, &atime, 8);
+    }
+    else if (inHour < -838)
+    {
+      Time atime;
+      atime.hour = -838;
+      atime.minute = 59;
+      atime.second = 59;
+      atime.msecond = 999999;
+      atime.is_neg = false;
+      memcpy(&value, &atime, 8);
+    }
+  }
+  return value;
+}
+
+
 //------------------------------------------------------------------------------
 // Convert time string to binary time.  Used by BulkLoad.
 // Most of this is taken from str_to_time in sql-common/my_time.c
diff --git a/utils/dataconvert/dataconvert.h b/utils/dataconvert/dataconvert.h
index bddcb6d2ac..50c7536ab7 100644
--- a/utils/dataconvert/dataconvert.h
+++ b/utils/dataconvert/dataconvert.h
@@ -1228,6 +1228,13 @@ class DataConvert
   EXPORT static int64_t convertColumnTime(const char* dataOrg, CalpontDateTimeFormat datetimeFormat,
                                           int& status, unsigned int dataOrgLen);
 
+
+  EXPORT static int64_t convertArrowColumnTime32(int32_t timeVal);
+
+  EXPORT static int64_t convertArrowColumnTime64(int64_t timeVal);
+
+
+
   /**
    * @brief Is specified datetime valid; used by binary bulk load
    */
diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index cefa487a12..33bd1fba5e 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -64,6 +64,8 @@ using namespace querytele;
 #include <arrow/status.h>
 #include <arrow/io/file.h>
 #include <parquet/stream_reader.h>
+using namespace execplan;
+
 namespace
 {
 const std::string BAD_FILE_SUFFIX = ".bad";  // Reject data file suffix
@@ -319,6 +321,639 @@ bool TableInfo::lockForRead(const int& locker)
 // }
 
 
+void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, int cbs)
+{
+  char biVal;
+  int iVal;
+  float fVal;
+  double dVal;
+  short siVal;
+  void* pVal;
+  int32_t iDate;
+  char charTmpBuf[MAX_COLUMN_BOUNDARY + 1] = {0};
+  long long llVal = 0, llDate = 0;
+  int128_t bigllVal = 0;
+  uint64_t tmp64;
+  uint32_t tmp32;
+  uint8_t ubiVal;
+  uint16_t usiVal;
+  uint32_t uiVal;
+  uint64_t ullVal;
+
+  int width = column.width;
+  switch (column.weType)
+  {
+    case WriteEngine::WR_FLOAT:
+    {
+      const float* dataPtr = columnData->data()->GetValues<float>(1);
+      for (uint32_t i = 0; i < cbs; i++)
+      {
+        void* p = buf + i * width;
+        if (columnData->IsNull(i))
+        {
+          if (column.fWithDefault)
+          {
+            fVal = column.fDefaultDbl;
+            pVal = &fVal;
+          }
+          else
+          {
+            tmp32 = joblist::FLOATNULL;
+            pVal = &tmp32;
+          }
+        }
+        else
+        {
+          float minFltSat = column.fMinDblSat;
+          float maxFltSat = column.fMaxDblSat;
+          memcpy(&fVal, dataPtr + i, width);
+          if (fVal > maxFltSat)
+          {
+            fVal = maxFltSat;
+            bufStats.satCount++;
+          }
+          else if (fVal < minFltSat)
+          {
+            fVal = minFltSat;
+            bufStats.satCount++;
+          }
+          pVal = &fVal;
+        }
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+
+    case WriteEngine::WR_DOUBLE:
+    {
+      const double* dataPtr = columnData->data()->GetValues<double>(1);
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        void* p = buf + i * width;
+        if (columnData->IsNull(i))
+        {
+          if (column.fWithDefault)
+          {
+            dVal = column.fDefaultDbl;
+            pVal = &dVal;
+          }
+          else
+          {
+            tmp64 = joblist::DOUBLENULL;
+            pVal = &tmp64;
+          }
+        }
+        else
+        {
+          memcpy(&dVal, dataPtr + i, width);
+        }
+        if (dVal > column.fMaxDblSat)
+        {
+          dVal = column.fMaxDblSat;
+          bufStats.satCount++;
+        }
+        else if (dVal < column.fMinDblSat)
+        {
+          dVal = column.fMinDblSat;
+          bufStats.satCount++;
+        }
+        pVal = &dVal;
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+
+    case WriteEngine::WR_CHAR:
+    {
+      auto binaryArray = std::static_pointer_cast<arrow::BinaryArray>(columnData);
+      int tokenLen;
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        void* p = buf + width * i;
+        if (columnData->IsNull(i))
+        {
+          if (column.fWithDefault)
+          {
+            int defLen = column.fDefaultChr.size();
+            const char* defData = column.fDefaultChr.c_str();
+            if (defLen > column.definedWidth)
+              memcpy(charTmpBuf, defData, column.definedWidth);
+            else
+              memcpy(charTmpBuf, defData, defLen);
+          }
+          else
+          {
+            idbassert(width <= 8);
+            for (j = 0; j < width - 1; j++)
+            {
+              charTmpBuf[j] = '\377';
+            }
+            charTmpBuf[width - 1] = '\376';
+            pVal = charTmpBuf;
+            // break;
+          }
+        }
+        else
+        {
+          const uint8_t* dataPtr = binaryArray->GetValue(i, &tokenLen);
+          if (tokenLen > column.definedWidth)
+          {
+            uint8_t truncate_point = utf8::utf8_truncate_point(field, column.definedWidth);
+            memcpy(charTmpBuf, dataPtr, column.definedWidth - truncate_point);
+            bufStats.satCount++;
+          }
+          else
+          {
+            memcpy(charTmpBuf, dataPtr, tokenLen);
+          }
+        }
+
+        uint64_t compChar = uint64ToStr(*(reinterpret_cast<uint64_t*>(charTmpBuf)));
+        int64_t binChar = static_cast<int64_t>(compChar);
+
+        // Update min/max range
+        uint64_t minVal = static_cast<uint64_t>(bufStats.minBufferVal);
+        uint64_t maxVal = static_cast<uint64_t>(bufStats.maxBufferVal);
+
+        if (compChar < minVal)
+          bufStats.minBufferVal = binChar;
+        if (compChar > maxVal)
+          bufStats.maxBufferVal = binChar;
+
+        pVal = charTmpBuf;
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+
+    case WriteEngine::WR_SHORT:
+    {
+      long long origVal;
+      // use char type here
+      const short* dataPtr = columnData->data()->GetValues<short>(1);
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        bool bSatVal = false;
+        void* p = buf + i * width;
+        if (columnData->IsNull(i))
+        {
+          if (!column.autoIncFlag)
+          {
+            if (column.fWithDefault)
+            {
+              origVal = column.fDefaultInt;
+            }
+            else
+            {
+              siVal = joblist::SMALLINTNULL;
+              pVal = &siVal;
+              // to jump to next loop
+              continue;
+            }
+          }
+          else
+          {
+            // FIXME: no fAutoIncNextValue in tableInfo
+            // fill 1 temporarily
+            // origVal = tAutoIncNextValue++;
+            origVal = 1;
+          }
+        }
+        else
+        {
+          memcpy(&siVal, dataPtr + i, width);
+          origVal = siVal;
+        }
+
+        if (origVal < column.fMinIntSat)
+        {
+          origVal = column.fMinIntSat;
+          bSatVal = true;
+        }
+        else if (origVal > static_cast<int64_t>(column.fMaxIntSat))
+        {
+          origVal = static_cast<int64_t>(column.fMaxIntSat);
+          bSatVal = true;
+        }
+
+        if (bSatVal)
+          bufStats.satCount++;
+
+        if (origVal < bufStats.minBufferVal)
+          bufStats.minBufferVal = origVal;
+        if (origVal > bufStats.maxBufferVal)
+          bufStats.maxBufferVal = origVal;
+        
+        siVal = origVal;
+        pVal = &siVal;
+        memcpy(p, pVal, width);
+        
+      }
+      break;
+    }
+
+
+    case WriteEngine::WR_USHORT:
+    {
+      int64_t origVal = 0;
+      const uint16_t* dataPtr = columnData->data()->GetValues<uint16_t>(1);
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        bool bSatVal = false;
+        void* p = buf + i * width;
+        if (columnData->IsNull(i))
+        {
+          if (!column.autoIncFlag)
+          {
+            if (column.fWithDefault)
+            {
+              origVal = static_cast<int64_t>(column.fDefaultUInt);
+            }
+            else
+            {
+              usiVal = joblist::USMALLINTNULL;
+              pVal = &usiVal;
+              // FIXME:
+              // to jump to next loop
+              continue;
+            }
+          }
+          else
+          {
+            // FIXME: no fAutoIncNextValue in tableInfo
+            // fill 1 temporarily
+            // origVal = tAutoIncNextValue++;
+            origVal = 1;
+          }
+        }
+        else
+        {
+          memcpy(&usiVal, dataPtr + i, width);
+          origVal = usiVal;
+        }
+
+        if (origVal < column.fMinIntSat)
+        {
+          origVal = column.fMinIntSat;
+          bSatVal = true;
+        }
+        else if (origVal > static_cast<int64_t>(column.fMaxIntSat))
+        {
+          origVal = static_cast<int64_t>(column.fMaxIntSat);
+          bSatVal = true;
+        }
+
+        if (bSatVal)
+          bufStats.satCount++;
+
+        uint64_t uVal = origVal;
+
+        if (uVal < static_cast<uint64_t>(bufStats.minBufferVal))
+          bufStats.minBufferVal = origVal;
+        if (uVal > static_cast<uint64_t>(bufStats.maxBufferVal))
+          bufStats.maxBufferVal = origVal;
+        
+        usiVal = origVal;
+        pVal = &usiVal;
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+
+    case WriteEngine::WR_BYTE:
+    {
+      long long origVal;
+      const char* dataPtr = columnData->data()->GetValues<char>(1);
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        bool bSatVal = false;
+        void* p = buf + i * width;
+        if (columnData->IsNull(i))
+        {
+          if (!column.autoIncFlag)
+          {
+            if (!column.fWithDefault)
+            {
+              origVal = column.fDefaultInt;
+            }
+            else
+            {
+              biVal = joblist::TINYINTNULL;
+              pVal = &biVal;
+              continue;
+            }
+
+          }
+          else
+          {
+            origVal = 1;
+          }
+        }
+        else
+        {
+          memcpy(&biVal, dataPtr + i, width);
+        }
+
+        if (origVal < column.fMinIntSat)
+        {
+          origVal = column.fMinIntSat;
+        }
+        else if (origVal > static_cast<int64_t>(column.fMaxIntSat))
+        {
+          origVal = static_cast<int64_t>(column.fMaxIntSat);
+          bSatVal = true;
+        }
+
+        if (bSatVal)
+          bufStats.satCount++;
+
+
+        if (origVal < bufStats.minBufferVal)
+          bufStats.minBufferVal = origVal;
+        
+        if (origVal > bufStats.maxBufferVal)
+          bufStats.maxBufferVal = origVal;
+
+        biVal = origVal;
+        pVal = &biVal;
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+
+    case WriteEngine::WR_UBYTE:
+    {
+      int64_t origVal = 0;
+      const uint8_t* dataPtr = columnData->data()->GetValues<uint8_t>(1);
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        bool bSatVal = false;
+        void* p = buf + i * width;
+        if (columnData->IsNull(i))
+        {
+          if (!column.autoIncFlag)
+          {
+            if (!column.fWithDefault)
+            {
+              origVal = static_cast<int64_t>(column.fDefaultUInt);
+            }
+            else
+            {
+              ubiVal = joblist::UTINYINTNULL;
+              pVal = &ubiVal;
+              continue;
+            }
+          }
+          else
+          {
+            origVal = 1;
+          }
+        }
+        else
+        {
+          memcpy(&ubiVal, dataPtr + i, width);
+        }
+
+        if (origVal < column.fMinIntSat)
+        {
+          origVal = column.fMinIntSat;
+        }
+        else if (origVal > static_cast<int64_t>(column.fMaxIntSat))
+        {
+          origVal = static_cast<int64_t>(column.fMaxIntSat);
+          bSatVal = true;
+        }
+
+        if (bSatVal)
+          bufStats.satCount++;
+
+        uint64_t uVal = origVal;
+
+        if (origVal < static_cast<uint64_t>(bufStats.minBufferVal))
+          bufStats.minBufferVal = origVal;
+        
+        if (origVal > static_cast<uint64_t>(bufStats.maxBufferVal))
+          bufStats.maxBufferVal = origVal;
+
+        ubiVal = origVal;
+        pVal = &ubiVal;
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+    
+    case WriteEngine::WR_LONGLONG:
+    {
+      if (column.dataType != CalpontSystemCatalog::DATETIME &&
+          column.dataType != CalpontSystemCatalog::TIMESTAMP &&
+          column.dataType != CalpontSystemCatalog::TIME)
+      {
+        const long long *dataPtr = columnData->data()->GetValues<long long>(1);
+        for (unsigned int i = 0; i < cbs; i++)
+        {
+          void *p = buf + i * width;
+          bool bSatVal = false;
+          if (columnData->IsNull(i))
+          {
+            if (!column.autoIncFlag)
+            {
+              if (column.fWithDefault)
+              {
+                llVal = column.fDefaultInt;
+              }
+              else
+              {
+                llVal = joblist::BIGINTNULL;
+                pVal = &llVal;
+                continue;
+              }
+            }
+            else
+            {
+              llVal = 1;
+            }
+          }
+          else
+          {
+            memcpy(&llVal, dataPtr + i, width);
+          }
+          if (llVal < column.fMinIntSat)
+          {
+            llVal = column.fMinIntSat;
+            bSatVal = true;
+          }
+          else if (llVal > static_cast<int64_t>(column.fMaxIntSat))
+          {
+            llVal = static_cast<int64_t>(column.fMaxIntSat);
+            bSatVal = true;
+          }
+
+          if (bSatVal)
+            bufStats.satCount++;
+
+          // Update min/max range
+          if (llVal < bufStats.minBufferVal)
+            bufStats.minBufferVal = llVal;
+
+          if (llVal > bufStats.maxBufferVal)
+            bufStats.maxBufferVal = llVal;
+
+          pVal = &llVal;
+          memcpy(p, pVal, width);
+        }
+      }
+      else if (column.dataType == CalpontSystemCatalog::TIME)
+      {
+        // time conversion here
+        // for parquet, there are two time type, time32 and time64
+        // if it's time32, unit is millisecond, int32
+        if (columnData->type_id() == arrow::Type::type::TIME32)
+        {
+          std::shared_ptr<arrow::Time32Array> timeArray = std::static_pointer_cast<arrow::Time32Array>(columnData);
+          for (unsigned int i = 0; i < cbs; i++)
+          {
+            bool bSatVal = false;
+            void *p = buf + i * width;
+            if (columnData->IsNull(i))
+            {
+              if (column.fWithDefault)
+              {
+                llDate = column.fDefaultInt;
+              }
+              else
+              {
+                llDate = joblist::TIMENULL;
+                pVal = &llDate;
+                continue;
+              }
+            }
+            else
+            {
+              // timeVal is millisecond since midnight
+              int32_t timeVal = timeArray->Value(i);
+              llDate = dataconvert::DataConvert::convertArrowColumnTime32(timeVal);
+
+            }
+            if (llDate < bufStats.minBufferVal)
+              bufStats.minBufferVal = llDate;
+            if (llDate > bufStats.maxBufferVal)
+              bufStats.maxBufferVal = llDate;
+            memcpy(p, pVal, width);
+          }
+        }
+        // if it's time64, unit is microsecond, int64
+        else if (columnData->type_id() == arrow::Type::type::TIME64)
+        {
+          std::shared_ptr<arrow::Time64Array> timeArray = std::static_pointer_cast<arrow::Time64Array>(columnData);
+          for (unsigned int i = 0; i < cbs; i++)
+          {
+            bool bSatVal = false;
+            void *p = buf + i * width;
+            if (columnData->IsNull(i))
+            {
+              if (column.fWithDefault)
+              {
+                llDate = column.fDefaultInt;
+              }
+              else
+              {
+                llDate = joblist::TIMENULL;
+                pVal = &llDate;
+                continue;
+              }
+            }
+            else
+            {
+              // timeVal is macrosecond since midnight
+              int64_t timeVal = timeArray->Value(i);
+              llDate = dataconvert::DataConvert::convertArrowColumnTime64(timeVal);
+
+            }
+            if (llDate < bufStats.minBufferVal)
+              bufStats.minBufferVal = llDate;
+            if (llDate > bufStats.maxBufferVal)
+              bufStats.maxBufferVal = llDate;
+            pVal = &llDate;
+            memcpy(p, pVal, width);
+          }
+        }
+      }
+      else if (column.dataType == CalpontSystemCatalog::TIMESTAMP)
+      {
+        // timestamp conversion here
+        // default column type is TIMESTAMP
+        // default unit is millisecond
+        std::shared_ptr<arrow::TimestampArray> timeArray = std::static_pointer_cast<arrow::TimestampArray>(columnData);
+        for (unsigned int i = 0; i < cbs; i++)
+        {
+          bool bSatVal = false;
+          void *p = buf + i * width;
+          if (columnData->IsNull(i))
+          {
+            if (column.fWithDefault)
+            {
+              llDate = column.fDefaultInt;
+            }
+            else
+            {
+              llDate = joblist::TIMESTAMPNULL;
+              pVal = &llDate;
+              continue;
+            }
+          }
+          else
+          {
+            int64_t timeVal = timeArray->Value(i);
+            llDate = timeVal;
+          }
+          if (llDate < bufStats.minBufferVal)
+            bufStats.minBufferVal = llDate;
+          if (llDate > bufStats.maxBufferVal)
+            bufStats.maxBufferVal = llDate;
+          pVal = &llDate;
+          memcpy(p, pVal, width);
+        }
+      }
+      else
+      {
+        // datetime conversion here
+        // default column type is TIMESTAMP
+        std::shared_ptr<arrow::TimestampArray> timeArray = std::static_pointer_cast<arrow::TimestampArray>(columnData);
+        for (unsigned int i = 0; i < cbs; i++)
+        {
+          bool bSatVal = false;
+          void *p = buf + i * width;
+          if (columnData->IsNull(i))
+          {
+            if (column.fWithDefault)
+            {
+              llDate = column.fDefaultInt;
+            }
+            else
+            {
+              llDate = joblist::DATETIMENULL;
+              pVal = &llDate;
+              continue;
+            }
+          }
+          else
+          {
+            int64_t timestampVal = timeArray->Value(i);
+            // TODO:To get the datetime info of timestampVal
+          }
+        }
+
+      }
+    }
+
+    case WriteEngine::WR_BINARY:
+    {
+      bool bSatVal = false;
+
+    }
+  }
+}
+
 int TableInfo::readParquetData()
 {
   int rc = NO_ERROR;
@@ -393,6 +1028,15 @@ int TableInfo::readParquetData()
           // get current column data type
           // arrow::Type::type colType = columnData->type()->id();
           // only consider `int` type now 
+
+          // parquetConvert(std::shared_ptr<arrow::Array>, JobColumn&, BLBufferStats&, unsigned char*)
+
+          parquetConvert(columnData, columnInfo.column, bufStats, buf, current_batch_size);
+
+
+
+
+
           const char* data_ptr = columnData->data()->GetValues<char>(1);
           for (uint32_t i = 0; i < current_batch_size; i++)
           {
diff --git a/writeengine/bulk/we_tableinfo.h b/writeengine/bulk/we_tableinfo.h
index c5630c77a3..b7baac82c9 100644
--- a/writeengine/bulk/we_tableinfo.h
+++ b/writeengine/bulk/we_tableinfo.h
@@ -395,6 +395,8 @@ class TableInfo : public WeUIDGID
   // */
   // int parseParquet(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, int bs);
 
+  void parquetConvert(std::shared_ptr<arrow::Array> columnData, JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, int cbs)
+
   /** @brief Read the parquet file data into the memory
    */
   int readParquetData();

From 83ea4fbf9192063540114833e490a570ba116875 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Tue, 4 Jul 2023 01:27:52 +0800
Subject: [PATCH 07/15] support dict_extent

---
 writeengine/bulk/we_columninfo.cpp   |  25 ++
 writeengine/bulk/we_columninfo.h     |   6 +
 writeengine/bulk/we_tableinfo.cpp    | 441 ++++++++++++++++++++-------
 writeengine/bulk/we_tableinfo.h      |   4 +-
 writeengine/dictionary/we_dctnry.cpp | 206 +++++++++++++
 writeengine/dictionary/we_dctnry.h   |  22 ++
 6 files changed, 591 insertions(+), 113 deletions(-)

diff --git a/writeengine/bulk/we_columninfo.cpp b/writeengine/bulk/we_columninfo.cpp
index 3f89c28a0f..ff440f5ecc 100644
--- a/writeengine/bulk/we_columninfo.cpp
+++ b/writeengine/bulk/we_columninfo.cpp
@@ -1657,6 +1657,31 @@ int ColumnInfo::closeDctnryStore(bool bAbort)
   return rc;
 }
 
+
+int ColumnInfo::updateDctnryStoreParquet(std::shared_ptr<arrow::Array> columnData, const int totalRow, char* tokenBuf)
+{
+  long long truncCount = 0;
+
+  // if ((curCol.colDataType == WR_VARBINARY) || (curCol.colType == WR_BLOB))
+  // {
+
+  // }
+  int rc = fStore->insertDctnryParquet(columnData, totalRow, id, tokenBuf, truncCount);
+  if (rc != NO_ERROR)
+  {
+    WErrorCodes ec;
+    std::ostringstream oss;
+    oss << "updateDctnryStore: error adding rows to store file for "
+        << "OID-" << column.dctnry.dctnryOid << "; DBRoot-" << curCol.dataFile.fDbRoot << "; part-"
+        << curCol.dataFile.fPartition << "; seg-" << curCol.dataFile.fSegment << "; " << ec.errorString(rc);
+    fLog->logMsg(oss.str(), rc, MSGLVL_CRITICAL);
+    fpTableInfo->fBRMReporter.addToErrMsgEntry(oss.str());
+    return rc;
+  }
+  incSaturatedCnt(truncCount);
+  return NO_ERROR;
+}
+
 //------------------------------------------------------------------------------
 // Update dictionary store file with specified strings, and return the assigned
 // tokens (tokenbuf) to be stored in the corresponding column token file.
diff --git a/writeengine/bulk/we_columninfo.h b/writeengine/bulk/we_columninfo.h
index 8a04a89b94..38190eb03d 100644
--- a/writeengine/bulk/we_columninfo.h
+++ b/writeengine/bulk/we_columninfo.h
@@ -200,6 +200,12 @@ class ColumnInfo : public WeUIDGID
    */
   void lastInputRowInExtentInc();
 
+  /** @brief Update dictionary for arrow/parquet format
+   * 
+  */
+  int updateDctnryStoreParquet(std::shared_ptr<arrow::Array> columnData, const int totalRow, char* tokenBuf);
+
+
   /** @brief Update dictionary method.
    *  Parses and stores specified strings into the store file, and
    *  returns the assigned tokens (tokenBuf) to be stored in the
diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index 33bd1fba5e..85564dff1b 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -66,6 +66,8 @@ using namespace querytele;
 #include <parquet/stream_reader.h>
 using namespace execplan;
 
+#include "utils_utf8.h"  // utf8_truncate_point()
+
 namespace
 {
 const std::string BAD_FILE_SUFFIX = ".bad";  // Reject data file suffix
@@ -293,13 +295,36 @@ bool TableInfo::lockForRead(const int& locker)
 // }
 
 
-// int TableInfo::parseParquetDict(unsigned int k, int bs)
-// {
-//   int rc = NO_ERROR;
+int TableInfo::parseParquetDict(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, unsigned int cbs, int64_t bs, int batchProcessed)
+{
+  int rc = NO_ERROR;
+  ColumnInfo& columnInfo = fColumns[k];
 
+  ColumnBufferSection* section = 0;
+  RID lastInputRowInExtent = 0;
+  uint32_t nRowsParsed;
+  RETURN_ON_ERROR(columnInfo.fColBufferMgr->reserveSection(bs * batchProcessed, cbs, nRowsParsed, &section, lastInputRowInExtent));
 
-//   return rc;
-// }
+  if (nRowsParsed > 0)
+  {
+    char* tokenBuf = new char[nRowsParsed * 8];
+    std::shared_ptr<arrow::Array> columnData = batch->column(k);
+    rc = columnInfo.updateDctnryStoreParquet(columnData, nRowsParsed, tokenBuf);
+
+    if (rc == NO_ERROR)
+    {
+      section->write(tokenBuf, nRowsParsed);
+      delete[] tokenBuf;
+
+      RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section));
+    }
+    else
+    {
+      delete[] tokenBuf;
+    }
+  }
+  return rc;
+}
 
 // int TableInfo::parseParquet(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, int bs)
 // {
@@ -321,7 +346,7 @@ bool TableInfo::lockForRead(const int& locker)
 // }
 
 
-void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, int cbs)
+void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, unsigned int cbs)
 {
   char biVal;
   int iVal;
@@ -329,8 +354,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
   double dVal;
   short siVal;
   void* pVal;
-  int32_t iDate;
-  char charTmpBuf[MAX_COLUMN_BOUNDARY + 1] = {0};
+  // int32_t iDate;
   long long llVal = 0, llDate = 0;
   int128_t bigllVal = 0;
   uint64_t tmp64;
@@ -360,6 +384,8 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           {
             tmp32 = joblist::FLOATNULL;
             pVal = &tmp32;
+            memcpy(p, pVal, width);
+            continue;
           }
         }
         else
@@ -401,6 +427,8 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           {
             tmp64 = joblist::DOUBLENULL;
             pVal = &tmp64;
+            memcpy(p, pVal, width);
+            continue;
           }
         }
         else
@@ -429,6 +457,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
       int tokenLen;
       for (unsigned int i = 0; i < cbs; i++)
       {
+        char charTmpBuf[MAX_COLUMN_BOUNDARY + 1] = {0};
         void* p = buf + width * i;
         if (columnData->IsNull(i))
         {
@@ -444,21 +473,24 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           else
           {
             idbassert(width <= 8);
-            for (j = 0; j < width - 1; j++)
+            for (int j = 0; j < width - 1; j++)
             {
               charTmpBuf[j] = '\377';
             }
             charTmpBuf[width - 1] = '\376';
             pVal = charTmpBuf;
+            memcpy(p, pVal, width);
+            continue;
             // break;
           }
         }
         else
         {
-          const uint8_t* dataPtr = binaryArray->GetValue(i, &tokenLen);
+          const uint8_t* data = binaryArray->GetValue(i, &tokenLen);
+          const char* dataPtr = reinterpret_cast<const char*>(data);
           if (tokenLen > column.definedWidth)
           {
-            uint8_t truncate_point = utf8::utf8_truncate_point(field, column.definedWidth);
+            uint8_t truncate_point = utf8::utf8_truncate_point(dataPtr, column.definedWidth);
             memcpy(charTmpBuf, dataPtr, column.definedWidth - truncate_point);
             bufStats.satCount++;
           }
@@ -507,6 +539,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             {
               siVal = joblist::SMALLINTNULL;
               pVal = &siVal;
+              memcpy(p, pVal, width);
               // to jump to next loop
               continue;
             }
@@ -573,6 +606,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             {
               usiVal = joblist::USMALLINTNULL;
               pVal = &usiVal;
+              memcpy(p, pVal, width);
               // FIXME:
               // to jump to next loop
               continue;
@@ -640,6 +674,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             {
               biVal = joblist::TINYINTNULL;
               pVal = &biVal;
+              memcpy(p, pVal, width);
               continue;
             }
 
@@ -701,6 +736,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             {
               ubiVal = joblist::UTINYINTNULL;
               pVal = &ubiVal;
+              memcpy(p, pVal, width);
               continue;
             }
           }
@@ -717,6 +753,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         if (origVal < column.fMinIntSat)
         {
           origVal = column.fMinIntSat;
+          bSatVal = true;
         }
         else if (origVal > static_cast<int64_t>(column.fMaxIntSat))
         {
@@ -729,10 +766,10 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
 
         uint64_t uVal = origVal;
 
-        if (origVal < static_cast<uint64_t>(bufStats.minBufferVal))
+        if (uVal < static_cast<uint64_t>(bufStats.minBufferVal))
           bufStats.minBufferVal = origVal;
         
-        if (origVal > static_cast<uint64_t>(bufStats.maxBufferVal))
+        if (uVal > static_cast<uint64_t>(bufStats.maxBufferVal))
           bufStats.maxBufferVal = origVal;
 
         ubiVal = origVal;
@@ -765,6 +802,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
               {
                 llVal = joblist::BIGINTNULL;
                 pVal = &llVal;
+                memcpy(p, pVal, width);
                 continue;
               }
             }
@@ -812,7 +850,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           std::shared_ptr<arrow::Time32Array> timeArray = std::static_pointer_cast<arrow::Time32Array>(columnData);
           for (unsigned int i = 0; i < cbs; i++)
           {
-            bool bSatVal = false;
+            // bool bSatVal = false;
             void *p = buf + i * width;
             if (columnData->IsNull(i))
             {
@@ -824,6 +862,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
               {
                 llDate = joblist::TIMENULL;
                 pVal = &llDate;
+                memcpy(p, pVal, width);
                 continue;
               }
             }
@@ -847,7 +886,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           std::shared_ptr<arrow::Time64Array> timeArray = std::static_pointer_cast<arrow::Time64Array>(columnData);
           for (unsigned int i = 0; i < cbs; i++)
           {
-            bool bSatVal = false;
+            // bool bSatVal = false;
             void *p = buf + i * width;
             if (columnData->IsNull(i))
             {
@@ -859,6 +898,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
               {
                 llDate = joblist::TIMENULL;
                 pVal = &llDate;
+                memcpy(p, pVal, width);
                 continue;
               }
             }
@@ -886,7 +926,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         std::shared_ptr<arrow::TimestampArray> timeArray = std::static_pointer_cast<arrow::TimestampArray>(columnData);
         for (unsigned int i = 0; i < cbs; i++)
         {
-          bool bSatVal = false;
+          // bool bSatVal = false;
           void *p = buf + i * width;
           if (columnData->IsNull(i))
           {
@@ -898,6 +938,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             {
               llDate = joblist::TIMESTAMPNULL;
               pVal = &llDate;
+              memcpy(p, pVal, width);
               continue;
             }
           }
@@ -921,7 +962,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         std::shared_ptr<arrow::TimestampArray> timeArray = std::static_pointer_cast<arrow::TimestampArray>(columnData);
         for (unsigned int i = 0; i < cbs; i++)
         {
-          bool bSatVal = false;
+          // bool bSatVal = false;
           void *p = buf + i * width;
           if (columnData->IsNull(i))
           {
@@ -933,23 +974,259 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             {
               llDate = joblist::DATETIMENULL;
               pVal = &llDate;
+              memcpy(p, pVal, width);
               continue;
             }
           }
           else
           {
-            int64_t timestampVal = timeArray->Value(i);
+            // int64_t timestampVal = timeArray->Value(i);
             // TODO:To get the datetime info of timestampVal
+            continue;
           }
         }
 
       }
+      break;
     }
 
     case WriteEngine::WR_BINARY:
     {
-      bool bSatVal = false;
+      // Parquet does not have data type with 128 byte
+      // const int128_t* dataPtr = static_pointer_cast<int128_t>(columnData);
+      const int128_t* dataPtr = columnData->data()->GetValues<int128_t>(1);
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        void* p = buf + i * width;
+        // bool bSatVal = false;
+        if (columnData->IsNull(i))
+        {
+          if (!column.autoIncFlag)
+          {
+            if (column.fWithDefault)
+            {
+              bigllVal = column.fDefaultWideDecimal;
+            }
+            else
+            {
+              bigllVal = datatypes::Decimal128Null;
+              pVal = &bigllVal;
+              memcpy(p, pVal, width);
+              continue;
+            }
+          }
+          else
+          {
+            bigllVal = 1;
+          }
+        }
+        else
+        {
+          memcpy(&bigllVal, dataPtr + i, width);
+        }
+
+        //TODO: no bSatVal change here
+        if (bigllVal < bufStats.bigMinBufferVal)
+          bufStats.bigMinBufferVal = bigllVal;
+        
+        if (bigllVal > bufStats.bigMaxBufferVal)
+          bufStats.bigMaxBufferVal = bigllVal;
+        
+        pVal = &bigllVal;
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+
+
+    case WriteEngine::WR_ULONGLONG:
+    {
+      const uint64_t* dataPtr = columnData->data()->GetValues<uint64_t>(1);
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        bool bSatVal = false;
+        void* p = buf + i * width;
+        // const uint64_t* dataPtr = static_pointer_cast<uint64_t>(columnData);
+        if (columnData->IsNull(i))
+        {
+          if (!column.autoIncFlag)
+          {
+            if (column.fWithDefault)
+            {
+              ullVal = column.fDefaultUInt;
+            }
+            else
+            {
+              ullVal = joblist::UBIGINTNULL;
+              pVal = &ullVal;
+              memcpy(p, pVal, width);
+              continue;
+            }
+          }
+          else
+          {
+            ullVal = 1;
+          }
+        }
+        else
+        {
+          memcpy(&ullVal, dataPtr+i, width);
+        }
+        if (ullVal > column.fMaxIntSat)
+        {
+          ullVal = column.fMaxIntSat;
+          bSatVal = true;
+        }
+        // TODO:why no comparsion with column.fMinIntSat
+        
+
+        if (bSatVal)
+          bufStats.satCount++;
+        if (ullVal < static_cast<uint64_t>(bufStats.minBufferVal))
+          bufStats.minBufferVal = static_cast<int64_t>(ullVal);
 
+        if (ullVal > static_cast<uint64_t>(bufStats.maxBufferVal))
+          bufStats.maxBufferVal = static_cast<int64_t>(ullVal);
+
+        pVal = &ullVal;
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+
+    case WriteEngine::WR_UMEDINT:
+    case WriteEngine::WR_UINT:
+    {
+      int64_t origVal;
+      // const uint32_t* dataPtr = static_pointer_cast<uint32_t>(columnData);
+      const uint32_t* dataPtr = columnData->data()->GetValues<uint32_t>(1);
+      for (unsigned int i = 0; i < cbs; i++)
+      {
+        bool bSatVal = false;
+        void* p = buf + i * width;
+        if (columnData->IsNull(i))
+        {
+          if (!column.autoIncFlag)
+          {
+            if (column.fWithDefault)
+            {
+              origVal = static_cast<int64_t>(column.fDefaultUInt);
+            }
+            else
+            {
+              uiVal = joblist::UINTNULL;
+              pVal = &uiVal;
+              memcpy(p, pVal, width);
+              // TODO:continue jump to next loop?
+              continue;
+            }
+          }
+          else
+          {
+            origVal = 1;
+          }
+        }
+        else
+        {
+          memcpy(&uiVal, dataPtr + i, width);
+        }
+        if (origVal < column.fMinIntSat)
+        {
+          origVal = column.fMinIntSat;
+          bSatVal = true;
+        }
+        else if (origVal > static_cast<int64_t>(column.fMaxIntSat))
+        {
+          origVal = static_cast<int64_t>(column.fMaxIntSat);
+          bSatVal = true;
+        }
+
+        if (bSatVal)
+          bufStats.satCount++;
+
+        // Update min/max range
+        uint64_t uVal = origVal;
+
+        if (uVal < static_cast<uint64_t>(bufStats.minBufferVal))
+          bufStats.minBufferVal = origVal;
+
+        if (uVal > static_cast<uint64_t>(bufStats.maxBufferVal))
+          bufStats.maxBufferVal = origVal;
+
+        uiVal = origVal;
+        pVal = &uiVal;
+        memcpy(p, pVal, width);
+      }
+      break;
+    }
+
+    case WriteEngine::WR_MEDINT:
+    case WriteEngine::WR_INT:
+    default:
+    {
+      if (column.dataType != CalpontSystemCatalog::DATE)
+      {
+        const int* dataPtr = columnData->data()->GetValues<int>(1);
+        for (unsigned int i = 0; i < cbs; i++)
+        {
+          bool bSatVal = false;
+          void* p = buf + i * width;
+          long long origVal;
+          if (columnData->IsNull(i))
+          {
+            if (!column.autoIncFlag)
+            {
+              if (column.fWithDefault)
+              {
+                origVal = column.fDefaultInt;
+              }
+              else
+              {
+                iVal = joblist::INTNULL;
+                pVal = &iVal;
+                memcpy(p, pVal, width);
+                continue;
+              }
+            }
+            else
+            {
+              origVal = 1;
+            }
+          }
+          else
+          {
+            memcpy(&iVal, dataPtr + i, width);
+            origVal = (long long)iVal;
+          }
+
+          if (origVal < column.fMinIntSat)
+          {
+            origVal = column.fMinIntSat;
+            bSatVal = true;
+          }
+          else if (origVal > static_cast<int64_t>(column.fMaxIntSat))
+          {
+            origVal = static_cast<int64_t>(column.fMaxIntSat);
+            bSatVal = true;
+          }
+          if (bSatVal)
+            bufStats.satCount++;
+
+          if (origVal < bufStats.minBufferVal)
+            bufStats.minBufferVal = origVal;
+
+          if (origVal > bufStats.maxBufferVal)
+            bufStats.maxBufferVal = origVal;
+
+          iVal = (int)origVal;
+          pVal = &iVal;
+          memcpy(p, pVal, width);
+        }
+      }
+      else
+      {
+        // date conversion here
+      }
     }
   }
 }
@@ -1005,7 +1282,8 @@ int TableInfo::readParquetData()
       // parseParquet(batch, k, current_batch_size);
       if (fColumns[k].column.colType == COL_TYPE_DICT)
       {
-        // rc = parseParquetDict(k, bs);
+        rc = parseParquetDict(batch, k, current_batch_size, bs, batch_processed);
+        //TODO: if input data is spanned to 2 extents.
         continue;
       }
       else
@@ -1033,105 +1311,49 @@ int TableInfo::readParquetData()
 
           parquetConvert(columnData, columnInfo.column, bufStats, buf, current_batch_size);
 
+          updateCPInfoPendingFlag = true;
 
+          if (columnInfo.column.width <= 8)
+          {
+            columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.minBufferVal, bufStats.maxBufferVal,
+                                    columnInfo.column.dataType, columnInfo.column.width);
+          }
+          else
+          {
+            columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.bigMinBufferVal, bufStats.bigMaxBufferVal,
+                                    columnInfo.column.dataType, columnInfo.column.width);
+          }
 
+          // what's this rowsPerExtent for?
+          lastInputRowInExtent += columnInfo.rowsPerExtent();
 
-
-          const char* data_ptr = columnData->data()->GetValues<char>(1);
-          for (uint32_t i = 0; i < current_batch_size; i++)
+          if (isUnsigned(columnInfo.column.dataType))
           {
-            unsigned char* p = buf + i * columnInfo.column.width;
-            void *t;
-            long long origVal;
-            int32_t iVal;
-            bool bSatVal = false;
-            if (columnData->IsNull(i))
+            if (columnInfo.column.width <= 8)
             {
-              if (columnInfo.column.fWithDefault)
-              {
-                origVal = columnInfo.column.fDefaultInt;
-              }
-              else
-              {
-                iVal = joblist::INTNULL;
-              }
+              bufStats.minBufferVal = static_cast<int64_t>(MAX_UBIGINT);
+              bufStats.maxBufferVal = static_cast<int64_t>(MIN_UBIGINT);
             }
             else
             {
-              memcpy(&iVal, data_ptr + 4*i, 4);
-              origVal = (long long)iVal;
-            }
-
-            // Saturate the value
-            if (origVal < columnInfo.column.fMinIntSat)
-            {
-              origVal = columnInfo.column.fMinIntSat;
-              bSatVal = true;
+              bufStats.bigMinBufferVal = -1;
+              bufStats.bigMaxBufferVal = 0;
             }
-            else if (origVal > static_cast<int64_t>(columnInfo.column.fMaxIntSat))
+            updateCPInfoPendingFlag = false;
+          }
+          else
+          {
+            if (columnInfo.column.width <= 8)
             {
-              origVal = static_cast<int64_t>(columnInfo.column.fMaxIntSat);
-              bSatVal = true;
+              bufStats.minBufferVal = MAX_BIGINT;
+              bufStats.maxBufferVal = MIN_BIGINT;
             }
-            if (bSatVal)
-              bufStats.satCount++;
-
-            if (origVal < bufStats.minBufferVal)
-              bufStats.minBufferVal = origVal;
-
-            if (origVal > bufStats.maxBufferVal)
-              bufStats.maxBufferVal = origVal;
-            t = &iVal;
-            memcpy(p, t, 4);
-
-            updateCPInfoPendingFlag = true;
-
-            if ((RID)(bs * batch_processed + i) == lastInputRowInExtent)
+            else
             {
-              if (columnInfo.column.width <= 8)
-              {
-                columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.minBufferVal, bufStats.maxBufferVal,
-                                        columnInfo.column.dataType, columnInfo.column.width);
-              }
-              else
-              {
-                columnInfo.updateCPInfo(lastInputRowInExtent, bufStats.bigMinBufferVal, bufStats.bigMaxBufferVal,
-                                        columnInfo.column.dataType, columnInfo.column.width);
-              }
-
-              // what's this rowsPerExtent for?
-              lastInputRowInExtent += columnInfo.rowsPerExtent();
-
-              if (isUnsigned(columnInfo.column.dataType))
-              {
-                if (columnInfo.column.width <= 8)
-                {
-                  bufStats.minBufferVal = static_cast<int64_t>(MAX_UBIGINT);
-                  bufStats.maxBufferVal = static_cast<int64_t>(MIN_UBIGINT);
-                }
-                else
-                {
-                  bufStats.bigMinBufferVal = -1;
-                  bufStats.bigMaxBufferVal = 0;
-                }
-                updateCPInfoPendingFlag = false;
-              }
-              else
-              {
-                if (columnInfo.column.width <= 8)
-                {
-                  bufStats.minBufferVal = MAX_BIGINT;
-                  bufStats.maxBufferVal = MIN_BIGINT;
-                }
-                else
-                {
-                  utils::int128Max(bufStats.bigMinBufferVal);
-                  utils::int128Min(bufStats.bigMaxBufferVal);
-                }
-                updateCPInfoPendingFlag = false;
-              }
+              utils::int128Max(bufStats.bigMinBufferVal);
+              utils::int128Min(bufStats.bigMaxBufferVal);
             }
-
+            updateCPInfoPendingFlag = false;
           }
 
           if (updateCPInfoPendingFlag)
@@ -1156,13 +1378,10 @@ int TableInfo::readParquetData()
           section->write(buf, current_batch_size);
           delete[] buf;
 
-          RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section))
-
+          RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section));
         }
-        // return rc;
       }
     }
-
     // process `aux` column
     ColumnInfo& columnInfo = fColumns[fNumberOfColumns-1];
     ColumnBufferSection* section = 0;
@@ -1289,7 +1508,7 @@ int TableInfo::readParquetData()
       section->write(buf, current_batch_size);
       delete[] buf;
 
-      RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section))
+      RETURN_ON_ERROR(columnInfo.fColBufferMgr->releaseSection(section));
 
     }
 
diff --git a/writeengine/bulk/we_tableinfo.h b/writeengine/bulk/we_tableinfo.h
index b7baac82c9..aee516ac5e 100644
--- a/writeengine/bulk/we_tableinfo.h
+++ b/writeengine/bulk/we_tableinfo.h
@@ -389,13 +389,13 @@ class TableInfo : public WeUIDGID
 
   // /** @brief parse parquet data
   // */
-  // int parseParquetDict(unsigned int k, int bs);
+  int parseParquetDict(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, unsigned int cbs, int64_t bs, int batchProcessed);
 
   // /** @brief parse parquet data
   // */
   // int parseParquet(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, int bs);
 
-  void parquetConvert(std::shared_ptr<arrow::Array> columnData, JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, int cbs)
+  void parquetConvert(std::shared_ptr<arrow::Array> columnData, const JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, unsigned int cbs);
 
   /** @brief Read the parquet file data into the memory
    */
diff --git a/writeengine/dictionary/we_dctnry.cpp b/writeengine/dictionary/we_dctnry.cpp
index 0a4f5e90b4..c2efe3b86c 100644
--- a/writeengine/dictionary/we_dctnry.cpp
+++ b/writeengine/dictionary/we_dctnry.cpp
@@ -745,6 +745,212 @@ int Dctnry::insertDctnry2(Signature& sig)
   return NO_ERROR;
 }
 
+
+int Dctnry::insertDctnryParquet(std::shared_ptr<arrow::Array> columnData, const int totalRow, const int col, char* tokenBuf, long long& truncCount)
+{
+  int startPos = 0;
+  int totalUseSize = 0;
+
+  bool found = false;
+  Signature curSig;
+  const char* pIn;
+  char* pOut = tokenBuf;
+  int outOffset = 0;
+  bool next = false;
+  CommBlock cb;
+  cb.file.oid = m_dctnryOID;
+  cb.file.pFile = m_dFile;
+  WriteEngine::Token nullToken;
+  auto binaryArray = std::static_pointer_cast<arrow::BinaryArray>(columnData);
+
+  while (startPos < totalRow)
+  {
+    found = false;
+    void* curSigPtr = static_cast<void*>(&curSig);
+    memset(curSigPtr, 0, sizeof(curSig));
+
+    const uint8_t* data = binaryArray->GetValue(startPos, &curSig.size);
+    const char* dataPtr = reinterpret_cast<const char*>(data);
+
+    if (curSig.size > 0)
+    {
+      const char* fld = dataPtr;
+      int kk = curSig.size - 1;
+
+      for (; kk >= 0; kk--)
+      {
+        if (fld[kk] != '\0')
+          break;
+      }
+      curSig.size = kk + 1;
+    }
+
+    if ((curSig.size == 0) || (curSig.size > MAX_BLOB_SIZE))
+    {
+      if (m_defVal.length() > 0)
+      {
+        pIn = m_defVal.c_str();
+        curSig.signature = (unsigned char*)pIn;
+        curSig.size = m_defVal.length();
+      }
+      else
+      {
+        memcpy(pOut + outOffset, &nullToken, 8);
+        outOffset += 8;
+        startPos++;
+        continue;
+      }
+    }
+    else
+    {
+      pIn = dataPtr;
+      curSig.signature = (unsigned char*)pIn;
+    }
+
+    if (curSig.size > m_colWidth)
+    {
+      uint8_t truncate_point = utf8::utf8_truncate_point((const char*)curSig.signature, m_colWidth);
+      curSig.size = m_colWidth - truncate_point;
+      ++truncCount;
+    }
+
+    if (curSig.size <= MAX_SIGNATURE_SIZE)
+    {
+      found = getTokenFromArray(curSig);
+
+      if (found)
+      {
+        memcpy(pOut + outOffset, &curSig.token, 8);
+        outOffset += 8;
+        startPos++;
+        continue;
+      }
+    }
+    totalUseSize = m_totalHdrBytes + curSig.size;
+
+    if (((totalUseSize <= m_freeSpace - HDR_UNIT_SIZE) ||
+         ((curSig.size > 8176) && (m_freeSpace > HDR_UNIT_SIZE))) &&
+         (m_curOp < (MAX_OP_COUNT - 1)))
+    {
+      RETURN_ON_ERROR(insertDctnry2(curSig));
+      m_curBlock.state = BLK_WRITE;
+      memcpy(pOut + outOffset, &curSig.token, 8);
+      outOffset += 8;
+      startPos++;
+      found = true;
+
+      if (m_curOp >= MAX_OP_COUNT - 1)
+      {
+        RETURN_ON_ERROR(writeDBFileNoVBCache(cb, &m_curBlock, m_curFbo));
+        m_curBlock.state = BLK_READ;
+        next = true;
+      }
+
+      if ((m_arraySize < MAX_STRING_CACHE_SIZE) && (curSig.size <= MAX_SIGNATURE_SIZE))
+      {
+        addToStringCache(curSig);
+      }
+    }
+    else
+    {
+      RETURN_ON_ERROR(writeDBFileNoVBCache(cb, &m_curBlock, m_curFbo));
+      m_curBlock.state = BLK_READ;
+      next = true;
+      found = false;
+    }
+
+    if (next)
+    {
+      memset(m_curBlock.data, 0, sizeof(m_curBlock.data));
+      memcpy(m_curBlock.data, &m_dctnryHeader2, m_totalHdrBytes);
+      m_freeSpace = BYTE_PER_BLOCK - m_totalHdrBytes;
+      m_curBlock.state = BLK_WRITE;
+      m_curOp = 0;
+      next = false;
+      m_lastFbo++;
+      m_curFbo = m_lastFbo;
+
+      //...Expand current extent if it is an abbreviated initial extent
+      if ((m_curFbo == m_numBlocks) && (m_numBlocks == NUM_BLOCKS_PER_INITIAL_EXTENT))
+      {
+        RETURN_ON_ERROR(expandDctnryExtent());
+      }
+
+      //...Allocate a new extent if we have reached the last block in the
+      //   current extent.
+      if (m_curFbo == m_numBlocks)
+      {
+        // last block
+        LBID_t startLbid;
+
+        // Add an extent.
+        RETURN_ON_ERROR(
+            createDctnry(m_dctnryOID, m_colWidth, m_dbRoot, m_partition, m_segment, startLbid, false));
+
+        if (m_logger)
+        {
+          std::ostringstream oss;
+          oss << "Add dictionary extent OID-" << m_dctnryOID << "; DBRoot-" << m_dbRoot << "; part-"
+              << m_partition << "; seg-" << m_segment << "; hwm-" << m_curFbo << "; LBID-" << startLbid
+              << "; file-" << m_segFileName;
+          m_logger->logMsg(oss.str(), MSGLVL_INFO2);
+        }
+
+        m_curLbid = startLbid;
+
+        // now seek back to the curFbo, after adding an extent
+        // @bug5769 For uncompressed only;
+        // ChunkManager manages the file offset for the compression case
+        if (m_compressionType == 0)
+        {
+#ifdef PROFILE
+          Stats::startParseEvent(WE_STATS_PARSE_DCT_SEEK_EXTENT_BLK);
+#endif
+          long long byteOffset = m_curFbo;
+          byteOffset *= BYTE_PER_BLOCK;
+          RETURN_ON_ERROR(setFileOffset(m_dFile, byteOffset));
+#ifdef PROFILE
+          Stats::stopParseEvent(WE_STATS_PARSE_DCT_SEEK_EXTENT_BLK);
+#endif
+        }
+      }
+      else
+      {
+        // LBIDs are numbered collectively and consecutively within an
+        // extent, so within an extent we can derive the LBID by simply
+        // incrementing it rather than having to go back to BRM to look
+        // up the LBID for each FBO.
+        m_curLbid++;
+      }
+
+#ifdef PROFILE
+      Stats::startParseEvent(WE_STATS_PARSE_DCT);
+#endif
+      m_curBlock.lbid = m_curLbid;
+
+      //..."found" flag indicates whether the string was already found
+      //   "or" added to the end of the previous block.  If false, then
+      //   we need to add the string to the new block.
+      if (!found)
+      {
+        RETURN_ON_ERROR(insertDctnry2(curSig));  // m_freeSpace updated!
+        m_curBlock.state = BLK_WRITE;
+        memcpy(pOut + outOffset, &curSig.token, 8);
+        outOffset += 8;
+        startPos++;
+
+        //...Add string to cache, if we have not exceeded cache limit
+        if ((m_arraySize < MAX_STRING_CACHE_SIZE) && (curSig.size <= MAX_SIGNATURE_SIZE))
+        {
+          addToStringCache(curSig);
+        }
+      }
+    }  // if next
+  }
+
+  return NO_ERROR;
+}
+
 /*******************************************************************************
  * Description:
  * Used by bulk import to insert collection of strings into this store file.
diff --git a/writeengine/dictionary/we_dctnry.h b/writeengine/dictionary/we_dctnry.h
index 7d41e5d03c..ba2c201236 100644
--- a/writeengine/dictionary/we_dctnry.h
+++ b/writeengine/dictionary/we_dctnry.h
@@ -36,6 +36,16 @@
 #include "we_brm.h"
 #include "bytestream.h"
 
+#include <arrow/api.h>
+#include <arrow/io/api.h>
+#include <parquet/arrow/reader.h>
+#include <parquet/arrow/writer.h>
+#include <parquet/exception.h>
+#include <arrow/result.h>
+#include <arrow/status.h>
+#include <arrow/io/file.h>
+#include <parquet/stream_reader.h>
+
 #define EXPORT
 
 /** Namespace WriteEngine */
@@ -146,6 +156,8 @@ class Dctnry : public DbFileOp
     return m_dctnryHeader2;
   }
 
+
+
   /**
    * @brief Insert a signature value to a file block and return token/pointer.
    * (for DDL/DML use)
@@ -156,6 +168,16 @@ class Dctnry : public DbFileOp
    */
   EXPORT int insertDctnry(const int& sgnature_size, const unsigned char* sgnature_value, Token& token);
 
+
+
+  /**
+   * @brief Insert signature value to a file block and return token/pointer
+   * (for Bulk use)
+  */
+  EXPORT int insertDctnryParquet(std::shared_ptr<arrow::Array> columnData, const int totalRow, const int col, char* tokenBuf, long long& truncCount);
+  
+
+
   /**
    * @brief Insert a signature value to a file block and return token/pointer
    * (for Bulk use)

From b6faaaacb712ab7ded9d88676b74f7f6675951f6 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Tue, 4 Jul 2023 17:54:18 +0800
Subject: [PATCH 08/15] support date, datetime parse

---
 utils/dataconvert/dataconvert.cpp | 82 +++++++++++++++++++++++++++++++
 utils/dataconvert/dataconvert.h   |  8 +++
 writeengine/bulk/we_tableinfo.cpp | 62 ++++++++++++++++++++++-
 3 files changed, 150 insertions(+), 2 deletions(-)

diff --git a/utils/dataconvert/dataconvert.cpp b/utils/dataconvert/dataconvert.cpp
index 5e2a327be4..d6e4a47e2e 100644
--- a/utils/dataconvert/dataconvert.cpp
+++ b/utils/dataconvert/dataconvert.cpp
@@ -40,6 +40,7 @@ using namespace boost::algorithm;
 
 #include "joblisttypes.h"
 
+#include <chrono>
 #define DATACONVERT_DLLEXPORT
 #include "dataconvert.h"
 #undef DATACONVERT_DLLEXPORT
@@ -1603,6 +1604,43 @@ boost::any DataConvert::StringToTimestamp(const datatypes::ConvertFromStringPara
   return value;
 }
 
+
+int32_t DataConvert::ConvertArrowColumnDate(int32_t dayVal, int& status)
+{
+  int inYear;
+  int inMonth;
+  int inDay;
+  int32_t value = 0;
+
+  dayVal = (long long)dayVal;
+  int64_t secondsSinceEpoch = dayVal * 86400;
+  std::chrono::seconds duration(secondsSinceEpoch);
+
+  std::chrono::system_clock::time_point timePoint(duration);
+
+  std::time_t ttime = std::chrono::system_clock::to_time_t(timePoint);
+  std::tm* timeInfo = std::localtime(&ttime);
+
+  inYear = timeInfo->tm_year + 1900;
+  inMonth = timeInfo->tm_mon + 1;
+  inDay = timeInfo->tm_mday;
+
+  if (isDateValid(inDay, inMonth, inYear))
+  {
+    Date aDay;
+    aDay.year = inYear;
+    aDay.month = inMonth;
+    aDay.day = inDay;
+    memcpy(&value, &aDay, 4);
+  }
+  else
+  {
+    status = -1;
+  }
+  return value;
+
+}
+
 //------------------------------------------------------------------------------
 // Convert date string to binary date.  Used by BulkLoad.
 //------------------------------------------------------------------------------
@@ -1689,6 +1727,50 @@ bool DataConvert::isColumnDateValid(int32_t date)
   return (isDateValid(d.day, d.month, d.year));
 }
 
+int64_t DataConvert::convertArrowColumnDatetime(int64_t timeVal, int& status)
+{
+  int64_t value = 0;
+  int inYear;
+  int inMonth;
+  int inDay;
+  int inHour;
+  int inMinute;
+  int inSecond;
+  int inMicrosecond;
+
+  std::chrono::milliseconds duration(timeVal);
+  std::chrono::system_clock::time_point timePoint(duration);
+
+  std::time_t ttime = std::chrono::system_clock::to_time_t(timePoint);
+  std::tm* timeInfo = std::localtime(&ttime);
+
+  inYear = timeInfo->tm_year + 1900;
+  inMonth = timeInfo->tm_mon + 1;
+  inDay = timeInfo->tm_mday;
+  inHour = timeInfo->tm_hour;
+  inMinute = timeInfo->tm_min;
+  inSecond = timeInfo->tm_sec;
+  inMicrosecond = (duration.count() % 1000) * 1000;
+  if (isDateValid(inDay, inMonth, inYear) && isDateTimeValid(inHour, inMinute, inSecond, inMicrosecond))
+  {
+    DateTime aDatetime;
+    aDatetime.year = inYear;
+    aDatetime.month = inMonth;
+    aDatetime.day = inDay;
+    aDatetime.hour = inHour;
+    aDatetime.minute = inMinute;
+    aDatetime.second = inSecond;
+    aDatetime.msecond = inMicrosecond;
+
+    memcpy(&value, &aDatetime, 8);
+  }
+  else
+  {
+    status = -1;
+  }
+  return value;
+}
+
 //------------------------------------------------------------------------------
 // Convert date/time string to binary date/time.  Used by BulkLoad.
 //------------------------------------------------------------------------------
diff --git a/utils/dataconvert/dataconvert.h b/utils/dataconvert/dataconvert.h
index 50c7536ab7..9ebed758e2 100644
--- a/utils/dataconvert/dataconvert.h
+++ b/utils/dataconvert/dataconvert.h
@@ -1170,6 +1170,10 @@ class DataConvert
   EXPORT static std::string timeToString1(long long timevalue);
   static inline void timeToString1(long long timevalue, char* buf, unsigned int buflen);
 
+
+  EXPORT static int32_t ConvertArrowColumnDate(int32_t dayVal, int& status);
+
+
   /**
    * @brief convert a date column data, represnted as a string, to it's native
    * format. This function is for bulkload to use.
@@ -1188,6 +1192,10 @@ class DataConvert
    */
   EXPORT static bool isColumnDateValid(int32_t date);
 
+  EXPORT static int64_t convertArrowColumnDatetime(int64_t timeVal, int& status);
+
+
+
   /**
    * @brief convert a datetime column data, represented as a string,
    * to it's native format. This function is for bulkload to use.
diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index 85564dff1b..f9ba19fb74 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -354,7 +354,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
   double dVal;
   short siVal;
   void* pVal;
-  // int32_t iDate;
+  int32_t iDate;
   long long llVal = 0, llDate = 0;
   int128_t bigllVal = 0;
   uint64_t tmp64;
@@ -877,6 +877,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
               bufStats.minBufferVal = llDate;
             if (llDate > bufStats.maxBufferVal)
               bufStats.maxBufferVal = llDate;
+            pVal = &llDate;
             memcpy(p, pVal, width);
           }
         }
@@ -963,6 +964,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         for (unsigned int i = 0; i < cbs; i++)
         {
           // bool bSatVal = false;
+          int rc = 0;
           void *p = buf + i * width;
           if (columnData->IsNull(i))
           {
@@ -982,8 +984,25 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           {
             // int64_t timestampVal = timeArray->Value(i);
             // TODO:To get the datetime info of timestampVal
-            continue;
+            int64_t timeVal = timeArray->Value(i);
+            llDate = dataconvert::DataConvert::convertArrowColumnDatetime(timeVal, rc);
+            // continue;
           }
+          if (rc == 0)
+          {
+            if (llDate < bufStats.minBufferVal)
+              bufStats.minBufferVal = llDate;
+
+            if (llDate > bufStats.maxBufferVal)
+              bufStats.maxBufferVal = llDate;
+          }
+          else
+          {
+            llDate = 0;
+            bufStats.satCount++;
+          }
+          pVal = &llDate;
+          memcpy(p, pVal, width);
         }
 
       }
@@ -1226,6 +1245,45 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
       else
       {
         // date conversion here
+        std::shared_ptr<arrow::Date32Array> timeArray = std::static_pointer_cast<arrow::Date32Array>(columnData);
+        for (unsigned int i = 0; i < cbs; i++)
+        {
+          int rc = 0;
+          void* p = buf + i * width;
+          if (columnData->IsNull(i))
+          {
+            if (column.fWithDefault)
+            {
+              iDate = column.fDefaultInt;
+            }
+            else
+            {
+              iDate = joblist::DATENULL;
+              pVal = &iDate;
+              continue;
+            }
+          }
+          else
+          {
+            int32_t dayVal = timeArray->Value(i);
+            iDate = dataconvert::DataConvert::ConvertArrowColumnDate(dayVal, rc);
+          }
+          if (rc == 0)
+          {
+            if (iDate < bufStats.minBufferVal)
+              bufStats.minBufferVal = iDate;
+
+            if (iDate > bufStats.maxBufferVal)
+              bufStats.maxBufferVal = iDate;
+          }
+          else
+          {
+            iDate = 0;
+            bufStats.satCount++;
+          }
+          pVal = &iDate;
+          memcpy(p, pVal, width);
+        }
       }
     }
   }

From 8da979923d73b82beb9a53d09720a6d03e6a27bd Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Wed, 5 Jul 2023 17:16:59 +0800
Subject: [PATCH 09/15] fix DATE convertion error

---
 utils/dataconvert/dataconvert.cpp | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/utils/dataconvert/dataconvert.cpp b/utils/dataconvert/dataconvert.cpp
index d6e4a47e2e..94672a911f 100644
--- a/utils/dataconvert/dataconvert.cpp
+++ b/utils/dataconvert/dataconvert.cpp
@@ -2101,7 +2101,7 @@ int64_t DataConvert::convertArrowColumnTime32(int32_t timeVal)
   // inMinute %= 60;
   inSecond = (timeVal - inHour * 3600000 - inMinute * 60000) / 1000;
   // inSecond %= 60;
-  inMicrosecond = (timeVal - inHour * 360000 - inMinute * 60000 - inSecond * 1000) * 1000;
+  inMicrosecond = (timeVal - inHour * 3600000 - inMinute * 60000 - inSecond * 1000) * 1000;
   if (isTimeValid(inHour, inMinute, inSecond, inMicrosecond))
   {
     Time atime;
@@ -2155,7 +2155,7 @@ int64_t DataConvert::convertArrowColumnTime64(int64_t timeVal)
   // inMinute %= 60;
   inSecond = (timeVal - inHour * 3600000000 - inMinute * 60000000) / 1000000;
   // inSecond %= 60;
-  inMicrosecond = timeVal - inHour * 360000000 - inMinute * 60000000 - inSecond * 1000000;
+  inMicrosecond = timeVal - inHour * 3600000000 - inMinute * 60000000 - inSecond * 1000000;
   if (isTimeValid(inHour, inMinute, inSecond, inMicrosecond))
   {
     Time atime;

From fc8ceab9133d7d0c572358507e0048cab60527d6 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Wed, 5 Jul 2023 21:22:29 +0800
Subject: [PATCH 10/15] add autoincrement support

---
 writeengine/bulk/we_tableinfo.cpp    | 35 +++++++++++++++++-----------
 writeengine/bulk/we_tableinfo.h      |  2 +-
 writeengine/dictionary/we_dctnry.cpp |  2 ++
 3 files changed, 25 insertions(+), 14 deletions(-)

diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index f9ba19fb74..90d835356f 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -346,7 +346,7 @@ int TableInfo::parseParquetDict(std::shared_ptr<arrow::RecordBatch> batch, unsig
 // }
 
 
-void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, unsigned int cbs)
+void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, unsigned int cbs, uint64_t& fAutoIncNextValue)
 {
   char biVal;
   int iVal;
@@ -549,13 +549,14 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             // FIXME: no fAutoIncNextValue in tableInfo
             // fill 1 temporarily
             // origVal = tAutoIncNextValue++;
-            origVal = 1;
+            origVal = fAutoIncNextValue++;
           }
         }
         else
         {
-          memcpy(&siVal, dataPtr + i, width);
-          origVal = siVal;
+          origVal = *(dataPtr + i);
+          // memcpy(&siVal, dataPtr + i, width);
+          // origVal = siVal;
         }
 
         if (origVal < column.fMinIntSat)
@@ -617,7 +618,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             // FIXME: no fAutoIncNextValue in tableInfo
             // fill 1 temporarily
             // origVal = tAutoIncNextValue++;
-            origVal = 1;
+            origVal = fAutoIncNextValue++;
           }
         }
         else
@@ -681,7 +682,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           }
           else
           {
-            origVal = 1;
+            origVal = fAutoIncNextValue++;
           }
         }
         else
@@ -742,7 +743,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           }
           else
           {
-            origVal = 1;
+            origVal = fAutoIncNextValue++;
           }
         }
         else
@@ -808,7 +809,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             }
             else
             {
-              llVal = 1;
+              llVal = fAutoIncNextValue++;
             }
           }
           else
@@ -1036,7 +1037,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           }
           else
           {
-            bigllVal = 1;
+            bigllVal = fAutoIncNextValue++;
           }
         }
         else
@@ -1084,7 +1085,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           }
           else
           {
-            ullVal = 1;
+            ullVal = fAutoIncNextValue++;
           }
         }
         else
@@ -1142,7 +1143,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           }
           else
           {
-            origVal = 1;
+            origVal = fAutoIncNextValue++;
           }
         }
         else
@@ -1209,7 +1210,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             }
             else
             {
-              origVal = 1;
+              origVal = fAutoIncNextValue++;
             }
           }
           else
@@ -1354,8 +1355,16 @@ int TableInfo::readParquetData()
         ColumnInfo& columnInfo = fColumns[k];
         RETURN_ON_ERROR(columnInfo.fColBufferMgr->reserveSection(bs * batch_processed, current_batch_size, nRowsParsed,
                         &section, lastInputRowInExtent));
+        uint64_t fAutoIncNextValue = 0;
+        int64_t nullCount = batch->column(k)->null_count();
         if (nRowsParsed > 0)
         {
+          if ((columnInfo.column.autoIncFlag) && (nullCount > 0))
+          {
+            rc = columnInfo.reserveAutoIncNums(nullCount, fAutoIncNextValue);
+          }
+
+
           unsigned char* buf = new unsigned char[current_batch_size * columnInfo.column.width];
 
           BLBufferStats bufStats(columnInfo.column.dataType);
@@ -1367,7 +1376,7 @@ int TableInfo::readParquetData()
 
           // parquetConvert(std::shared_ptr<arrow::Array>, JobColumn&, BLBufferStats&, unsigned char*)
 
-          parquetConvert(columnData, columnInfo.column, bufStats, buf, current_batch_size);
+          parquetConvert(columnData, columnInfo.column, bufStats, buf, current_batch_size, fAutoIncNextValue);
 
           updateCPInfoPendingFlag = true;
 
diff --git a/writeengine/bulk/we_tableinfo.h b/writeengine/bulk/we_tableinfo.h
index aee516ac5e..79a1581e8a 100644
--- a/writeengine/bulk/we_tableinfo.h
+++ b/writeengine/bulk/we_tableinfo.h
@@ -395,7 +395,7 @@ class TableInfo : public WeUIDGID
   // */
   // int parseParquet(std::shared_ptr<arrow::RecordBatch> batch, unsigned int k, int bs);
 
-  void parquetConvert(std::shared_ptr<arrow::Array> columnData, const JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, unsigned int cbs);
+  void parquetConvert(std::shared_ptr<arrow::Array> columnData, const JobColumn& column, BLBufferStats& bufStats, unsigned char* buf, unsigned int cbs, uint64_t& fAutoIncNextValue);
 
   /** @brief Read the parquet file data into the memory
    */
diff --git a/writeengine/dictionary/we_dctnry.cpp b/writeengine/dictionary/we_dctnry.cpp
index c2efe3b86c..e3447652cf 100644
--- a/writeengine/dictionary/we_dctnry.cpp
+++ b/writeengine/dictionary/we_dctnry.cpp
@@ -35,6 +35,8 @@
 #include <iostream>
 using namespace std;
 
+
+
 #include "bytestream.h"
 #include "brmtypes.h"
 #include "extentmap.h"  // for DICT_COL_WIDTH

From fb0abbf9b5d26a94b09a864fbe5b96572afd4e4c Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Sun, 9 Jul 2023 14:25:42 +0800
Subject: [PATCH 11/15] add mysql-tests, mcsParquetGen, revise decimal parsing

---
 .../basic/r/mcs287_cpimport_parquet.result    |  41 +++
 .../basic/t/mcs287_cpimport_parquet.test      |  36 ++
 mysql-test/columnstore/std_data/date.parquet  | Bin 0 -> 2655 bytes
 .../columnstore/std_data/decimal.parquet      | Bin 0 -> 610 bytes
 .../columnstore/std_data/double.parquet       | Bin 0 -> 3282 bytes
 mysql-test/columnstore/std_data/float.parquet | Bin 0 -> 2665 bytes
 mysql-test/columnstore/std_data/int16.parquet | Bin 0 -> 2679 bytes
 mysql-test/columnstore/std_data/int32.parquet | Bin 0 -> 2614 bytes
 .../columnstore/std_data/string.parquet       | Bin 0 -> 2224 bytes
 .../std_data/test-small-scale.parquet         | Bin 0 -> 18332 bytes
 mysql-test/columnstore/std_data/time.parquet  | Bin 0 -> 2660 bytes
 mysql-test/columnstore/std_data/ts.parquet    | Bin 0 -> 3365 bytes
 tests/parquetconvert-tests.cpp                |  29 ++
 tools/CMakeLists.txt                          |   1 +
 tools/parquetGen/CMakeLists.txt               |   6 +
 tools/parquetGen/main.cpp                     | 344 ++++++++++++++++++
 utils/dataconvert/dataconvert.cpp             |  79 ++++
 utils/dataconvert/dataconvert.h               |   2 +
 writeengine/bulk/CMakeLists.txt               |   2 +
 writeengine/bulk/we_tableinfo.cpp             | 126 ++++++-
 20 files changed, 654 insertions(+), 12 deletions(-)
 create mode 100644 mysql-test/columnstore/basic/r/mcs287_cpimport_parquet.result
 create mode 100644 mysql-test/columnstore/basic/t/mcs287_cpimport_parquet.test
 create mode 100644 mysql-test/columnstore/std_data/date.parquet
 create mode 100644 mysql-test/columnstore/std_data/decimal.parquet
 create mode 100644 mysql-test/columnstore/std_data/double.parquet
 create mode 100644 mysql-test/columnstore/std_data/float.parquet
 create mode 100644 mysql-test/columnstore/std_data/int16.parquet
 create mode 100644 mysql-test/columnstore/std_data/int32.parquet
 create mode 100644 mysql-test/columnstore/std_data/string.parquet
 create mode 100644 mysql-test/columnstore/std_data/test-small-scale.parquet
 create mode 100644 mysql-test/columnstore/std_data/time.parquet
 create mode 100644 mysql-test/columnstore/std_data/ts.parquet
 create mode 100644 tests/parquetconvert-tests.cpp
 create mode 100644 tools/parquetGen/CMakeLists.txt
 create mode 100644 tools/parquetGen/main.cpp

diff --git a/mysql-test/columnstore/basic/r/mcs287_cpimport_parquet.result b/mysql-test/columnstore/basic/r/mcs287_cpimport_parquet.result
new file mode 100644
index 0000000000..30e18fef7e
--- /dev/null
+++ b/mysql-test/columnstore/basic/r/mcs287_cpimport_parquet.result
@@ -0,0 +1,41 @@
+DROP DATABASE IF EXISTS mcs287_db;
+CREATE DATABASE mcs287_db;
+USE mcs287_db;
+CREATE TABLE t1(col1 INT, col2 FLOAT, col3 DOUBLE, col4 TIME, col5 VARCHAR(20), col6 TIMESTAMP, col7 DATE) ENGINE=Columnstore;
+SELECT * FROM t1;
+col1	col2	col3	col4	col5	col6	col7
+0	1.5	2.5	00:00:00	hhhh	0000-00-00 00:00:00	1970-01-01
+NULL	2.5	3.5	01:00:05	NULL	1970-01-01 08:00:09	1970-01-11
+NULL	NULL	4.5	02:00:10	hhhh	1970-01-01 08:00:19	1970-01-21
+NULL	4.5	NULL	03:00:15	hhhh	1970-01-01 08:00:28	1970-01-31
+4	5.5	6.5	04:00:20	hhhh	1970-01-01 08:00:38	1970-02-10
+5	6.5	7.5	05:00:25	hhhh	1970-01-01 08:00:47	1970-02-20
+6	7.5	8.5	06:00:30	hhhh	1970-01-01 08:00:57	1970-03-02
+7	8.5	9.5	07:00:35	hhhh	1970-01-01 08:01:06	1970-03-12
+8	9.5	10.5	08:00:40	hhhh	1970-01-01 08:01:16	1970-03-22
+9	10.5	11.5	09:00:45	hhhh	1970-01-01 08:01:25	1970-04-01
+10	11.5	12.5	10:00:50	hhhh	1970-01-01 08:01:35	1970-04-11
+11	12.5	13.5	11:00:55	hhhh	1970-01-01 08:01:44	1970-04-21
+12	13.5	14.5	12:01:00	hhhh	1970-01-01 08:01:54	1970-05-01
+13	14.5	15.5	13:01:05	hhhh	1970-01-01 08:02:03	1970-05-11
+14	15.5	16.5	14:01:10	hhhh	1970-01-01 08:02:13	1970-05-21
+15	16.5	17.5	15:01:15	hhhh	1970-01-01 08:02:23	1970-05-31
+16	17.5	18.5	16:01:20	hhhh	1970-01-01 08:02:32	1970-06-10
+17	18.5	19.5	17:01:25	hhhh	1970-01-01 08:02:42	1970-06-20
+18	19.5	20.5	18:01:30	hhhh	1970-01-01 08:02:51	1970-06-30
+19	20.5	21.5	19:01:35	hhhh	1970-01-01 08:03:01	1970-07-10
+20	21.5	22.5	20:01:40	hhhh	1970-01-01 08:03:10	1970-07-20
+21	22.5	23.5	21:01:45	hhhh	1970-01-01 08:03:20	1970-07-30
+22	23.5	24.5	22:01:50	hhhh	1970-01-01 08:03:29	1970-08-09
+23	24.5	25.5	23:01:55	hhhh	1970-01-01 08:03:39	1970-08-19
+24	25.5	26.5	24:02:00	hhhh	1970-01-01 08:03:48	1970-08-29
+25	26.5	27.5	25:02:05	hhhh	1970-01-01 08:03:58	1970-09-08
+26	27.5	28.5	26:02:10	hhhh	1970-01-01 08:04:07	1970-09-18
+27	28.5	29.5	27:02:15	hhhh	1970-01-01 08:04:17	1970-09-28
+28	29.5	30.5	28:02:20	hhhh	1970-01-01 08:04:27	1970-10-08
+29	30.5	31.5	29:02:25	hhhh	1970-01-01 08:04:36	1970-10-18
+SELECT COUNT(*) FROM t1;
+COUNT(*)
+30
+TRUNCATE t1;
+DROP DATABASE mcs287_db;
diff --git a/mysql-test/columnstore/basic/t/mcs287_cpimport_parquet.test b/mysql-test/columnstore/basic/t/mcs287_cpimport_parquet.test
new file mode 100644
index 0000000000..c4a5113306
--- /dev/null
+++ b/mysql-test/columnstore/basic/t/mcs287_cpimport_parquet.test
@@ -0,0 +1,36 @@
+if (!$MYSQL_TEST_ROOT){
+    skip Should be run by root to execute cpimport;
+}
+
+-- source ../include/have_columnstore.inc
+
+--disable_warnings
+DROP DATABASE IF EXISTS mcs287_db;
+--enable_warnings
+
+CREATE DATABASE mcs287_db;
+USE mcs287_db;
+
+CREATE TABLE t1(col1 INT, col2 FLOAT, col3 DOUBLE, col4 TIME, col5 VARCHAR(20), col6 TIMESTAMP, col7 DATE) ENGINE=Columnstore;
+
+# Generate data
+--exec mcsParquetGen -d a
+--exec mcsParquetGen -d b
+--exec mcsParquetGen -d c
+--exec mcsParquetGen -d d
+--exec mcsParquetGen -d e
+--exec mcsParquetGen -d f
+--exec mcsParquetGen -d g
+--exec mcsParquetGen -d h
+--exec mcsParquetGen -d i
+
+
+#Valid data and table
+--exec $MCS_CPIMPORT mcs287_db t1 $MTR_SUITE_DIR/../std_data/test-small-scale.parquet >/dev/null
+SELECT * FROM t1;
+SELECT COUNT(*) FROM t1;
+
+TRUNCATE t1;
+
+# Clean UP
+DROP DATABASE mcs287_db;
\ No newline at end of file
diff --git a/mysql-test/columnstore/std_data/date.parquet b/mysql-test/columnstore/std_data/date.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..4dc471c6fc0f9e21dc93dc87466208d20a91cdf8
GIT binary patch
literal 2655
zcmb`JF=!J}7{@QymrF>~<{Iv$?;uDJ`^b<MQ|Ok(#i>JZbPH`jLED&C>)b(#Wav<w
z#W9G3h?9tel+vL?hEC4n;LyQAI*9+jH@wST&ReeZYxw^8-tYY=<hyk5+-plAl~kM3
zkyh3E_fx`O4<#+>Nw0->T$EE+f~gW5s#(oYhrmWTIeYGwrN_CtwEYd&a(pGWd;5K9
z)tuU!9Da327yrlcThOtj&AVN^Kw?Vo29hRfo$ti-m@2^;>X{BfNbkp7vfj0=Pi+XA
zvk_97U<Y^IMRieeL8eM@hFH@f2nmjzWWi5)eUyiwIU6CR3EszD+o&B>T#%^}oFUe9
z2ttBCi^+n23i`YNL31`jN)vpJyADw!R9uj$5}YB{bO=I%@8**Qzm)W-1VM8)LP`^S
zg}Yv(#;CX;QzbY<tmzPh1g{p71rHbWMHzzTY=o31_yKo)MxCMJf=rd*46&v|5E6Xv
zCJTP8=;I0m&DjVkO>ly{zM;OO;(|<-;0&>*Ll6@DRZSLrQPq<r2%57IQkviu?z%>a
z+$=$+N^pi)(@hJ0l*xi;o<8v)XwF7RX@ZMXK;4`v$W#f=5No<=!Qactf-jf#WetMn
zY=ksR&~I&6%Guj`(0|<H3b$A6VE?a_Hy`o8)$!l@^=uyxe5^RSh!;GY0MB^22l!K)
ze4G4?cXPl$%9Ah1&v>;4{PP0&4*3~x#(+O6kzXV~<HZ*6FUsVX$j^8$1^nX*`DOAm
zUMm5AvPAwO`5AA8fPdnV?~<SKhdSV2*2u3~&BmZNeDbuvzq&OTtoDY(-Gj!n{&4T%
Z?oOk<zIJ=9?bqx0pwHtgVi#X6{{oq(GJ^mB

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/decimal.parquet b/mysql-test/columnstore/std_data/decimal.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..bd468450fdab2b2c9d7c42a40d3a837429ec85e4
GIT binary patch
literal 610
zcmb`FzfQw25XR4!$QXtyih5QoS&#)QLs}6;AE4^mp)j*VArh4+4Jm(KgOQPEU}NPG
z`Ung>2WJWuLt(09->18iPrv)*$?&Y8kRpo4ED!?#+1-QJ(K`Xf6z3$lDM{KS^wlKv
zeT~_#jNc&NAP@n%XJM&h1`$Y;>|E5<bXHywXsMqBA9v!^f0In^DF}f>#KJToDN<v?
z72N6Y<p&JcV8B%d<ESC~(pB~ihC(2?Wv~$p^`qe9KG3}(qy0H+6Pn2fkjO=KS<gxj
z-C<T-uYI`3#>M%$kBp*~$&KB*LEc#D6iXL?=Wl;c?~r$gwTqCYP1)Yu)wjK>X?kVb
d&L7hIx?N1?*J*LwKk668T3&Zw08IFIeF8N<V{`xj

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/double.parquet b/mysql-test/columnstore/std_data/double.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..88e17ae52393ef13561f02d7a0746bd49701d8a3
GIT binary patch
literal 3282
zcmcK7F>?|@6bJC-?&gLdX3m2>IfM)uWfLb5Aqk0z#GHMKjN=!;$c)aYATiorNoi?i
zk%G#hw9%3x1*KIA3rb2$D|g+!y>}Dt<}8j0dE{}te}1!Mmz+F#+Qb@e;Kni5F*1?3
zX%2so71eYw!g-vp(W?x4*Gq*ozru99N19`y^#xseokH(=N>T42GE0?k#%>u%w+s4<
z-ud&_U5qT<x=PV6@{FYaXR=+RzdXVUqTdW!5TZX<aOIe_C8p@mC+Ka3AxvyuN32Lh
z(XkW{0lW0&Y`m(cRE5m7#fHn2b(tc+RC1w81soDGdZFUllB_y3pWf~|{|c&xE=g5t
zR>6|ME}a0DWSCye;Y;#ICu4uP;S_(lVHd^YtO>?_Q8z+48<MjIIItV!jBZ46K4-{u
zNv;l@;&Wg(CZ{eK4|sJOVI2C5_Xkt=Ie~7FGg*$}e7i~JS&tK#A~}I>JdWEGj4e^O
zLpj?XhrY&-gxw%#b}NeW(;!1ba^RGZ*|FYi?v7xzMBNSL>`KlK;J|K><KigJ?;IKB
zBnM9MIj|dZb@l|~p{V<zoPEjJ102{5a=sLzIG=8li6uF3iqC=Fn4AN_cqD2&l+%`+
z1HggZAm_)OD9*S@X13(ODLw~wV{#4!<FTkmp`0VhIRqTo4RWqlqBzqsam$her}!M$
zUC6O(EmY9YPG5H4blAC?sVd$vjjXo))h;D{g0oKoI!V)#M~KEHe%R78n+9H}wB{9-
znD}|fiDUMmC$F)@#E&eVI9+0iI!jFaRN;y9EK5wY#Kbp#o;WmEVumFqzBlv4QH~{M
zSz_YbCr_MMEOD77CceY*#F@<!4VIYrCd3onGD|ekdZphPygTo{ub=k&_0C|>`&jwV
c9h|-Dy{$C2HXEBwyHujv<aZ6B6Z+rGUs`T|4*&oF

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/float.parquet b/mysql-test/columnstore/std_data/float.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..689d66466f82fe1c829182a38c8f25777f5c2a01
GIT binary patch
literal 2665
zcmb`}F=!fL6bJC{PCXB6>P7Cm-hqQd`{7_hEe&)iM7InXLZ_?}EGe|rnxxHGB$IRq
zlA(kQC1iBy5IP0P5S)T!D49a&kfB2dDH%$qzW06ipcjtQ;l$_hl=uCA2)=Wr_M*a*
z+~U?UTv(pL<8+a+VwE$V=lL=>;6sBO1viQB;_K<6qnG~cU_^&XB(#JszGww*dJ7ga
zJU8|7b+f+7nPWJgHF%1r!i+k{E2Dwy3|=g_Fb2KL-DLnM+HRGxuTU4rv$-AQT}a+;
z)nUk^4vxX23{6iwWa396)OV;khno1Ui-9hMG<@f%$-*({%o<~EEllXv@CzLKLh6FT
zBO^liEhRcBDWqW~q>fD%mO%FmYAIB>B!#7#I+nVi@TVCe{F@fTv=q|toueiTS3$Q9
zwH+$lmcmtENL^6azZW4KWJEV3g*2>$)J^dn?ttzS)Ly7?PYQQ@A$39FcqT&FnGvI`
z6w<H~Qa6S00CY!C{ZL_F3J-iCbwS~=6(JnvL@y_WG^~WwO(8r6-3ioLsPIe*k9{F^
zLE)c#gs__zm$Onx!%9fq6vA`ReTTXV6<$f<xi6$HC_Ld2!jUcZZ7HN-C8TZ&;SK11
zLEVN5Z>8|Y7g84#esm**y$9mjkwO|)Lh3?=UU`AJ#>U!u<4qlRx%o)<?*z<w?)AMw
z%=ZYqw-~~Ni_I9E9`}Za8v~p_(BW$97!db@Rso$91|%^c?)|C)hG`5iFd**rr~<kf
z3@|Yu?(L=mMp+EVU_ji<Nd@$B7?8z)xOa;RxSYj+`xp@SYES|DHU?N25ce-z1zbBA
zkY}Z0tKNRM)!3X{YqjR;?RN7+@qMGc@v8Z@Sa~x4c)sEl3b1M{_`kCPe=`38AtiY_

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/int16.parquet b/mysql-test/columnstore/std_data/int16.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..bf2c7b99eae3a5163889cfc9b132b01767a5daed
GIT binary patch
literal 2679
zcmb`Jv2W8r7{xEn#W88pxQWj_Ly$7iQ-`!7NM-86-l5_@h^k0*pbcq(9WkMd88e|y
zsA6P9OekZ<j2$aRM#R8-HPRUy*^8rmvA*Z;-un&7=NvzKK2%a^rH_=WL`U4cD)@9z
zN~k~u1KjaZZcj_9T5>29yNM10Z@Cqx`bd~hm7a2<17En2uAQD;4xcI!y5YwP-saGF
zc}CFyJVH4P_i+KmKYUdv1gP;&hL5V2oFSj>ASC#HRCD-#J7(#C&>l`%6%o1!tD`(r
zmXNBJoT07lAS4JsyE%m4YGzggp*@_kDk8jxum)-al_jLAC1+@BI|vEFpI#2(d(W)u
zAhd^5Rz-wOgtbtcs4O8>EjdG5+d)VWe%Z(&TsF+S0YZB?WmQDjMwpM<LS+f5YRMVe
z+73d3@K-B`aMm*GCJ61}lvNQSf6QG}fXWh5)si!`wH<^6;a5M0aMd=8HVEzElvNR-
zx=R;g8`mr$RgGN`6WR_!g7958hj898H(MaIhe>EVQADT_7NPE=vV>H%<P2?X2O&ZD
zUF8t219KIC&>l`%6%jr_SP%6Ol_jLAC1+@BI|vEF4?2f%v2AWc5Zc2jtN#&3g9D-6
zi<1}Qmm}_SXUF;bB-rU6U3Yzcsl&tQI_j1Du;4?+H6AYbR>HmPRUi8=9R@fID0@@K
z0kawdBm>G`v~j?y&H$GIW$(#2VBTPW$AGfeTpX}&GN8eLvbR(muxK-&$$+w#OdN2t
z#ehu)l)WS3fUAH3J_E}BiN^uAAp<&Mw?7$8U%eh*?ww2~d!y;}{B8fuczSVqe%2p8
T*?+u0jCx#B5&pRy<1gnQ1XTU9

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/int32.parquet b/mysql-test/columnstore/std_data/int32.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..f3e547e78c0cbc865736f56d8f5f70ab74384128
GIT binary patch
literal 2614
zcmb`JF>l&H7>3X1i!p={1HQ|-r4mDXVjxkel&wp5hN%AlMM%xigp#!V4@?~ym@;|j
zl%K(GK%Mywo%(*p(pfgH7b9MuzL)#ndxY?3Za#gUNFjacPbHVE$C8(1vL}0E>B#`{
z23nAPxGFKqRIoYZIu2)M?F=N3t^?*p+P%Afl1zE(mxH$%8~=YP(HIa+a)wKQg)!8D
z45nlQicUNsw*W@27WBE|BVj8T37F@&+-%(=U~5OM9rK5q7Y;Prnaeqfrlp?Zn;|q0
zCp91+0$wP??Ds~l7PLpPk+2mE!t)&NzGY_R9pQU+)U#tYCuT3eXIpbYReVhx(}GT+
zA|JV0&>o7l6^snu)-UDTHB8(9pKZ+rRq?fP)EU%)ihSg1L3=3HRxmPrtJ6}xP0Q??
z;Ipl{penv|92G!asK`gI7PN<AZ3QF4w>>N6+qF&H2A^%s1y%9UE!&4esK`gI7PN<A
zZ3QF4w+c%6Hs@yF0iSKn1y%9M<ZQ++uon5q)wstGe71s-;oJ5~`F33scfn^{iO*K7
zicjOH2zmt-`N-9R_E4;?U}X4KvXpNVntdO9wlx=2#rGOV4WKtrk&j$0Xb;8O3Py%+
zdr``_Qzlm6v#q(HV|>y0nrZLx_RIY1jD|LU$CH82)W_&|G^q7KKo1bl_*n20M0UNi
z9FG8`zi_M}r}%nDF(x?T_X2Au68c&v=^;LDP`sDW*E$GO`X<Hu34N_|ETwN#d@G@^
zbquBS9g1%!^tDcrl)g*xorJ#DA&}DdDLzQ(YrTh4dPVU)HX1Hw%WvQ3PnWlg#pP_d
geE2#1F<(C3J=_l`AFkeCO`-wKpua9-H~7c+4^*r3Pyhe`

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/string.parquet b/mysql-test/columnstore/std_data/string.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..89e8b7a68939f532dac74d02e9a2158270a1918a
GIT binary patch
literal 2224
zcmchZF;Buk7>2)IkF(Z_wQ__e9ay+901+chF76D(e?SNc4hk03)zL69F)=YQ7$)LC
zoSdAToSdBe9p1-H8ZRNa(5Agh+PkMuuKnJ&d45sll>6LoaKa$~pa9U78wVcnpv0NH
z$T*AYq)736Zr#d3L>_j^q97ivh<jnp2Nve+!7%2KW!VQy?&4H9e`kgzc|+g?WaG;Y
zU_$};M}S!t12M9-0?$N@NL2qlcMA&Rlvd$|iZM+<VX~uDcx7TDAK}(lVY;hTcyq*5
zz6)DdnC)p5-d!<s6Hu7%YZX2`G4~QsSR7~-KGR~6PC#LKs8#s##nMkeVRfWc_zuJ>
z*hC>L)gZ?P?QZ9)g`wpY$U5W-(1>JqWzWK=Ffxunj7ugQ*<}DE&pgo-aYPVF5NV!J
z3OS~Tq=+<69EF_V=OV)pX`UboIbE-%gGlp4P{^5!mM$XAD_kMx9wI$NnpdnsF4Blh
zBhtJA6>{k#(nq9uMJePeKx6>Le7_an+;)cLcE4Y4#c}UGf7gizm%ZzJ^`vrKsfH1j
L*`p26l>aI}#LZ6L

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/test-small-scale.parquet b/mysql-test/columnstore/std_data/test-small-scale.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..305867facabf41bd97628948398d09f04c7ecae6
GIT binary patch
literal 18332
zcmcg!4{TM{89(>+_U%z?t(Et<#ex;-M<;(QAb$juhua*oPMO9@SeSz1U=!$|DsyZ;
z5fvS>4lC&#V_jF#Y3Djb))B&pYYbz|FhdqX2xAK&#5LL(M;1cJe&2of_MCUmxqURf
zuQ#4|dcJ$U@BGg9efP(G?|gCLyn7}m?PMaEs87a{qC&V=QY0&q6%&&2WI0;A%CT9T
z{Y=@l$_U~ZT9IYN1hrUI$ynvIauKg|idL>}Oo~)I)nws6nm~#EtW-__2$75le3YXT
z0^{;zc|D6=PzUD<QJppct4=epgL6|c2Ih}^U`19@j1Cu7B@-U7;zu4`vos5>#Y(kU
zbSg%>V=g#fH(<#Kt}a<u58wD66T(hoNnE9Aw-Xf%c6f5Q;>Co2$MOEM(<xDFkYXPD
zAa2Eq#tM2rUX?8I(8nKM^VqUSm%E-lVWm!3)KyG9c9n0jBJKYbYTLLSC+Vo$NyKJ|
za(gw0BX<inOT9!8waO?La>p>43Gv32tCmll;zDk-Qf(F;NYIO%4xzS;5Z!dh<|rrN
z3S7Z-n2r=+x#NC%kcx^eThP%fs*<ICZmw%w>%z%csf<MzOXz4xRY2DWK?}MNne8oD
z2iL^O7I&J*68;@OFhaON_vT9}l$D@&mQ^Kf5AQJc;JU`8s~VKJw_QnpFXgyvhC<96
zcNB<w2|x@t?ZRfMjJq7=qTX?}68DFfHs;3t?Q*(s72+<n0aY0ZBSeJ;IPS$+cmaN5
zsblkfet6{w0+*lSOasTSk?8vPDN6!96?Cuy(4=O-juBdp_nOi|bfO*AAAI0C>atW5
zKk&-PgXcZyEh!^SWgnV1lXQN#OH(1Hj0mff)sjQ8nivU$e2r$5xlZ(mXmlTij7-A`
z1}W5~Q#V$c+3Ap#I%LuL5wveaA3I%!Y2z*wKRfZ)M0Mh%s4cn1(w;S&rH;*W*w1q0
zA@=-y?pm1#Iy+q$N$-z@qosDhmJ#CRuoEC@>=d`GxS%bgL)oco6m1z*H9c3?2ti?|
z%%A@3vXNN4j3Xs7y%*eG^H{>a<0O0??A9R7^<YnR9(Fo)9c{Y~aldTy#vLhf9}NJt
zXj9O%UDzyjY@Wlhk|PLs-(K90-=M@@W2cYC(B3hKyVMTY$_Fuyl|F~YPmB(crH;*W
z*sL5upg`P75@H`kWeK3OhAxf;KB*coln<W}y=kDE2ORTsd@N;x@AW9kALZgZRof3m
z^^T+c<6MgJl^LNlZ02_*ZLt=v>(g#0Zt(gVolw~axN7>S>Uu_PkYbYJ-4o-@T$O#3
zI&vdrZtUZ#%dnl#;dP}8teIs`Tj}yH16Q%sv3U-ANse+MADko;Lg%UvC(_P|@VL|t
z*fK&K99NyG3+1Y&Iy!UHK)Fgh|8fxrGc#%eas}6(ZnxJ`G~wUDOOL1H2Hl%4rLds{
zy?bgNuG%|=KAOyN*9?W2H#$|}syP5~2iih3Z5K969h>KHtmFs+1$F0iCGHwmy*G`v
zPD9+KcEDCXh{LcNzwBLsrbA?@WAhv~D@PD05YNw)5CdGbc_tm30en(5U??9xkUe;6
zCfa->SIu|1s&*cm<vGk;tfAuDJG&pQIy8%#XSrPED+f#&5o%mDE{!#DeLn4WVtgo9
zjql^CaSB(dQdm&DyZg5OxT^hDIzFe5t5hr4hR1`d)J(lf&d#s+#9BC<VvABs@Et4o
zt&gRS&2!jGa+C|XWu8n3ovYqV)A_mZxYQ2VGJ1S)T($oTp<H$DcG`dYK)EWjU<rRi
z5aOTzb^FW{Tlrsf{Siv|ckl}2>2P3lDU_9<@3<omS8e?gz4t|aukseoYu@NoCGLv>
z;9<1Yrd{B>J`(}Y;aJHL1PbcScPeq$xa!sUboR@LyVMTY$_KF&t6hm!hNh<`OC6i%
zuvs~RK!NzdS0uy$SDju!9SeX@ss;?@!zaWdFwY9K^+v8*@3PY(kE{GqF21dI^}|)I
zU!|UUm#chbM##%C?O|~vLXE2?rm-fjo6>HVsSD#O+`+$w?ln<zRgM%l74N?Iwf?y3
z;@#AFx6f5MR<MoiIyqAFc9fib&}ojX82Oi2LshIuPY9MeHqT)%$x$xk-g{+2=v=k&
zUi#o3cwA}+Y#BX1IIe2`dMH;NypNji8z@(avT^)vL}c3k==NgvBG=iP#}fV>1l`kd
z1LMt?(p(RIwkQu*oxPu4y`ST*8459PbgB~f^#HIDZ3~*V3!9~m&2u<bas+{rs;9r9
z#9ia6PZ!gH#fZDq4%o^E@hYrVj&?Pg4w0pf&2!kS96_K!-1SWfF~C(_OK8&);FGEW
zL;3Itu?al21+Cf0Rn0D?Z1T9uALZgZ`(Qs@^}h$G`vI4$d}T(+%Q07BaU;SYS7j!r
zu_khNiq}sK<*KPZS3w6$d3>TuVMp=qzaHw3tBx(B&CB|@O0^PV+qfMyXGh;sl&Nkg
z+C1iU16Q#WIg2^$B{|B4eCQFG5IR?#SWdf^!{bsrV9N+`a9q{1B9yCIR#4Bk2Fg{L
zzx8GVx8eo<)*&*NuIFzj`XiL^@8HG9)8WAAQYb4yKk}VCTy@~v^yx}|ukseoYu@No
zCGOh+pcU;+G@S@o>exJoV<krrD5$$uD{<Gj>hLPsz6x=d+5ubnAXZ?tYtZ`p!Jp@_
z+3ZjDJi?_wywo5e2DqxJfljUgKB*coln<W}JHS)zXdOnb>ToG#hsRa^C>P&>b^UPF
z(Y3T=t;<!uG9%>Wn5(e35uwIaH>cStA~VhFr-yRY^ggb-S>Y;G3OkB-_dVVpS9Lr_
zryKjYO0|M*cs!^|&D&9OwrT9Cq83Wpt+n-h8XGwIW2s~F9QKkN<w9=#o=gaxt9Gxa
zOHaV#QafPF=<&gERrmKpxvKX`>V9&dTqR!FSAso@%=mlx=M5p=`?uR`9!vOl@CxMV
zxPkHJODSw9L2v(I9<JK{13J8c<E|MBF>iFL68Aj-Z~*NPnzjp@rH;*WI9755fr7f}
zY31-gu8~z6&RIWx3Xzxk0c-g{CS3qRj6ko0WT}Is&4QF82o#Vfo>4#s=&ENU&eAtp
zfGD*Yq8#OYe(=*J$Z9`Yw~?^AU0&Ja5tcv7h1mKWAR1~FvS$FhpS9@HCI-oC@TX?Y
z=tqsSW~8w!a(JfK-xA7MxAbw=4282)DeNddZhHY62rpM?-fYpK=dptXuP-vHAvb+B
zX<oO#apN;~=Y)NB*QEa#Xp5ze&2u=Ka)fmh)LXYGnW6Jm>yIqzd6E4t4Ft>?{XRJ6
z>e>oWAw>&kUP8LQWDS(OGK)5qvWLYdRs55R$UOV5+iOo$!oPzzAy0?Hqf22#@#D^)
z0CK-|3r(m7>i#h&fNm>f1*2;f{`wFYPNJPf(>7wW)UkOEM@)_&P=Gfzs|ld<*UR9q
zZJYqoK)_r+lnxfGL>q~wqhu*guJOrc<p=@=<;m>|$^e0V{E9{UUSWt*J76mxL?MoV
zypExrG!ocJmvWAH1m=%&A-4S#5JL%U4+^d_s1sxA^7R>{9GM??jlgE5u`Kd;w%5-I
zC9pYt1U5?{FjWdWijUiOU<2U<w*6-o9e$Pbm)92=)ev@KkeYX-<nO_{+Tue~9w<I~
z^Y&srGg#`_Jck`6N4cn*exYQBPGD_2k-tA@ze@uFbH?Nt9D(ioB|wD`*x6R3YwLgs
zOjO;)Kh%oM?z3($?tF@WPtl*KgntKt@^swrc=M$c%1ZQG+X1;>0^9a0i{5W@6F{>S
zvVzgIN&@r(!v!?kGHk?VsbljTj+h+f0^jz!ngAMswePa1_ccxcX&_)OAIfX7U=`XZ
zG(AmO>exJo&B_r3ihED}T0t2gu--Q;+W!Val-dDX`5+2$2ISR)_L-5uK644|j7MPp
zC>LUT2Ox$L*xt7++V~cO<TdzHvt|UT5!kJ1EQ>t8&Fkle64=~60=rcqFjWdWijQ~w
z78?jBu$H$iI`SJge_a5oA-LNkFjbnDz>ZJ<Yw_uscKqC|*(iw(esN@}WAhx2rX1y>
z-nLuG44uH*e~0|-WWP%T0dq#b501e0?*XU~0z3B(()FDI6IkXSBlrhmAs+8^`%LMb
z{A;fML?!$?cvJFpI6S%(%1ZRxeh<j~5?J$Iyn?^W3832wS;6R9g}};~qR_^m=?TD6
zoUh@NBPK_=z?=7}37`?!u0L4xX%{DeG!QUnLRq<GnsDOl9$K+{)zV}cO3Z6wZf&|q
zCh%9b7+fSv@V8f5ot@$(U`<*5hO4WX^sui|Rz>M>ji_fy(#BYp=GIiyZ>jL7@+#h!
z;F{9<M=?7!r?R7RL!>40k(ad>zS5i`FAR^Mu$zXW)|w(OjZU==OT{UH4!^J>wW6(V
zrl^aNso;ge6nR~51a-MI6s58hd1Y%hxeiuvcEvcmqAg6NsOw0n;H8}uc_k(dzLJuL
zqPUSFuSHDlXX?5*7X5IWvn$$CLW;Wbj|yIlN0Hag(co*}Xei3jDDvvDY<3-+!Pyn(
z?25Mdi=wX8qJo!CQRLN5H27*I8j1oUioD(@n_V3XIJ**@UD1~7P}J2mRPcfqio8CB
z247!7Ls9ZUkymJBvuo25&aM*9u4oG^DC&9$DtL(kMP5-rgRcmnp*W<c0-UL5^Xudq
z&aYC=ugH(YsQ@R~G!%!*RERTRisTHJhUi$83ULaWO*xcSaL$!+&P9HTNd-7`q@g$m
zq(U6qQ6$H1G(;z1REUGCY|h~{oO7<6b1w3OCn~@>5e>!B4He>~g(5jAp&>fFphBEA
zWOEJ&n4EJJqPDtW>Duo;w!CrTLk$fRm#$sA=85XZm#<y7a?R@M$x|lPO`2S}0mlgX
Of8t$Kfh@%Tm*@Xm+KO`k

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/time.parquet b/mysql-test/columnstore/std_data/time.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..5ea5fe0592ab1fc7d11f598af6e0c1c5c95fc6dc
GIT binary patch
literal 2660
zcmb`JKWGzC9LL|iyt{;$Cf9f`eJ4SJw2vTZXp7aV9dr}vP@G&uLkYA)+nClrgM)uS
zigd^j#8CuMiikK!5r+;^O2r}_ii3z_2SEh~aS-3PH$3l>^Og&D9KT<Fzt4TR<Ne-E
zo<29s85dkkaEp^X+54sFF=Deh!U=b{Q&Ioe>a>c2AuAY)3Z(o`q!Lt}mO&H!M6MV`
zPTf(PSgv4;GqZJ03RdBfp$<7NQ~%?*6{SNs#l3BHA;hmItjDC3`b5g<{YIxAvVx%o
zdOGs!?IyzYep9(lm7wkokfH>KGG~pk>@DMzz1l?(S;0^Ptd9JGD^|GR8&fWsN>KL(
zNKt}k^52X}N7D0!3$*hIA}bhbfYp&-@M|hu@J~{1CY7M>4UnP)FNrptKJbn<iZszF
zh^%0!0aizT!RPzJ1=rGYIjsbBZ-5jfc>Un<#LZG8v2^H37eQnNLk+Mx@(X_N2^YNG
zBeyb2Q1=E%QG%`h&xr?;vxnsgET+I3MpiJ?0IMUv;7dDP@NG`Ea!OG521rqYPY>T=
zFDkFuYV}7KL1YC(4X`@$3;xW93*ODk?Or9Qdjq5>!L^~XxiNCl{BY#H+4%&K6$~}N
z>c}tniiZnsII`_1LERf5MG1a9`riC9#;n~FC)L~zzG7qrLk+Mx@(cdz3m3fCCwB@;
zQ1=E%-2~mrC=u4e)O3Beh7nE&)GWdLAIMJJ=q(o2?bXIH?mlyi@$M1WTP&GU7l#l9
zk9op-_;m_C1wZBi?eUjP@EQ0q&sUGXnFQYgKj!i1@t4!!r@)VSx_SJq4ESmAV;)W(
zzm)?&1Aff2#p7@Hf}aIH=F#Bs+Yb0P_%W|+kH1p@KTpb~My+}IN_}x~s?iv%HJkI-
dN>}U6g_-%e((p)is5<QKEp=OcCr+yG%fH^BkqH0*

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/ts.parquet b/mysql-test/columnstore/std_data/ts.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..fc0ea341d957b2903f6b12b2794ea986037e3773
GIT binary patch
literal 3365
zcmchaO=uHA6vtmax=q?9Zqsa%ty`^N$AW2Tgr4-`u~MX{haz~0CD0yfV_MszgH%Ki
z4_c*XDbj-n5tSl>pdPC9;<Xg~IOsvp9Q5L$IPdMOn`OETUUo@%yYpuL|NXtm&TJ-5
zo~c+#Ys4BEw+st%@bBRFSKafWN(@gdu<};EEP9#ZYdED8$c#9XM*#-+Xcfu0_!_Zz
z;xMo;F~>^Uqb3-3DZMZ=Tbo~~&ekm`7=`Va_^@*<^*`cvS=>KZalAoO1aYSU9{%PX
z-9Mbah)LkhKNM9SFH=f+V~|H}6(TJ>*V;5ZzY=UcA&69=5P2OD+_;+{lD={hBRqXe
zQ6=&+Vus`xnjzWWZxtFXL=RIMqSbb`MLz&VC`4XI#7|vlBa+X*De|S;241T~UPhEt
zj-evT{(fta=zXV#=w%0Mrg4rGp%8f;5oC|FBLQD~MG=lq(o>=mc^NSqatsww_V-(Z
zL_e|`qE8vNlELRl5ekvl5%CXA_c@=wnI^K`Lme1ZA}%wcoN^2mQE3el-N|W)mb=-8
ziF2d~g~;oO;NA-&;78APA_=_yPEjTDGNPPv3>8uK_gjNR&n*qndY<j{;2bGJA@VvR
zKDpdQBtM-DMt=PnMU}|Qh;qs?R7Ba|Zw(S{mo!9MMaGLbM~YC0yp9N*(^(>U@|7Zt
zUEPP*Dv_5F<&<Nnh_b)m8YJ4?uOVvovbA2EBSk1gUPr_~7EL68#m5wR*H|}RszhE!
zlv9qOBFg@Ls~Fs}dOtX*AzC@WHv4dn6rm9Ly@>4cD3px(sp;Bm75CocK)hu)AIOd0
z$~g{VLE(h`$aW&w_VM+>U?~yu0KzefjoI~FPoQZWO{3U5UDGXmU&<%ZG>YxbHEpKR
z)IifHb|BYuC4;6ZG>u}Da7{N%H0?msDAsY;bf*VRyU;X>rPej&MKsN#X%wrWYr58p
zrY4$3v0%BTn|)}SgTelKwQ>1MZDDAtULUG98gonii?zo5%-p5^%CX^*;fhU**EjK6
JJt6)e{RP;~@nHY}

literal 0
HcmV?d00001

diff --git a/tests/parquetconvert-tests.cpp b/tests/parquetconvert-tests.cpp
new file mode 100644
index 0000000000..9659d64a5a
--- /dev/null
+++ b/tests/parquetconvert-tests.cpp
@@ -0,0 +1,29 @@
+#include "gtest/gtest.h"
+
+#include "dataconvert.h"
+using namespace dataconvert;
+#include <arrow/api.h>
+#include <arrow/io/api.h>
+#include <parquet/exception.h>
+
+
+
+// int32
+TEST(ParquetConvertTests, Convert)
+{
+  arrow::Int32Builder builder;
+  int reserve_num = 30;
+  PARQUET_THROW_NOT_OK(builder.Reserve(reserve_num));
+  std::vector<bool> validity(reserve_num, true);
+  validity[1] = 0;
+  validity[2] = 0;
+  validity[3] = 0;
+  std::vector<int32_t> values;
+  for (int32_t i = 0; i < reserve_num; i++)
+    values.push_back(i);
+  PARQUET_THROW_NOT_OK(builder.AppendValues(values, validity));
+  std::shared_ptr<arrow::Array> array;
+  PARQUET_THROW_NOT_OK(builder.Finish(&array));
+
+  
+}
\ No newline at end of file
diff --git a/tools/CMakeLists.txt b/tools/CMakeLists.txt
index c7f96e1214..b1e0945a4e 100644
--- a/tools/CMakeLists.txt
+++ b/tools/CMakeLists.txt
@@ -13,3 +13,4 @@ add_subdirectory(idbmeminfo)
 add_subdirectory(rebuildEM)
 add_subdirectory(passwd)
 add_subdirectory(configMgt)
+add_subdirectory(parquetGen)
diff --git a/tools/parquetGen/CMakeLists.txt b/tools/parquetGen/CMakeLists.txt
new file mode 100644
index 0000000000..1d77b0e88a
--- /dev/null
+++ b/tools/parquetGen/CMakeLists.txt
@@ -0,0 +1,6 @@
+include_directories(${ENGINE_COMMON_INCLUDES})
+
+set(parquetGen_SRCS main.cpp)
+add_executable(mcsParquetGen ${parquetGen_SRCS})
+target_link_libraries(mcsParquetGen ${ENGINE_LDFLAGS} ${ENGINE_WRITE_LIBS} boost_system boost_filesystem arrow parquet)
+install(TARGETS mcsParquetGen DESTINATION ${ENGINE_BINDIR} COMPONENT columnstore-engine)
diff --git a/tools/parquetGen/main.cpp b/tools/parquetGen/main.cpp
new file mode 100644
index 0000000000..68e1acbbb8
--- /dev/null
+++ b/tools/parquetGen/main.cpp
@@ -0,0 +1,344 @@
+#include <iostream>
+#include <string>
+#include <boost/algorithm/string/case_conv.hpp>
+#include <arrow/api.h>
+#include <arrow/io/api.h>
+#include <parquet/exception.h>
+#include <parquet/arrow/reader.h>
+#include <parquet/arrow/writer.h>
+
+
+void generateIntTable()
+{
+	// generate data
+  arrow::Int32Builder builder;
+  int reserve_num = 30;
+  PARQUET_THROW_NOT_OK(builder.Reserve(reserve_num));
+  std::vector<bool> validity(reserve_num, true);
+  validity[1] = 0;
+  validity[2] = 0;
+  validity[3] = 0;
+  std::vector<int32_t> values;
+  for (int32_t i = 0; i < reserve_num; i++)
+    values.push_back(i);
+  PARQUET_THROW_NOT_OK(builder.AppendValues(values, validity));
+  std::shared_ptr<arrow::Array> array;
+  PARQUET_THROW_NOT_OK(builder.Finish(&array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("int", arrow::int32()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/int32.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+
+}
+
+void generateFloatTable()
+{
+  int reserve_num = 30;
+  arrow::FloatBuilder builder;
+  PARQUET_THROW_NOT_OK(builder.Reserve(reserve_num));
+  std::vector<bool> validity(reserve_num, true);
+  validity[2] = 0;
+  std::vector<float> values;
+  for (int i = 0; i < reserve_num; i++)
+    values.push_back(i+1.5);
+  PARQUET_THROW_NOT_OK(builder.AppendValues(values, validity));
+  std::shared_ptr<arrow::Array> array;
+  PARQUET_THROW_NOT_OK(builder.Finish(&array));
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("float", arrow::float32()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/float.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+void generateDoubleTable()
+{
+  // -----------------Float64-----------------------
+  int reserve_num = 30;
+  arrow::DoubleBuilder doublebuilder;
+  PARQUET_THROW_NOT_OK(doublebuilder.Reserve(reserve_num));
+  std::vector<bool> dvalidity(reserve_num, true);
+  dvalidity[3] = 0;
+  std::vector<double> dvalues;
+  for (int i = 0; i < reserve_num; i++)
+    dvalues.push_back(i+2.5);
+  PARQUET_THROW_NOT_OK(doublebuilder.AppendValues(dvalues, dvalidity));
+  std::shared_ptr<arrow::Array> doublearray;
+  PARQUET_THROW_NOT_OK(doublebuilder.Finish(&doublearray));
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("double", arrow::float64()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {doublearray});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/double.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+void generateTimeTable()
+{
+	int reserve_num = 30;
+  arrow::Time32Builder time32builder(arrow::time32(arrow::TimeUnit::MILLI), arrow::default_memory_pool());
+  // int reserve_num = 500;
+  PARQUET_THROW_NOT_OK(time32builder.Reserve(reserve_num));
+  std::vector<bool> time32validity(reserve_num, true);
+  std::vector<int32_t> time32values;
+  for (int32_t i = 0; i < reserve_num; i++)
+    time32values.push_back(i*3605000);
+  PARQUET_THROW_NOT_OK(time32builder.AppendValues(time32values, time32validity));
+  std::shared_ptr<arrow::Array> time32array;
+  PARQUET_THROW_NOT_OK(time32builder.Finish(&time32array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("time", arrow::time32(arrow::TimeUnit::MILLI)),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {time32array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/time.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+void generateStringTable()
+{
+	int reserve_num = 30;
+  // ----------------- String -------------------------
+  arrow::StringBuilder strbuilder;
+  PARQUET_THROW_NOT_OK(strbuilder.Reserve(reserve_num));
+  uint8_t validity1[reserve_num];
+  std::vector<std::string> values1;
+  for (int64_t i = reserve_num-1; i >= 0; i--)
+  {
+    values1.push_back(std::string("hhhh"));
+    validity1[i] = 1;
+  }
+  validity1[1] = 0; // set element 1 null
+  PARQUET_THROW_NOT_OK(strbuilder.AppendValues(values1, validity1));
+  std::shared_ptr<arrow::Array> strarray;
+  PARQUET_THROW_NOT_OK(strbuilder.Finish(&strarray));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("str", arrow::utf8()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {strarray});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/string.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+void generateTimestampTable()
+{
+	int reserve_num = 30;
+  // ----------------- Timestamp -------------------------
+  arrow::TimestampBuilder tsbuilder(arrow::timestamp(arrow::TimeUnit::MILLI), arrow::default_memory_pool());
+  PARQUET_THROW_NOT_OK(tsbuilder.Reserve(reserve_num));
+  std::vector<bool> tsvalidity(reserve_num, true);
+  std::vector<int64_t> tsvalues;
+  for (int64_t i = 0; i < reserve_num; i++)
+    tsvalues.push_back(i * 10000000);
+  PARQUET_THROW_NOT_OK(tsbuilder.AppendValues(tsvalues, tsvalidity));
+  std::shared_ptr<arrow::Array> tsarray;
+  PARQUET_THROW_NOT_OK(tsbuilder.Finish(&tsarray));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("timestamp", arrow::timestamp(arrow::TimeUnit::MILLI)),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {tsarray});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/ts.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+
+}
+
+void generateDateTable()
+{
+	int reserve_num = 30;
+  // -------------------------DATETIME
+  arrow::Date32Builder date32builder;
+  PARQUET_THROW_NOT_OK(date32builder.Reserve(reserve_num));
+  std::vector<bool> date32validity(reserve_num, true);
+  std::vector<int32_t> date32values;
+  for (int32_t i = 0; i < reserve_num; i++)
+    date32values.push_back(i * 10);
+  PARQUET_THROW_NOT_OK(date32builder.AppendValues(date32values, date32validity));
+  std::shared_ptr<arrow::Array> date32array;
+  PARQUET_THROW_NOT_OK(date32builder.Finish(&date32array));
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("date", arrow::date32()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {date32array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/date.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+void generateInt16Table()
+{
+	int reserve_num = 30;
+  // ---------------int16
+  arrow::Int16Builder i16builder;
+  PARQUET_THROW_NOT_OK(i16builder.Reserve(reserve_num));
+  std::vector<bool> i16validity(reserve_num, true);
+  std::vector<int16_t> i16values;
+  for (int16_t i = 0; i < reserve_num; i++)
+    i16values.push_back(i);
+  PARQUET_THROW_NOT_OK(i16builder.AppendValues(i16values, i16validity));
+  std::shared_ptr<arrow::Array> i16array;
+  PARQUET_THROW_NOT_OK(i16builder.Finish(&i16array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("int16", arrow::int16()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {i16array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/int16.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+void generateDecimalTable()
+{
+  // ----------------------decimal
+  auto t = arrow::Decimal128Type::Make(9, 3);
+  PARQUET_ASSIGN_OR_THROW(auto t1, t);
+  arrow::Decimal128Builder d128builder(t1, arrow::default_memory_pool());
+  // std::cout << arrow::Decimal128("138.3433").kBitWidth << std::endl;
+  PARQUET_THROW_NOT_OK(d128builder.Append(arrow::Decimal128("138.3433")));
+  PARQUET_THROW_NOT_OK(d128builder.Append(arrow::Decimal128("532235.234")));
+  PARQUET_THROW_NOT_OK(d128builder.AppendNull());
+  PARQUET_THROW_NOT_OK(d128builder.Append(arrow::Decimal128("5325.234")));
+  std::shared_ptr<arrow::Array> decimalArray;
+  PARQUET_THROW_NOT_OK(d128builder.Finish(&decimalArray));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("decimal", arrow::decimal128(9, 3)),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {decimalArray});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+	//TODO: revise the path
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/decimal.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+int main(int argc, char** argv)
+{
+  int32_t option;
+
+  while ((option = getopt(argc, argv, "d:")) != EOF)
+  {
+    switch (option)
+    {
+      case 'd':
+      {
+        char col = optarg[0];
+
+        switch (col)
+        {
+          case 'a':
+          {
+						generateIntTable();
+						break;
+          }
+					case 'b':
+					{
+						generateFloatTable();
+						break;
+					}
+					case 'c':
+					{
+						generateDoubleTable();
+						break;
+					}
+					case 'd':
+					{
+						generateTimeTable();
+						break;
+					}
+					case 'e':
+					{
+						generateStringTable();
+						break;
+					}
+					case 'f':
+					{
+						generateTimestampTable();
+						break;
+					}
+					case 'g':
+					{
+						generateDateTable();
+						break;
+					}
+					case 'h':
+					{
+						generateInt16Table();
+						break;
+					}
+					case 'i':
+					{
+						generateDecimalTable();
+						break;
+					}
+					
+        }
+      }
+    }
+  }
+  return 0;
+}
\ No newline at end of file
diff --git a/utils/dataconvert/dataconvert.cpp b/utils/dataconvert/dataconvert.cpp
index 94672a911f..2e0026b478 100644
--- a/utils/dataconvert/dataconvert.cpp
+++ b/utils/dataconvert/dataconvert.cpp
@@ -515,6 +515,85 @@ void number_int_value(const string& data, cscDataType typeCode,
   }
 }
 
+void parquet_int_value(int128_t& bigllVal, int columnScale, int columnPrecision, int fScale, int fPrecision, bool* bSatVal)
+{
+  int128_t leftPart = bigllVal, rightPart;
+  for (int i = 0; i < fScale; i++)
+  {
+    // bigllVal
+    leftPart /= 10;
+  }
+  // int128_t tPart = leftPart;
+  for (int i = 0; i < fScale; i++)
+  {
+    leftPart *= 10;
+  }
+  rightPart = bigllVal - leftPart;
+
+  // apply the scale
+  if (columnScale > fScale)
+  {
+    for (int i = 0; i < columnScale - fScale; i++)
+    {
+      rightPart *= 10;
+      leftPart *= 10;
+    }
+  }
+  else
+  {
+    for (int i = 0; i < fScale - columnScale; i++)
+    {
+      leftPart /= 10;
+      rightPart /= 10;
+    }
+  }
+
+  bigllVal = leftPart + rightPart;
+  // is column.width always 16?
+  // if (LIKELY(column.width == 16))
+  // {
+  int128_t tmp;
+  utils::int128Min(tmp);
+  if (bigllVal < tmp + 2)  // + 2 for NULL and EMPTY values
+  {
+    bigllVal = tmp + 2;
+    *bSatVal = true;
+  }
+  // }
+
+  if (columnScale > 0)
+  {
+    int128_t rangeUp, rangeLow;
+    if (columnPrecision < 19)
+    {
+      rangeUp = (int128_t)columnstore_precision[columnPrecision];
+    }
+    else
+    {
+      auto precision = 
+          columnPrecision == rowgroup::MagicPrecisionForCountAgg ? datatypes::INT128MAXPRECISION : columnPrecision;
+      if (precision > datatypes::INT128MAXPRECISION || precision < 0)
+      {
+        throw QueryDataExcept("Unsupported precision " + std::to_string(precision) + " converting DECIMAL ",
+                              dataTypeErr);
+      }
+      rangeUp = datatypes::ConversionRangeMaxValue[columnPrecision - 19];
+    }
+    rangeLow = -rangeUp;
+
+    if (bigllVal > rangeUp)
+    {
+      bigllVal = rangeUp;
+      *bSatVal = true;
+    }
+    else if (bigllVal < rangeLow)
+    {
+      bigllVal = rangeLow;
+      *bSatVal = true;
+    }
+  }
+}
+
 // Explicit template instantiation
 template void number_int_value<int64_t>(const std::string& data, cscDataType typeCode,
                                         const datatypes::SystemCatalog::TypeAttributesStd& ct,
diff --git a/utils/dataconvert/dataconvert.h b/utils/dataconvert/dataconvert.h
index 9ebed758e2..99d0b2474a 100644
--- a/utils/dataconvert/dataconvert.h
+++ b/utils/dataconvert/dataconvert.h
@@ -1081,6 +1081,8 @@ inline uint64_t string_to_ull(const std::string& data, bool& bSaturate)
   return value;
 }
 
+void parquet_int_value(int128_t& bigllVal, int columnScale, int columnPrecision, int fScale, int fPrecision, bool* bSatVal);
+
 template <typename T>
 void number_int_value(const std::string& data, cscDataType typeCode,
                       const datatypes::SystemCatalog::TypeAttributesStd& ct, bool& pushwarning,
diff --git a/writeengine/bulk/CMakeLists.txt b/writeengine/bulk/CMakeLists.txt
index 66c01501a1..b51b51be36 100644
--- a/writeengine/bulk/CMakeLists.txt
+++ b/writeengine/bulk/CMakeLists.txt
@@ -40,10 +40,12 @@ set(cpimport.bin_SRCS cpimport.cpp)
 
 add_executable(cpimport.bin ${cpimport.bin_SRCS})
 add_dependencies(cpimport.bin marias3)
+
 target_link_libraries(cpimport.bin boost_program_options ${ENGINE_LDFLAGS} ${NETSNMP_LIBRARIES} ${ENGINE_WRITE_LIBS} ${S3API_DEPS} we_bulk we_xml)
 FIND_PACKAGE(Arrow)
 FIND_PACKAGE(Parquet)
 target_link_libraries(cpimport.bin arrow)
 target_link_libraries(cpimport.bin parquet)
+
 install(TARGETS cpimport.bin DESTINATION ${ENGINE_BINDIR} COMPONENT columnstore-engine)
 
diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index 90d835356f..43769b9d91 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -554,7 +554,18 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         }
         else
         {
-          origVal = *(dataPtr + i);
+          // origVal = *(dataPtr + i);
+          if ((column.dataType == CalpontSystemCatalog::DECIMAL) ||
+              (column.dataType == CalpontSystemCatalog::UDECIMAL))
+          {
+            const int128_t* dataPtr1 = reinterpret_cast<const int128_t*>(dataPtr);
+            // auto dataPtr1 = std::static_pointer_cast<int128_t>(dataPtr);
+            origVal = *(dataPtr1 + i);
+          }
+          else
+          {
+            origVal = *(dataPtr + i);
+          }
           // memcpy(&siVal, dataPtr + i, width);
           // origVal = siVal;
         }
@@ -623,8 +634,9 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         }
         else
         {
-          memcpy(&usiVal, dataPtr + i, width);
-          origVal = usiVal;
+          origVal = *(dataPtr + i);
+          // memcpy(&usiVal, dataPtr + i, width);
+          // origVal = usiVal;
         }
 
         if (origVal < column.fMinIntSat)
@@ -658,7 +670,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
     case WriteEngine::WR_BYTE:
     {
       long long origVal;
-      const char* dataPtr = columnData->data()->GetValues<char>(1);
+      const int8_t* dataPtr = columnData->data()->GetValues<int8_t>(1);
       for (unsigned int i = 0; i < cbs; i++)
       {
         bool bSatVal = false;
@@ -687,7 +699,19 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         }
         else
         {
-          memcpy(&biVal, dataPtr + i, width);
+          // memcpy(&biVal, dataPtr + i, width);
+          // origVal = *(dataPtr + i);
+          if ((column.dataType == CalpontSystemCatalog::DECIMAL) ||
+              (column.dataType == CalpontSystemCatalog::UDECIMAL))
+          {
+            const int128_t* dataPtr1 = reinterpret_cast<const int128_t*>(dataPtr);
+            // auto dataPtr1 = std::static_pointer_cast<int128_t>(dataPtr);
+            origVal = *(dataPtr1 + i);
+          }
+          else
+          {
+            origVal = *(dataPtr + i);
+          }
         }
 
         if (origVal < column.fMinIntSat)
@@ -748,7 +772,8 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         }
         else
         {
-          memcpy(&ubiVal, dataPtr + i, width);
+          // memcpy(&ubiVal, dataPtr + i, width);
+          origVal = *(dataPtr + i);
         }
 
         if (origVal < column.fMinIntSat)
@@ -814,8 +839,38 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           }
           else
           {
-            memcpy(&llVal, dataPtr + i, width);
+            // memcpy(&llVal, dataPtr + i, width);
+            if ((column.dataType == CalpontSystemCatalog::DECIMAL) ||
+                (column.dataType == CalpontSystemCatalog::UDECIMAL))
+            {
+              const int128_t* dataPtr1 = reinterpret_cast<const int128_t*>(dataPtr);
+              llVal = *(dataPtr1 + i);
+              // long double ldVal = static_cast<long double>(llVal);
+              // for (int ii = 0; ii < column.scale; ii++)
+              // {
+              //   ldVal *= 10;
+              // }
+              // if (ldVal > LLONG_MAX)
+              // {
+              //   bSatVal = true;
+              //   llVal = LLONG_MAX;
+              // }
+              // else if (ldVal < LLONG_MIN)
+              // {
+              //   bSatVal = true;
+              //   llVal = LLONG_MIN;
+              // }
+              // else
+              // {
+              //   llVal = ldVal;
+              // }
+            }
+            else
+            {
+              llVal = *(dataPtr + i);
+            }
           }
+
           if (llVal < column.fMinIntSat)
           {
             llVal = column.fMinIntSat;
@@ -1014,11 +1069,18 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
     {
       // Parquet does not have data type with 128 byte
       // const int128_t* dataPtr = static_pointer_cast<int128_t>(columnData);
-      const int128_t* dataPtr = columnData->data()->GetValues<int128_t>(1);
+      // const int128_t* dataPtr = columnData->data()->GetValues<int128_t>(1);
+      std::shared_ptr<arrow::Decimal128Array> decimalArray = std::static_pointer_cast<arrow::Decimal128Array>(columnData);
+      std::shared_ptr<arrow::DecimalType> fType = std::static_pointer_cast<arrow::DecimalType>(decimalArray->type());
+      // int32_t fPrecision = fType->precision();
+      // int32_t fScale = fType->scale();
+      const int128_t* dataPtr = decimalArray->data()->GetValues<int128_t>(1);
+
+
       for (unsigned int i = 0; i < cbs; i++)
       {
         void* p = buf + i * width;
-        // bool bSatVal = false;
+        bool bSatVal = false;
         if (columnData->IsNull(i))
         {
           if (!column.autoIncFlag)
@@ -1042,8 +1104,17 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         }
         else
         {
-          memcpy(&bigllVal, dataPtr + i, width);
+          // TODO:
+          // compare parquet data precision and scale with table column precision and scale
+          
+          // Get int and frac part
+          memcpy(&bigllVal, dataPtr + i, sizeof(int128_t));
+          // dataconvert::parquet_int_value(bigllVal, column.scale, column.precision, fScale, fPrecision, &bSatVal);
+
+
         }
+        if (bSatVal)
+          bufStats.satCount++;
 
         //TODO: no bSatVal change here
         if (bigllVal < bufStats.bigMinBufferVal)
@@ -1215,8 +1286,39 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
           }
           else
           {
-            memcpy(&iVal, dataPtr + i, width);
-            origVal = (long long)iVal;
+            // memcpy(&iVal, dataPtr + i, width);
+            // origVal = (long long)iVal;
+            // memcpy(&origVal, )
+            if ((column.dataType == CalpontSystemCatalog::DECIMAL) ||
+                (column.dataType == CalpontSystemCatalog::UDECIMAL))
+            {
+              const int128_t* dataPtr1 = reinterpret_cast<const int128_t*>(dataPtr);
+              // auto dataPtr1 = std::static_pointer_cast<int128_t>(dataPtr);
+              origVal = *(dataPtr1 + i);
+              // long double ldVal = static_cast<long double>(origVal);
+              // for (int ii = 0; ii< column.scale; ii++)
+              // {
+              //   ldVal *= 10;
+              // }
+              // if (ldVal > LLONG_MAX)
+              // {
+              //   bSatVal = true;
+              //   origVal = LLONG_MAX;
+              // }
+              // else if (ldVal < LLONG_MIN)
+              // {
+              //   bSatVal = true;
+              //   origVal = LLONG_MIN;
+              // }
+              // else
+              // {
+              //   origVal = ldVal;
+              // }
+            }
+            else
+            {
+              origVal = *(dataPtr + i);
+            }
           }
 
           if (origVal < column.fMinIntSat)

From f343096457e7167d4d45f90b02697a56ebcc8278 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Sun, 9 Jul 2023 17:03:57 +0800
Subject: [PATCH 12/15] fix ci unrelated problem

---
 tests/parquetconvert-tests.cpp | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/tests/parquetconvert-tests.cpp b/tests/parquetconvert-tests.cpp
index 9659d64a5a..105f9f8dae 100644
--- a/tests/parquetconvert-tests.cpp
+++ b/tests/parquetconvert-tests.cpp
@@ -24,6 +24,6 @@ TEST(ParquetConvertTests, Convert)
   PARQUET_THROW_NOT_OK(builder.AppendValues(values, validity));
   std::shared_ptr<arrow::Array> array;
   PARQUET_THROW_NOT_OK(builder.Finish(&array));
-
+  // TODO: how to call tableInfo method
   
 }
\ No newline at end of file

From 2077a05de0da9acdde7e48f8992bca7de521e950 Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Sun, 9 Jul 2023 17:43:41 +0800
Subject: [PATCH 13/15] fix conflict

---
 writeengine/bulk/CMakeLists.txt | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/writeengine/bulk/CMakeLists.txt b/writeengine/bulk/CMakeLists.txt
index b51b51be36..41d14ebc85 100644
--- a/writeengine/bulk/CMakeLists.txt
+++ b/writeengine/bulk/CMakeLists.txt
@@ -41,7 +41,7 @@ set(cpimport.bin_SRCS cpimport.cpp)
 add_executable(cpimport.bin ${cpimport.bin_SRCS})
 add_dependencies(cpimport.bin marias3)
 
-target_link_libraries(cpimport.bin boost_program_options ${ENGINE_LDFLAGS} ${NETSNMP_LIBRARIES} ${ENGINE_WRITE_LIBS} ${S3API_DEPS} we_bulk we_xml)
+target_link_libraries(cpimport.bin ${ENGINE_LDFLAGS} ${NETSNMP_LIBRARIES} ${ENGINE_WRITE_LIBS} ${S3API_DEPS} we_bulk we_xml)
 FIND_PACKAGE(Arrow)
 FIND_PACKAGE(Parquet)
 target_link_libraries(cpimport.bin arrow)

From d0f98e27e590ff71f47094c936a34384b411d36f Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Sun, 9 Jul 2023 22:38:19 +0800
Subject: [PATCH 14/15] support bool type and fix default value error

---
 writeengine/bulk/we_tableinfo.cpp | 15 +++++++++++++--
 1 file changed, 13 insertions(+), 2 deletions(-)

diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index 43769b9d91..4425e8e5f9 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -669,7 +669,14 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
 
     case WriteEngine::WR_BYTE:
     {
+      // TODO:support boolean
+
       long long origVal;
+      // FIXME:if use int8_t here, it will take 8 bool value of parquet array
+      // if (columnData->type_id() == arrow::Type::type::BOOL)
+      // {
+      std::shared_ptr<arrow::BooleanArray> boolArray = std::static_pointer_cast<arrow::BooleanArray>(columnData);
+      // }
       const int8_t* dataPtr = columnData->data()->GetValues<int8_t>(1);
       for (unsigned int i = 0; i < cbs; i++)
       {
@@ -679,7 +686,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         {
           if (!column.autoIncFlag)
           {
-            if (!column.fWithDefault)
+            if (column.fWithDefault)
             {
               origVal = column.fDefaultInt;
             }
@@ -708,6 +715,10 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             // auto dataPtr1 = std::static_pointer_cast<int128_t>(dataPtr);
             origVal = *(dataPtr1 + i);
           }
+          else if (columnData->type_id() == arrow::Type::type::BOOL)
+          {
+            origVal = boolArray->Value(i);
+          }
           else
           {
             origVal = *(dataPtr + i);
@@ -753,7 +764,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         {
           if (!column.autoIncFlag)
           {
-            if (!column.fWithDefault)
+            if (column.fWithDefault)
             {
               origVal = static_cast<int64_t>(column.fDefaultUInt);
             }

From 8ef681dbbbd6aac42c214c59798f30cfbea74c2d Mon Sep 17 00:00:00 2001
From: HanpyBin <975189452@qq.com>
Date: Mon, 10 Jul 2023 21:28:33 +0800
Subject: [PATCH 15/15] update parquetGen, support NULL type insert, fix uint
 type bug

---
 .../basic/r/mcs287_cpimport_parquet.result    | 1387 ++++++++++++++++-
 .../basic/t/mcs287_cpimport_parquet.test      |  168 +-
 mysql-test/columnstore/std_data/bool.parquet  |  Bin 0 -> 1719 bytes
 mysql-test/columnstore/std_data/int32.parquet |  Bin 2614 -> 2614 bytes
 mysql-test/columnstore/std_data/int64.parquet |  Bin 0 -> 3244 bytes
 mysql-test/columnstore/std_data/int8.parquet  |  Bin 0 -> 2658 bytes
 mysql-test/columnstore/std_data/null.parquet  |  Bin 0 -> 1621 bytes
 .../columnstore/std_data/uint16.parquet       |  Bin 0 -> 2340 bytes
 .../columnstore/std_data/uint32.parquet       |  Bin 0 -> 2257 bytes
 .../columnstore/std_data/uint64.parquet       |  Bin 0 -> 2674 bytes
 mysql-test/columnstore/std_data/uint8.parquet |  Bin 0 -> 2319 bytes
 tests/parquetconvert-tests.cpp                |    5 +-
 tools/parquetGen/main.cpp                     |  373 ++++-
 writeengine/bulk/we_tableinfo.cpp             |    6 +-
 14 files changed, 1836 insertions(+), 103 deletions(-)
 create mode 100644 mysql-test/columnstore/std_data/bool.parquet
 create mode 100644 mysql-test/columnstore/std_data/int64.parquet
 create mode 100644 mysql-test/columnstore/std_data/int8.parquet
 create mode 100644 mysql-test/columnstore/std_data/null.parquet
 create mode 100644 mysql-test/columnstore/std_data/uint16.parquet
 create mode 100644 mysql-test/columnstore/std_data/uint32.parquet
 create mode 100644 mysql-test/columnstore/std_data/uint64.parquet
 create mode 100644 mysql-test/columnstore/std_data/uint8.parquet

diff --git a/mysql-test/columnstore/basic/r/mcs287_cpimport_parquet.result b/mysql-test/columnstore/basic/r/mcs287_cpimport_parquet.result
index 30e18fef7e..8ff4ec3a51 100644
--- a/mysql-test/columnstore/basic/r/mcs287_cpimport_parquet.result
+++ b/mysql-test/columnstore/basic/r/mcs287_cpimport_parquet.result
@@ -1,41 +1,1362 @@
 DROP DATABASE IF EXISTS mcs287_db;
 CREATE DATABASE mcs287_db;
 USE mcs287_db;
-CREATE TABLE t1(col1 INT, col2 FLOAT, col3 DOUBLE, col4 TIME, col5 VARCHAR(20), col6 TIMESTAMP, col7 DATE) ENGINE=Columnstore;
+CREATE TABLE t1(col1 INT) ENGINE=Columnstore;
+CREATE TABLE t2(col1 FLOAT) ENGINE=Columnstore;
+CREATE TABLE t3(col1 DOUBLE) ENGINE=Columnstore;
+CREATE TABLE t4(col1 TIME) ENGINE=Columnstore;
+CREATE TABLE t5(col1 VARCHAR(2)) ENGINE=Columnstore;
+CREATE TABLE t6(col1 VARCHAR(5)) ENGINE=Columnstore;
+CREATE TABLE t7(col1 VARCHAR(20)) ENGINE=Columnstore;
+CREATE TABLE t8(col1 CHAR(2)) ENGINE=Columnstore;
+CREATE TABLE t9(col1 CHAR(5)) ENGINE=Columnstore;
+CREATE TABLE t10(col1 CHAR(20)) ENGINE=Columnstore;
+CREATE TABLE t11(col1 TIMESTAMP) ENGINE=Columnstore;
+CREATE TABLE t12(col1 DATE) ENGINE=Columnstore;
+CREATE TABLE t13(col1 DATETIME) ENGINE=Columnstore;
+CREATE TABLE t14(col1 SMALLINT) ENGINE=Columnstore;
+CREATE TABLE t15(col1 DECIMAL(9,3)) ENGINE=Columnstore;
+CREATE TABLE t16(col1 BOOLEAN) ENGINE=Columnstore;
+CREATE TABLE t17(col1 BIGINT) ENGINE=Columnstore;
+CREATE TABLE t18(col1 INT UNSIGNED) ENGINE=Columnstore;
+CREATE TABLE t19(col1 SMALLINT UNSIGNED) ENGINE=Columnstore;
+CREATE TABLE t20(col1 TINYINT UNSIGNED) ENGINE=Columnstore;
+CREATE TABLE t21(col1 BIGINT UNSIGNED) ENGINE=Columnstore;
+CREATE TABLE t22(col1 TINYINT) ENGINE=Columnstore;
 SELECT * FROM t1;
-col1	col2	col3	col4	col5	col6	col7
-0	1.5	2.5	00:00:00	hhhh	0000-00-00 00:00:00	1970-01-01
-NULL	2.5	3.5	01:00:05	NULL	1970-01-01 08:00:09	1970-01-11
-NULL	NULL	4.5	02:00:10	hhhh	1970-01-01 08:00:19	1970-01-21
-NULL	4.5	NULL	03:00:15	hhhh	1970-01-01 08:00:28	1970-01-31
-4	5.5	6.5	04:00:20	hhhh	1970-01-01 08:00:38	1970-02-10
-5	6.5	7.5	05:00:25	hhhh	1970-01-01 08:00:47	1970-02-20
-6	7.5	8.5	06:00:30	hhhh	1970-01-01 08:00:57	1970-03-02
-7	8.5	9.5	07:00:35	hhhh	1970-01-01 08:01:06	1970-03-12
-8	9.5	10.5	08:00:40	hhhh	1970-01-01 08:01:16	1970-03-22
-9	10.5	11.5	09:00:45	hhhh	1970-01-01 08:01:25	1970-04-01
-10	11.5	12.5	10:00:50	hhhh	1970-01-01 08:01:35	1970-04-11
-11	12.5	13.5	11:00:55	hhhh	1970-01-01 08:01:44	1970-04-21
-12	13.5	14.5	12:01:00	hhhh	1970-01-01 08:01:54	1970-05-01
-13	14.5	15.5	13:01:05	hhhh	1970-01-01 08:02:03	1970-05-11
-14	15.5	16.5	14:01:10	hhhh	1970-01-01 08:02:13	1970-05-21
-15	16.5	17.5	15:01:15	hhhh	1970-01-01 08:02:23	1970-05-31
-16	17.5	18.5	16:01:20	hhhh	1970-01-01 08:02:32	1970-06-10
-17	18.5	19.5	17:01:25	hhhh	1970-01-01 08:02:42	1970-06-20
-18	19.5	20.5	18:01:30	hhhh	1970-01-01 08:02:51	1970-06-30
-19	20.5	21.5	19:01:35	hhhh	1970-01-01 08:03:01	1970-07-10
-20	21.5	22.5	20:01:40	hhhh	1970-01-01 08:03:10	1970-07-20
-21	22.5	23.5	21:01:45	hhhh	1970-01-01 08:03:20	1970-07-30
-22	23.5	24.5	22:01:50	hhhh	1970-01-01 08:03:29	1970-08-09
-23	24.5	25.5	23:01:55	hhhh	1970-01-01 08:03:39	1970-08-19
-24	25.5	26.5	24:02:00	hhhh	1970-01-01 08:03:48	1970-08-29
-25	26.5	27.5	25:02:05	hhhh	1970-01-01 08:03:58	1970-09-08
-26	27.5	28.5	26:02:10	hhhh	1970-01-01 08:04:07	1970-09-18
-27	28.5	29.5	27:02:15	hhhh	1970-01-01 08:04:17	1970-09-28
-28	29.5	30.5	28:02:20	hhhh	1970-01-01 08:04:27	1970-10-08
-29	30.5	31.5	29:02:25	hhhh	1970-01-01 08:04:36	1970-10-18
+col1
+0
+NULL
+NULL
+NULL
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+-2147483646
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
 SELECT COUNT(*) FROM t1;
 COUNT(*)
-30
+60
 TRUNCATE t1;
+SELECT * FROM t2;
+col1
+1.5
+2.5
+NULL
+4.5
+5.5
+6.5
+7.5
+8.5
+9.5
+10.5
+11.5
+12.5
+13.5
+14.5
+15.5
+16.5
+17.5
+18.5
+19.5
+20.5
+21.5
+22.5
+23.5
+24.5
+25.5
+26.5
+27.5
+28.5
+29.5
+30.5
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t2;
+COUNT(*)
+60
+TRUNCATE t2;
+SELECT * FROM t3;
+col1
+2.5
+3.5
+4.5
+NULL
+6.5
+7.5
+8.5
+9.5
+10.5
+11.5
+12.5
+13.5
+14.5
+15.5
+16.5
+17.5
+18.5
+19.5
+20.5
+21.5
+22.5
+23.5
+24.5
+25.5
+26.5
+27.5
+28.5
+29.5
+30.5
+31.5
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t3;
+COUNT(*)
+60
+TRUNCATE t3;
+SELECT * FROM t4;
+col1
+00:00:00
+01:00:05
+02:00:10
+03:00:15
+04:00:20
+05:00:25
+06:00:30
+07:00:35
+08:00:40
+09:00:45
+10:00:50
+11:00:55
+12:01:00
+13:01:05
+14:01:10
+15:01:15
+16:01:20
+17:01:25
+18:01:30
+19:01:35
+20:01:40
+21:01:45
+22:01:50
+23:01:55
+24:02:00
+25:02:05
+26:02:10
+27:02:15
+28:02:20
+29:02:25
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t4;
+COUNT(*)
+60
+TRUNCATE t4;
+SELECT * FROM t5;
+col1
+hh
+NULL
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t5;
+COUNT(*)
+60
+TRUNCATE t5;
+SELECT * FROM t6;
+col1
+hhhh
+NULL
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t6;
+COUNT(*)
+60
+TRUNCATE t6;
+SELECT * FROM t7;
+col1
+hhhh
+NULL
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+SELECT COUNT(*) FROM t7;
+COUNT(*)
+30
+TRUNCATE t7;
+SELECT * FROM t8;
+col1
+hh
+NULL
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+hh
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t8;
+COUNT(*)
+60
+TRUNCATE t8;
+SELECT * FROM t9;
+col1
+hhhh
+NULL
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t9;
+COUNT(*)
+60
+TRUNCATE t9;
+SELECT * FROM t10;
+col1
+hhhh
+NULL
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+hhhh
+SELECT COUNT(*) FROM t10;
+COUNT(*)
+30
+TRUNCATE t10;
+SELECT * FROM t11;
+col1
+0000-00-00 00:00:00
+1970-01-01 08:00:09
+1970-01-01 08:00:19
+1970-01-01 08:00:28
+1970-01-01 08:00:38
+1970-01-01 08:00:47
+1970-01-01 08:00:57
+1970-01-01 08:01:06
+1970-01-01 08:01:16
+1970-01-01 08:01:25
+1970-01-01 08:01:35
+1970-01-01 08:01:44
+1970-01-01 08:01:54
+1970-01-01 08:02:03
+1970-01-01 08:02:13
+1970-01-01 08:02:23
+1970-01-01 08:02:32
+1970-01-01 08:02:42
+1970-01-01 08:02:51
+1970-01-01 08:03:01
+1970-01-01 08:03:10
+1970-01-01 08:03:20
+1970-01-01 08:03:29
+1970-01-01 08:03:39
+1970-01-01 08:03:48
+1970-01-01 08:03:58
+1970-01-01 08:04:07
+1970-01-01 08:04:17
+1970-01-01 08:04:27
+1970-01-01 08:04:36
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+2023-07-10 19:43:03
+SELECT COUNT(*) FROM t11;
+COUNT(*)
+60
+TRUNCATE t11;
+SELECT * FROM t12;
+col1
+1970-01-01
+1970-01-11
+1970-01-21
+1970-01-31
+1970-02-10
+1970-02-20
+1970-03-02
+1970-03-12
+1970-03-22
+1970-04-01
+1970-04-11
+1970-04-21
+1970-05-01
+1970-05-11
+1970-05-21
+1970-05-31
+1970-06-10
+1970-06-20
+1970-06-30
+1970-07-10
+1970-07-20
+1970-07-30
+1970-08-09
+1970-08-19
+1970-08-29
+1970-09-08
+1970-09-18
+1970-09-28
+1970-10-08
+1970-10-18
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t12;
+COUNT(*)
+60
+TRUNCATE t12;
+SELECT * FROM t13;
+col1
+1970-01-01 08:00:00
+1970-01-01 10:46:40
+1970-01-01 13:33:20
+1970-01-01 16:20:00
+1970-01-01 19:06:40
+1970-01-01 21:53:20
+1970-01-02 00:40:00
+1970-01-02 03:26:40
+1970-01-02 06:13:20
+1970-01-02 09:00:00
+1970-01-02 11:46:40
+1970-01-02 14:33:20
+1970-01-02 17:20:00
+1970-01-02 20:06:40
+1970-01-02 22:53:20
+1970-01-03 01:40:00
+1970-01-03 04:26:40
+1970-01-03 07:13:20
+1970-01-03 10:00:00
+1970-01-03 12:46:40
+1970-01-03 15:33:20
+1970-01-03 18:20:00
+1970-01-03 21:06:40
+1970-01-03 23:53:20
+1970-01-04 02:40:00
+1970-01-04 05:26:40
+1970-01-04 08:13:20
+1970-01-04 11:00:00
+1970-01-04 13:46:40
+1970-01-04 16:33:20
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t13;
+COUNT(*)
+60
+TRUNCATE t13;
+SELECT * FROM t14;
+col1
+0
+1
+2
+3
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+29
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t14;
+COUNT(*)
+60
+TRUNCATE t14;
+SELECT * FROM t15;
+col1
+1383.433
+532235.234
+NULL
+5325.234
+SELECT COUNT(*) FROM t15;
+COUNT(*)
+4
+TRUNCATE t15;
+SELECT * FROM t16;
+col1
+1
+1
+1
+1
+1
+0
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+1
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t16;
+COUNT(*)
+60
+TRUNCATE t16;
+SELECT * FROM t17;
+col1
+0
+NULL
+NULL
+NULL
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+2147483648
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t17;
+COUNT(*)
+60
+TRUNCATE t17;
+SELECT * FROM t18;
+col1
+0
+NULL
+NULL
+NULL
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+2147483648
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t18;
+COUNT(*)
+60
+TRUNCATE t18;
+SELECT * FROM t19;
+col1
+0
+1
+2
+3
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+29
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t19;
+COUNT(*)
+60
+TRUNCATE t19;
+SELECT * FROM t20;
+col1
+0
+1
+2
+3
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+29
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t20;
+COUNT(*)
+60
+TRUNCATE t20;
+SELECT * FROM t21;
+col1
+0
+NULL
+NULL
+NULL
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+2147483648
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t21;
+COUNT(*)
+60
+TRUNCATE t21;
+SELECT * FROM t22;
+col1
+0
+1
+2
+3
+4
+5
+6
+7
+8
+9
+10
+11
+12
+13
+14
+15
+16
+17
+18
+19
+20
+21
+22
+23
+24
+25
+26
+27
+28
+29
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+NULL
+SELECT COUNT(*) FROM t22;
+COUNT(*)
+60
+TRUNCATE t22;
 DROP DATABASE mcs287_db;
diff --git a/mysql-test/columnstore/basic/t/mcs287_cpimport_parquet.test b/mysql-test/columnstore/basic/t/mcs287_cpimport_parquet.test
index c4a5113306..3f0e650ffc 100644
--- a/mysql-test/columnstore/basic/t/mcs287_cpimport_parquet.test
+++ b/mysql-test/columnstore/basic/t/mcs287_cpimport_parquet.test
@@ -10,27 +10,169 @@ DROP DATABASE IF EXISTS mcs287_db;
 
 CREATE DATABASE mcs287_db;
 USE mcs287_db;
-
-CREATE TABLE t1(col1 INT, col2 FLOAT, col3 DOUBLE, col4 TIME, col5 VARCHAR(20), col6 TIMESTAMP, col7 DATE) ENGINE=Columnstore;
+# Create table
+# CREATE TABLE t1(col1 INT, col2 FLOAT, col3 DOUBLE, col4 TIME, col5 VARCHAR(20), col6 TIMESTAMP, col7 DATE) ENGINE=Columnstore;
+CREATE TABLE t1(col1 INT) ENGINE=Columnstore;
+CREATE TABLE t2(col1 FLOAT) ENGINE=Columnstore;
+CREATE TABLE t3(col1 DOUBLE) ENGINE=Columnstore;
+CREATE TABLE t4(col1 TIME) ENGINE=Columnstore;
+CREATE TABLE t5(col1 VARCHAR(2)) ENGINE=Columnstore;
+CREATE TABLE t6(col1 VARCHAR(5)) ENGINE=Columnstore;
+CREATE TABLE t7(col1 VARCHAR(20)) ENGINE=Columnstore;
+CREATE TABLE t8(col1 CHAR(2)) ENGINE=Columnstore;
+CREATE TABLE t9(col1 CHAR(5)) ENGINE=Columnstore;
+CREATE TABLE t10(col1 CHAR(20)) ENGINE=Columnstore;
+CREATE TABLE t11(col1 TIMESTAMP) ENGINE=Columnstore;
+CREATE TABLE t12(col1 DATE) ENGINE=Columnstore;
+CREATE TABLE t13(col1 DATETIME) ENGINE=Columnstore;
+CREATE TABLE t14(col1 SMALLINT) ENGINE=Columnstore;
+CREATE TABLE t15(col1 DECIMAL(9,3)) ENGINE=Columnstore;
+CREATE TABLE t16(col1 BOOLEAN) ENGINE=Columnstore;
+CREATE TABLE t17(col1 BIGINT) ENGINE=Columnstore;
+CREATE TABLE t18(col1 INT UNSIGNED) ENGINE=Columnstore;
+CREATE TABLE t19(col1 SMALLINT UNSIGNED) ENGINE=Columnstore;
+CREATE TABLE t20(col1 TINYINT UNSIGNED) ENGINE=Columnstore;
+CREATE TABLE t21(col1 BIGINT UNSIGNED) ENGINE=Columnstore;
+CREATE TABLE t22(col1 TINYINT) ENGINE=Columnstore;
 
 # Generate data
---exec mcsParquetGen -d a
---exec mcsParquetGen -d b
---exec mcsParquetGen -d c
---exec mcsParquetGen -d d
---exec mcsParquetGen -d e
---exec mcsParquetGen -d f
---exec mcsParquetGen -d g
---exec mcsParquetGen -d h
---exec mcsParquetGen -d i
+--exec mcsParquetGen -d 
 
 
 #Valid data and table
---exec $MCS_CPIMPORT mcs287_db t1 $MTR_SUITE_DIR/../std_data/test-small-scale.parquet >/dev/null
+#--exec $MCS_CPIMPORT mcs287_db t1 $MTR_SUITE_DIR/../std_data/test-small-scale.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t1 $MTR_SUITE_DIR/../std_data/int32.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t1 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t2 $MTR_SUITE_DIR/../std_data/float.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t2 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t3 $MTR_SUITE_DIR/../std_data/double.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t3 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t4 $MTR_SUITE_DIR/../std_data/time.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t4 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t5 $MTR_SUITE_DIR/../std_data/string.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t5 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t6 $MTR_SUITE_DIR/../std_data/string.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t6 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t7 $MTR_SUITE_DIR/../std_data/string.parquet >/dev/null
+# --exec $MCS_CPIMPORT mcs287_db t7 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t8 $MTR_SUITE_DIR/../std_data/string.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t8 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t9 $MTR_SUITE_DIR/../std_data/string.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t9 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t10 $MTR_SUITE_DIR/../std_data/string.parquet >/dev/null
+# --exec $MCS_CPIMPORT mcs287_db t10 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t11 $MTR_SUITE_DIR/../std_data/ts.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t11 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t12 $MTR_SUITE_DIR/../std_data/date.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t12 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t13 $MTR_SUITE_DIR/../std_data/ts.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t13 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t14 $MTR_SUITE_DIR/../std_data/int16.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t14 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t15 $MTR_SUITE_DIR/../std_data/decimal.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t16 $MTR_SUITE_DIR/../std_data/bool.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t16 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t17 $MTR_SUITE_DIR/../std_data/int64.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t17 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t18 $MTR_SUITE_DIR/../std_data/uint32.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t18 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t19 $MTR_SUITE_DIR/../std_data/uint16.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t19 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t20 $MTR_SUITE_DIR/../std_data/uint8.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t20 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t21 $MTR_SUITE_DIR/../std_data/uint64.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t21 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t22 $MTR_SUITE_DIR/../std_data/int8.parquet >/dev/null
+--exec $MCS_CPIMPORT mcs287_db t22 $MTR_SUITE_DIR/../std_data/null.parquet >/dev/null
+
+
 SELECT * FROM t1;
 SELECT COUNT(*) FROM t1;
-
 TRUNCATE t1;
 
+SELECT * FROM t2;
+SELECT COUNT(*) FROM t2;
+TRUNCATE t2;
+
+SELECT * FROM t3;
+SELECT COUNT(*) FROM t3;
+TRUNCATE t3;
+
+SELECT * FROM t4;
+SELECT COUNT(*) FROM t4;
+TRUNCATE t4;
+
+SELECT * FROM t5;
+SELECT COUNT(*) FROM t5;
+TRUNCATE t5;
+
+SELECT * FROM t6;
+SELECT COUNT(*) FROM t6;
+TRUNCATE t6;
+
+SELECT * FROM t7;
+SELECT COUNT(*) FROM t7;
+TRUNCATE t7;
+
+SELECT * FROM t8;
+SELECT COUNT(*) FROM t8;
+TRUNCATE t8;
+
+SELECT * FROM t9;
+SELECT COUNT(*) FROM t9;
+TRUNCATE t9;
+
+SELECT * FROM t10;
+SELECT COUNT(*) FROM t10;
+TRUNCATE t10;
+
+SELECT * FROM t11;
+SELECT COUNT(*) FROM t11;
+TRUNCATE t11;
+
+SELECT * FROM t12;
+SELECT COUNT(*) FROM t12;
+TRUNCATE t12;
+
+SELECT * FROM t13;
+SELECT COUNT(*) FROM t13;
+TRUNCATE t13;
+
+SELECT * FROM t14;
+SELECT COUNT(*) FROM t14;
+TRUNCATE t14;
+
+SELECT * FROM t15;
+SELECT COUNT(*) FROM t15;
+TRUNCATE t15;
+
+SELECT * FROM t16;
+SELECT COUNT(*) FROM t16;
+TRUNCATE t16;
+
+SELECT * FROM t17;
+SELECT COUNT(*) FROM t17;
+TRUNCATE t17;
+
+SELECT * FROM t18;
+SELECT COUNT(*) FROM t18;
+TRUNCATE t18;
+
+SELECT * FROM t19;
+SELECT COUNT(*) FROM t19;
+TRUNCATE t19;
+
+SELECT * FROM t20;
+SELECT COUNT(*) FROM t20;
+TRUNCATE t20;
+
+SELECT * FROM t21;
+SELECT COUNT(*) FROM t21;
+TRUNCATE t21;
+
+SELECT * FROM t22;
+SELECT COUNT(*) FROM t22;
+TRUNCATE t22;
+
 # Clean UP
 DROP DATABASE mcs287_db;
\ No newline at end of file
diff --git a/mysql-test/columnstore/std_data/bool.parquet b/mysql-test/columnstore/std_data/bool.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..ef681ad0345a6030044beddb07f3d25ea835be4e
GIT binary patch
literal 1719
zcmb`|ze~eF6bJB^U)PwlLBtC^$k3&sLtBjC*2VuIIJwpmP*77-f2_s9!NI}5qf>_t
z9Xb>T2M7O{f*m^e?phEer}PL(xIpqgJd*e2;^UKu0`;iZqy%pWB|%lw@bsY}RshiP
zB3dat4JfcW5LPwM()5yoPyE=AL%Z{<gyD;L@VZ<aHaI@t;70hWOZ2(6=6{O*<MVp|
zG$j1c*tYvT{>75;GqVW(gGl(5RRsTROZaK22>yLX!Y{X;oV;)U<VyI7Q$+V~WeLA<
zi{KwU2|up<#ha{o1XVKVohMgaOd5r{zK$jM9X4WtQd%+2B((i_9{>flND5=FA)<3c
zEqDSM8i<%2QHz&AW+ozpBWfWM$jU;*=7?HU1Trll;&4PQ5CU29zf<Oj+Sm(Z;vnL2
zL~XbQvTzaE<%rq{3uIhDWDgp(emA?hOKw}ee!tbtvh<;LpJaoJ^tu)uwh!773j*9M
LzHm#4am)G!{l&M(

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/int32.parquet b/mysql-test/columnstore/std_data/int32.parquet
index f3e547e78c0cbc865736f56d8f5f70ab74384128..9610fdbf802733f6d147d63936c44fb33176f20f 100644
GIT binary patch
delta 125
zcmdlcvQ1>eDpoxP28ISv22l}F5gk!BQ2`)klaXMN0SZg7faJs&G>~|cZ?GCl;F8>|
X$hL+Vr|e`!M&Zfv>}-?&aasTX6qOL{

delta 122
zcmdlcvQ1>eDpoyN1_lOE22l}F5gk!BQ2`)klaXKniAu0Y14%Ik4J6*=8?1&BxFk0#
XvaMkj#VR{lj!|rKJUiRuf1DNoR!0sl

diff --git a/mysql-test/columnstore/std_data/int64.parquet b/mysql-test/columnstore/std_data/int64.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..c234aaa8d37d933342b0d1a65c9b725086be7afa
GIT binary patch
literal 3244
zcmcJSF>ljA6vxkwd%c7-ab2H#rUqqzQ--ukP|L)^o}uC!L{%g@(1x_Y%2*-B4v4uz
z3=EkNV#<I}hfav8>VWtFh_M5Tcn{xEtjpPAaFpaF@8$mg_e+%blI{Bsdfeka_xs%C
zBp`n;obZ4L9ZsQ0IZXu9rK?Ag*PfGw*ST=3IF3u?)JeD(Z~27AVqtgh@a`rj5sf}L
zaFv^q{f}<kfmR833EcS*2!ZD<-s)o-TK80k3o4ojx+0i<ZREC@nFWDA2-K;#^0PM=
z;nayv9r>{$XD&dP8W!cb5MAEw!@G<SR5ib-qJDz`CgkD2pNFmprq4vA&CINVp^jU*
zMdbIzxisfabneKnR370+ZHic=i)gBfqNd_C6-^pl5lo*!OEa6LnbmS=epcm46=+Nm
zi*yl9U3I^tV#7+KD}w1WXlZ7%G_M;uG%uIrv<@_;h()@Hrm4F3Ra~~x=!#(a3|gAm
zEY17n9GbVjyl4WADPoZ>qS2#kMNx!S8eI`gpFvAAo2B^@=Fogvk(U9`m?9SGA{wr`
zk5pW>(&&m{S7+MH%w}nRtme>si{x<xG^PmBm|0RpBUJaXir1|)x+0i9gO+ACOY>qa
zhvru-Co#~NA{OZ)nl;sZq9TOn_|Tkbx+0i9gO+9%GPrKkgnn}~hvwA{d6oc;DPobH
zM-z9ph@b~M4~LHixK6#>u3F9{x);BTlakjqu74^S1o*;$TiF{H7B%?IT!^8IhGj27
z*ri~2L?MPA8kW7MQp1xf8d5YYdzGYy(>fY5G%S1Cr-m0zG_0Xv*#kK>ybRE=j)rB=
z%+&BWLc<0cmOa)|!%2*WJ{p!ic~Zl(1PueyZjA=x$4`cb>pP>-`d~cXf7W_B93SlN
X@3ne&Ho6<VIKde^f#2%e@IU1@^<xpV

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/int8.parquet b/mysql-test/columnstore/std_data/int8.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..11fd32dce04a3bd2899596df92434ef8f1e5f202
GIT binary patch
literal 2658
zcmb`JKX21O7{)Ko#W89AIH}J$LqHkmsY6;3q)H53*gI5wgQ$u`2ilO9vNNCxb?DGf
zz*tob3``6Rs6rh&bm(VbU|?WC42b8chch<Di=(`;-p6;p`whwKY(9Q6R#IuDH<YVH
zPu#pJ_;gT8s6YiH-0@NFKue}ta#1Lj6CDEHaw|^tzA&eifpVfXU$~K$+dKP@lnCAM
zZ3S<$ZoL0-q7ih2a(K3n3nc#1t0Lj~HQveSG1Zc5sAoF_3B9k?e7#?eId>pv_ohfi
zf-cUgqdZhrkg1kjL#*u(Bm__0e8G=3b6A6*-J2p63Esk44b%cEE67w!t|8WT2oi$d
zynMmmb#qaNpxv7y6$v(RRtwceWd)gP$u-2<4nacj-9o<Lr-nIdK+x_@k%|O6ILk+M
zQCUHzT5=7swnLB*{NBnJeAP0SO$ge(DN>Ojf5wZb0F@PFswLMDYdZu9!S{Z?;OCAx
z?m*D)O_7QO)y?5T^l{A!GS!#@v7qe`Bm{r-@&#Y_%vBeHb}t2OCyE3$&WcdCQCUHz
zT5=7swnLB*{Gjp$zXawafS}!*A{7bV!C3>;T~t<(sg_(rtnCma1b_DP1>f||bqGPb
zH%0oFU^H42+TGiFI(;_b2zQp8c>XWl+c;bF_<au7qqAsG?h}Gf7T0*V;0p<O$@4wN
zpF89`<d;02WBy@{d`W)E(>3N_)X8_rFL^k|{G$f>9{DBDwwQm}B)>s^$)hReA9u)a
zl3(&<iTPJu^4sK>JQ!mBNkG0&e#yV<n13CT-xJHj*<}9w#dLpVYc^Y%%;&o=hX>R7
a-uCX!aQtxf!Rj~~a4@y;FKrY5F8=_lL;5iQ

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/null.parquet b/mysql-test/columnstore/std_data/null.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..97bcdec079dbcaafc6906ccdd1f5607f16942255
GIT binary patch
literal 1621
zcmbu=F;Buk6u|MvQLcqn(h#qqNe2eKXaYn`*j(Hl8YfpmNHjsfBKi$F@F5sFI5{&k
zhS`~+AA+F+pTKwL>Lp%o=xx7$n&!P;e0x7&76S%%;%EULtjU^PMwyQfjR1h)Ljm|h
z#7H>wfrf2swwg{E1T=_)n4fXyvMV!0c%KRJ?`%p`-F<~`D+cAfsw$^dejo<r(o&Uk
zi*GE0az<6<vc~r{gK}Z3%9+hm+n~IztICDLbCcQFHB{wwgO_!KcRsqR^3LU%Yf%0;
zQI(G#FTB6XVRr~^x*R`Fo=3PmjGU9-6`OwHCIvU)XBcU&A1)^4P7t30pw-?n$+s2s
zM0o8@lKw!@Tf%Gai}V`{Jr!PiE2Q7o&^y9w&%X4jjlLng_Jm8Hi|_9VuRX`omv!__
z;kBn#`piY|3$Hzs(ia~37F=`|qvT~ZdF_oCi{2<n=I@=iNwR#J&pLza{#AbvM&h3M
K#@~L77s?OlEy^SS

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/uint16.parquet b/mysql-test/columnstore/std_data/uint16.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..3572645abc3219820b63f5bf7a75a184d3638b48
GIT binary patch
literal 2340
zcmb`Jy>Ami5XH~u&Bh<Geg0Up2S##1Rw<kaBPCTD`V<lWffZRI1&MJI@-IYGC}oON
zC`#cXMJj|SQ=~u$QKm$QIweAg_jZG{pyRH&k)JJ%XWsmDcRTjx(`Q2^lva8}NfopL
z8wI?FkP1{sbq4q*f@E(kSQ5-@Var^REQG~JfjKVpR2Z*DfsD00*xuP6uBo6ayRQp)
znRQe8w>utSaG*j?iSU7Oe}NQ{;hZ^slK{fJ7OX<B{SM@9F%9HnXih?l;`L{tNVv~K
zB`67nc`aCl@KD~(rJ;Nk=0aE$uRjZ=j0qK}3MHX1uLY|R9?GZrG?X9GT)Erp^=F|h
zU_uS5LrEyiYr!gnhw`nQhVrItZrrot^=F|pFd>4PP!bCBTCfV?q5Q0-p`2CCZN=Uo
zuRjZgN2m>Tpd=LLwYWQI9?Ee&4ds2!9Mvp}*Pn%=FscjP`wt598fVakhjJdJp?q$b
z(}qRy`m<0pX2j5aDCw#&uLY|R9?FMS8p`*kxolb#uRjar0VedIhfop<^IEV9;h}u#
zq@nz3o9nhk@%occ;=yX5<=)ow@rx0cU$_|l*_VrYW7dxNXmr=(S=`HGr*i*FQ^E%x
z99ZVE9i8b(NY{|Axhy*8dLig4=$gyUa;{hWA?irF=CXdA>y5pxCA#LaNu29#g{&32
z=CTx=>rsua3v|upd^^|E23_lP&E=>%*UKhdBf92t>YVF!o35>3sXrM_UmlG2m$xR9
j<<WGyd)R+9p6+e$?(~OGRvxbm;~p2p4F4@Q@&D*I0%rXq

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/uint32.parquet b/mysql-test/columnstore/std_data/uint32.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..1d3a2958feeebbd9beff214f222c8a9d9a59cd64
GIT binary patch
literal 2257
zcmbuBv2W8r6voe&>(x!u#Bp-wTs&l;rwnODkeZ2wJwwHR5LJ=rKwHuR88cJ@bzthi
z#MA+yim3w=QwJud4oplPn3y^+MSSmEq-(L|!B6^<^!eWRes%nwvi0O?UkT+af2g=(
zA+w>F3RT!sQU#Dq2BItIg0`>tz@dugab{*-qIkR+Fd6I0&hDXNk&LF%)bxyhw=V9X
z6;qtyCBPeF_&ZR+kkV*P?hBN?+n#p?<+Zr!Z`(_+!p)p#w4Zs=%rl>G)k_AqYcmnF
z(nI{8gdovo5%N=vwrV?ffprDtwV+c7!jK-XJYeSCLI%gN7ae=%i!etb8Qd-|;#h)p
z6<UUHJO1OKycTo{;c$Fd%;oqd%?Z9ra5%+995vXlKy@gKgYsI?DTKrEc`29Uhi^{t
zXn?~hF5+mwK7g7~76;|Epi>Bk<Lh!R$FHh6uUZbLxQK%Wqy@F1EDp+RaWh5^$M=<7
zjz2YXQL`LQaS?|?p9s2_!$EnCsj}g4{A}cMylt4vy5(?+i#RkI#Ly~~bw4Pt1)V}T
z9KV~n9PgXvDzF?*aS_LT*eA9Ln`Lp}(o73Fg>X3Ltz3?eEpr`O4wU>W&f<uBn@r1t
z?PufXBU)~JjoVeYwmLj(b?8}$9>-^KQgT;ft4iZXQ#>W`D!=%!BVjnFUD@VjS$>CM
z-NEum;Jq!#viv$qEl(s_O0q1!SyIbWpDcZ{EWadD%kwH(R>`vbyr-5IHL|RcW%<!f
zEidb2StrZ#Q<z#_1!NhJW%+?hEw4ke3|Y6cKbpLFIX+z9-rrvzO(uJ<JFmu*gPpzI
WPXE!y!;OBN(BQwRFt&vsGk*aPfa@Uu

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/uint64.parquet b/mysql-test/columnstore/std_data/uint64.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..0302416a340c313ffba2cbe3c8fa844d69d68685
GIT binary patch
literal 2674
zcmb`JF>l&H6vxkJ=eQCA27Kn+dSGZy3?zaoVd~KC3{k%UijbP22_;FpcB&YvsAH!p
zsu(jwnJR{gkI<oF=x1Q4m^<{HeHYd0^}HB?|HjYn$4{31j-%%<`pjcK^M?#G)Ij$y
zhFF6&x{N@PFcJ^E4%J0|zXwM!d|b!DNPKc)=0%4-A`vH-C#M&K1BOBpesth14g~!l
zB<g|#Vi>{3hd>Cvw^@5A4}+7Zet1jeKW?}~b&XSfHk_Qe5y!>iyK8p4cEW2%tg*Po
z@xY8R+Vxm(2-ij05oJ|UsV@##1}ymN3Zf3xHBNPxvLp_6A0zRZm^JU5@Xirmx5V0u
z2WC#5<^!cyR=KUxq^WD1>aMKjn%XqqQ?V!|ng&juW<_c3sH|Evb&XTqmDOBq+cbZa
z#jKoY8aR2HHKpaNtXnj7jZ@u~)tpsrnqPLrs*-3LIC+}-fo>|jz@n*Zoa(Nu=E}Ee
z{;G+2EzvY^@-&&!3RSi&n!3iR?#gP;n>NjF4Y8>wng&juCRbXK%7+$BUE@@DWi>a<
zrul)1WsqnZIC+|nlvb<~;+@<zJ?Xl}sqTU!a%`%BwB$C;pDl6KN;C}|lV;RCM4X%-
zzZ}0B$$9VXV!c%C#>1QDGkNQUPotYCE^;}MOArwh0&Y$~7rGk20s`<`3>jcaFLa2*
z+z0yFgA6=LFLd^%^hHV1iKG`gGE@4jEa_Cz3!QW+eN~b4vZNO}pi=t0Cg~MPFLbV?
z^i5sTtCC*mI7sQsK+=6lFZ3x+=~pdDZ=g<lGMc`=9AE4mPbPb#>GbSv`^|WIesXr&
V?myY@?f0Wt4x-;KLPzj#^ABLW2|@q>

literal 0
HcmV?d00001

diff --git a/mysql-test/columnstore/std_data/uint8.parquet b/mysql-test/columnstore/std_data/uint8.parquet
new file mode 100644
index 0000000000000000000000000000000000000000..e1c8ae4d187709b3500d791fe614332226610ab0
GIT binary patch
literal 2319
zcmb`Jy>Ami5XH~u^~GPY&-U%H2S##1Rw<kaBLz{Up-&O<A6StkQji$ugZ}^_s)#B=
zG@z6gqCzPnM1?3*P$9|`RERPK@9nx+&~ew?$j_F>GjD#nyB&M`;iHihQc1NX1L<`=
z6D7R+ko06EqanTtp`d@?TNTVJVajY#Q1Z)nJpHQFmwvJldO@NpN4tB652P0d@yilk
zdQ(^bZBB-m>q(zOLVRG_UmRs*IHtmHQaG4bf>j8%FF4+nGdRBb`qVchPJ13n0P`iN
z3Z;=SuLP?Q4#~$#2FVYh=faRU?Rg|M45&j5D2;@9C0K=UNWLs(ko*qxg}t>-dmc#>
z1D2r{lt#k560AZvB;RWpBrj_E(mp3ndmc#}145_+rI9eN1gj7Z$*)ER$(x40s++sx
zwC9oV@bsVvN+V%jiNz6fNS?PcNIop<>!u-b+Ve;xCdJT=|Bx`RaQaL*B(K8^lFw~@
z(l#Vcdmf3xhy=O`rCk%|m0%UZA$i};Ao<qOXB|W0wC9oB!hk+>8%iT#UI|tq9Fk8_
z2FcH!KJOV4r#+1%8E$wgIM{hSc{1kC^H==EmRyOq=DjMPig+`bC;b8zDVJ`btN6e(
z1IHp(qV+uWY3kFoi0x)g=Ypn!rbR3&YkI+-o+zMc5j)44UYcuKrD+lC!<t^zNm{3A
z5u3o8UN>plq-ha{+M1rUY1*P`5$DsIo^@y%(zJ-9W=+p~H0^q;gXwto^k{Opwlkfs
jjc2p{XM^L(>|l3)Z!o&Ies_J8^tlw?;(x?8{tEp8k%IUo

literal 0
HcmV?d00001

diff --git a/tests/parquetconvert-tests.cpp b/tests/parquetconvert-tests.cpp
index 105f9f8dae..a24deb57ba 100644
--- a/tests/parquetconvert-tests.cpp
+++ b/tests/parquetconvert-tests.cpp
@@ -5,8 +5,7 @@ using namespace dataconvert;
 #include <arrow/api.h>
 #include <arrow/io/api.h>
 #include <parquet/exception.h>
-
-
+#include "we_tableinfo.h"
 
 // int32
 TEST(ParquetConvertTests, Convert)
@@ -25,5 +24,5 @@ TEST(ParquetConvertTests, Convert)
   std::shared_ptr<arrow::Array> array;
   PARQUET_THROW_NOT_OK(builder.Finish(&array));
   // TODO: how to call tableInfo method
-  
+  WriteEngine::TableInfo* tTable = new WriteEngine::TableInfo
 }
\ No newline at end of file
diff --git a/tools/parquetGen/main.cpp b/tools/parquetGen/main.cpp
index 68e1acbbb8..60fe031bb2 100644
--- a/tools/parquetGen/main.cpp
+++ b/tools/parquetGen/main.cpp
@@ -19,8 +19,9 @@ void generateIntTable()
   validity[2] = 0;
   validity[3] = 0;
   std::vector<int32_t> values;
-  for (int32_t i = 0; i < reserve_num; i++)
+  for (int32_t i = 0; i < reserve_num-1; i++)
     values.push_back(i);
+  values.push_back(2147483648);
   PARQUET_THROW_NOT_OK(builder.AppendValues(values, validity));
   std::shared_ptr<arrow::Array> array;
   PARQUET_THROW_NOT_OK(builder.Finish(&array));
@@ -40,6 +41,39 @@ void generateIntTable()
 
 }
 
+void generateInt64Table()
+{
+	// generate data
+  arrow::Int64Builder builder;
+  int reserve_num = 30;
+  PARQUET_THROW_NOT_OK(builder.Reserve(reserve_num));
+  std::vector<bool> validity(reserve_num, true);
+  validity[1] = 0;
+  validity[2] = 0;
+  validity[3] = 0;
+  std::vector<int64_t> values;
+  for (int64_t i = 0; i < reserve_num-1; i++)
+    values.push_back(i);
+  values.push_back(2147483648);
+  PARQUET_THROW_NOT_OK(builder.AppendValues(values, validity));
+  std::shared_ptr<arrow::Array> array;
+  PARQUET_THROW_NOT_OK(builder.Finish(&array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("int64", arrow::int64()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/int64.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+
+}
+
 void generateFloatTable()
 {
   int reserve_num = 30;
@@ -246,6 +280,35 @@ void generateInt16Table()
 	
 }
 
+void generateInt8Table()
+{
+	int reserve_num = 30;
+  // ---------------int16
+  arrow::Int8Builder i8builder;
+  PARQUET_THROW_NOT_OK(i8builder.Reserve(reserve_num));
+  std::vector<bool> i8validity(reserve_num, true);
+  std::vector<int8_t> i8values;
+  for (int8_t i = 0; i < reserve_num; i++)
+    i8values.push_back(i);
+  PARQUET_THROW_NOT_OK(i8builder.AppendValues(i8values, i8validity));
+  std::shared_ptr<arrow::Array> i8array;
+  PARQUET_THROW_NOT_OK(i8builder.Finish(&i8array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("int8", arrow::int8()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {i8array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/int8.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
 void generateDecimalTable()
 {
   // ----------------------decimal
@@ -276,67 +339,273 @@ void generateDecimalTable()
 	
 }
 
+
+void generateUintTable()
+{
+	// generate data
+  arrow::UInt32Builder builder;
+  uint reserve_num = 30;
+  PARQUET_THROW_NOT_OK(builder.Reserve(reserve_num));
+  std::vector<bool> validity(reserve_num, true);
+  validity[1] = 0;
+  validity[2] = 0;
+  validity[3] = 0;
+  std::vector<uint32_t> values;
+  for (uint32_t i = 0; i < reserve_num-1; i++)
+    values.push_back(i);
+  values.push_back(2147483648);
+  PARQUET_THROW_NOT_OK(builder.AppendValues(values, validity));
+  std::shared_ptr<arrow::Array> array;
+  PARQUET_THROW_NOT_OK(builder.Finish(&array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("int", arrow::uint32()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/uint32.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+
+}
+
+
+void generateUint16Table()
+{
+	uint16_t reserve_num = 30;
+  // ---------------int16
+  arrow::UInt16Builder i16builder;
+  PARQUET_THROW_NOT_OK(i16builder.Reserve(reserve_num));
+  std::vector<bool> i16validity(reserve_num, true);
+  std::vector<uint16_t> i16values;
+  for (uint16_t i = 0; i < reserve_num; i++)
+    i16values.push_back(i);
+  PARQUET_THROW_NOT_OK(i16builder.AppendValues(i16values, i16validity));
+  std::shared_ptr<arrow::Array> i16array;
+  PARQUET_THROW_NOT_OK(i16builder.Finish(&i16array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("uint16", arrow::uint16()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {i16array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/uint16.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+void generateUint8Table()
+{
+	uint8_t reserve_num = 30;
+  // ---------------int16
+  arrow::UInt8Builder i8builder;
+  PARQUET_THROW_NOT_OK(i8builder.Reserve(reserve_num));
+  std::vector<bool> i8validity(reserve_num, true);
+  std::vector<uint8_t> i8values;
+  for (uint8_t i = 0; i < reserve_num; i++)
+    i8values.push_back(i);
+  PARQUET_THROW_NOT_OK(i8builder.AppendValues(i8values, i8validity));
+  std::shared_ptr<arrow::Array> i8array;
+  PARQUET_THROW_NOT_OK(i8builder.Finish(&i8array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("uint8", arrow::uint8()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {i8array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/uint8.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+	
+}
+
+void generateUint64Table()
+{
+	// generate data
+  arrow::UInt64Builder builder;
+  uint64_t reserve_num = 30;
+  PARQUET_THROW_NOT_OK(builder.Reserve(reserve_num));
+  std::vector<bool> validity(reserve_num, true);
+  validity[1] = 0;
+  validity[2] = 0;
+  validity[3] = 0;
+  std::vector<uint64_t> values;
+  for (uint64_t i = 0; i < reserve_num-1; i++)
+    values.push_back(i);
+  values.push_back(2147483648);
+  PARQUET_THROW_NOT_OK(builder.AppendValues(values, validity));
+  std::shared_ptr<arrow::Array> array;
+  PARQUET_THROW_NOT_OK(builder.Finish(&array));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("uint64", arrow::uint64()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {array});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/uint64.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+
+}
+
+void generateBoolTable()
+{
+  int reserve_num = 30;
+  // ----------------------boolean
+  arrow::BooleanBuilder boolBuilder;
+  PARQUET_THROW_NOT_OK(boolBuilder.Reserve(reserve_num));
+  std::vector<bool> boolValidity(reserve_num, true);
+  std::vector<bool> boolValues;
+  for (int i = 0; i < reserve_num; i++)
+    boolValues.push_back(true);
+  boolValues[5] = false;
+  PARQUET_THROW_NOT_OK(boolBuilder.AppendValues(boolValues, boolValidity));
+  std::shared_ptr<arrow::Array> boolArray;
+  PARQUET_THROW_NOT_OK(boolBuilder.Finish(&boolArray));
+
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("bool", arrow::boolean()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {boolArray});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/bool.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+
+
+}
+
+
+void generateNullTable()
+{
+  int reserve_num = 30;
+  // ---------------------null
+  arrow::NullBuilder nullBuilder;
+  PARQUET_THROW_NOT_OK(nullBuilder.Reserve(reserve_num));
+  PARQUET_THROW_NOT_OK(nullBuilder.AppendNulls(reserve_num));
+  std::shared_ptr<arrow::Array> nullarray;
+  PARQUET_THROW_NOT_OK(nullBuilder.Finish(&nullarray));
+
+	std::shared_ptr<arrow::Schema> schema = arrow::schema({
+		arrow::field("null", arrow::null()),
+  });
+	std::shared_ptr<arrow::Table> table = arrow::Table::Make(schema, {nullarray});
+
+	// write to file
+  arrow::MemoryPool* pool = arrow::default_memory_pool();
+  std::shared_ptr<arrow::io::FileOutputStream> outfile;
+  PARQUET_ASSIGN_OR_THROW(
+      outfile, arrow::io::FileOutputStream::Open("../storage/columnstore/columnstore/mysql-test/columnstore/std_data/null.parquet"));
+  PARQUET_THROW_NOT_OK(parquet::arrow::WriteTable(*table, pool, outfile, 3));
+
+}
+
+
+void generateTable()
+{
+  generateBoolTable();
+  generateDateTable();
+  generateDecimalTable();
+  generateDoubleTable();
+  generateFloatTable();
+  generateInt16Table();
+  generateInt64Table();
+  generateInt8Table();
+  generateIntTable();
+  generateNullTable();
+  generateStringTable();
+  generateTimestampTable();
+  generateTimeTable();
+  generateUint16Table();
+  generateUint64Table();
+  generateUint8Table();
+  generateUintTable();
+}
+
+
 int main(int argc, char** argv)
 {
   int32_t option;
 
-  while ((option = getopt(argc, argv, "d:")) != EOF)
+  while ((option = getopt(argc, argv, "d")) != EOF)
   {
     switch (option)
     {
       case 'd':
       {
-        char col = optarg[0];
-
-        switch (col)
-        {
-          case 'a':
-          {
-						generateIntTable();
-						break;
-          }
-					case 'b':
-					{
-						generateFloatTable();
-						break;
-					}
-					case 'c':
-					{
-						generateDoubleTable();
-						break;
-					}
-					case 'd':
-					{
-						generateTimeTable();
-						break;
-					}
-					case 'e':
-					{
-						generateStringTable();
-						break;
-					}
-					case 'f':
-					{
-						generateTimestampTable();
-						break;
-					}
-					case 'g':
-					{
-						generateDateTable();
-						break;
-					}
-					case 'h':
-					{
-						generateInt16Table();
-						break;
-					}
-					case 'i':
-					{
-						generateDecimalTable();
-						break;
-					}
+        generateTable();
+        // char col = optarg[0];
+
+        // switch (col)
+        // {
+        //   case 'a':
+        //   {
+				// 		generateIntTable();
+				// 		break;
+        //   }
+				// 	case 'b':
+				// 	{
+				// 		generateFloatTable();
+				// 		break;
+				// 	}
+				// 	case 'c':
+				// 	{
+				// 		generateDoubleTable();
+				// 		break;
+				// 	}
+				// 	case 'd':
+				// 	{
+				// 		generateTimeTable();
+				// 		break;
+				// 	}
+				// 	case 'e':
+				// 	{
+				// 		generateStringTable();
+				// 		break;
+				// 	}
+				// 	case 'f':
+				// 	{
+				// 		generateTimestampTable();
+				// 		break;
+				// 	}
+				// 	case 'g':
+				// 	{
+				// 		generateDateTable();
+				// 		break;
+				// 	}
+				// 	case 'h':
+				// 	{
+				// 		generateInt16Table();
+				// 		break;
+				// 	}
+				// 	case 'i':
+				// 	{
+				// 		generateDecimalTable();
+				// 		break;
+				// 	}
 					
-        }
+        // }
       }
     }
   }
diff --git a/writeengine/bulk/we_tableinfo.cpp b/writeengine/bulk/we_tableinfo.cpp
index 4425e8e5f9..2d9408c036 100644
--- a/writeengine/bulk/we_tableinfo.cpp
+++ b/writeengine/bulk/we_tableinfo.cpp
@@ -912,7 +912,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         // time conversion here
         // for parquet, there are two time type, time32 and time64
         // if it's time32, unit is millisecond, int32
-        if (columnData->type_id() == arrow::Type::type::TIME32)
+        if (columnData->type_id() == arrow::Type::type::TIME32 || columnData->type_id() == arrow::Type::type::NA)
         {
           std::shared_ptr<arrow::Time32Array> timeArray = std::static_pointer_cast<arrow::Time32Array>(columnData);
           for (unsigned int i = 0; i < cbs; i++)
@@ -1230,7 +1230,8 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
         }
         else
         {
-          memcpy(&uiVal, dataPtr + i, width);
+          // memcpy(&uiVal, dataPtr + i, width);
+          origVal = *(dataPtr + i);
         }
         if (origVal < column.fMinIntSat)
         {
@@ -1374,6 +1375,7 @@ void TableInfo::parquetConvert(std::shared_ptr<arrow::Array> columnData, const J
             {
               iDate = joblist::DATENULL;
               pVal = &iDate;
+              memcpy(p, pVal, width);
               continue;
             }
           }
